{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13498329,"sourceType":"datasetVersion","datasetId":8570437},{"sourceId":13510653,"sourceType":"datasetVersion","datasetId":8578152},{"sourceId":13510901,"sourceType":"datasetVersion","datasetId":8578271},{"sourceId":13520907,"sourceType":"datasetVersion","datasetId":8585107}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üé¨ –ì–û–î–ñ–û 30 –°–ï–ö ‚Äî –ü–†–û–°–¢–ê–Ø –í–ï–†–°–ò–Ø –ë–ï–ó COMFYUI\n\n**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç notebook:**\n- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–Ω–∏–º–∞—Ü–∏—é —Å AnimateDiff –∏–ª–∏ —Å—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã\n- –ü—Ä–∏–º–µ–Ω—è–µ—Ç upscale —á–µ—Ä–µ–∑ Real-ESRGAN (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n- –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ—Ç –∫–∞–¥—Ä—ã —á–µ—Ä–µ–∑ RIFE –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏\n- –°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ\n\n**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:**\n1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –º–æ–¥–µ–ª—è–º–∏ –≤ Kaggle\n2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —è—á–µ–π–∫–µ –Ω–∏–∂–µ\n3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ —è—á–µ–π–∫–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É (Run All)","metadata":{}},{"cell_type":"code","source":"# === –†–ê–ù–ù–Ø–Ø –ù–ê–°–¢–†–û–ô–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø / –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê ===\n# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∞–∂–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –î–û –ª—é–±—ã—Ö heavy-–∏–º–ø–æ—Ä—Ç–æ–≤,\n# —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–π –æ –¥—É–±–ª–∏—Ä—É—é—â–µ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ CUDA-–ø–ª–∞–≥–∏–Ω–æ–≤ (cuFFT/cuDNN/cuBLAS) –æ—Ç XLA/JAX/TensorFlow.\nimport os\nimport importlib\n_changed_env = False\n\ndef _set_env_if_needed(k, v):\n    global _changed_env\n    if os.environ.get(k) != v:\n        os.environ[k] = v\n        _changed_env = True\n\n# –ü–æ–¥–∞–≤–ª—è–µ–º TensorFlow info/warnings, –æ—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥–∞–ª–æ–∫–∞—Ü–∏—é XLA –∫–ª–∏–µ–Ω—Ç–∞\n_set_env_if_needed('TF_CPP_MIN_LOG_LEVEL', '3')\n_set_env_if_needed('XLA_PYTHON_CLIENT_PREALLOCATE', 'false')\n_set_env_if_needed('XLA_PYTHON_CLIENT_MEM_FRACTION', '0.0')\n# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º JAX –Ω–∞ CPU, –µ—Å–ª–∏ –æ–Ω —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî —á—Ç–æ–±—ã –æ–Ω –Ω–µ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª GPU-–ø–ª–∞–≥–∏–Ω—ã\n_set_env_if_needed('JAX_PLATFORM_NAME', 'cpu')\n_set_env_if_needed('JAX_PLATFORMS', 'cpu')\n\n# –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –º—è–≥–∫–æ –ø–æ–¥–∞–≤–∏—Ç—å absl-–ª–æ–≥–∏ (–µ—Å–ª–∏ absl –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç)\ntry:\n    import absl.logging\n    absl.logging._warn_preinit_stderr = False\n    absl.logging.set_verbosity(absl.logging.WARNING)\nexcept Exception:\n    pass\n\n# –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –µ—Å—Ç—å –ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤—ã–∑–≤–∞—Ç—å XLA/JAX/TensorFlow –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ\n_found = {}\nfor mod in ('jax', 'jaxlib', 'tensorflow', 'torch_xla'):\n    _found[mod] = importlib.util.find_spec(mod) is not None\n\nprint('ENV diagnostic:')\nprint('  TF_CPP_MIN_LOG_LEVEL=', os.environ.get('TF_CPP_MIN_LOG_LEVEL'))\nprint('  XLA_PYTHON_CLIENT_PREALLOCATE=', os.environ.get('XLA_PYTHON_CLIENT_PREALLOCATE'))\nprint('  XLA_PYTHON_CLIENT_MEM_FRACTION=', os.environ.get('XLA_PYTHON_CLIENT_MEM_FRACTION'))\nprint('  JAX_PLATFORM_NAME=', os.environ.get('JAX_PLATFORM_NAME'))\nprint('  JAX_PLATFORMS=', os.environ.get('JAX_PLATFORMS'))\nprint('Detected potentially conflicting packages:')\nfor k, v in _found.items():\n    print(f'  {k}:', 'present' if v else 'not found')\n\nif _changed_env:\n    print('\\n‚ö†Ô∏è –í–∞–∂–Ω–æ: –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω—ã ‚Äî –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ kernel (Restart Kernel) –ø–µ—Ä–µ–¥ –¥–∞–ª—å–Ω–µ–π—à–∏–º –∏–º–ø–æ—Ä—Ç–æ–º heavy-–±–∏–±–ª–∏–æ—Ç–µ–∫, —á—Ç–æ–±—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤—Å—Ç—É–ø–∏–ª–∏ –≤ —Å–∏–ª—É –∏ —Å–æ–æ–±—â–µ–Ω–∏—è XLA/TensorFlow –Ω–µ –ø–æ—è–≤–ª—è–ª–∏—Å—å.')\nelse:\n    print('\\n‚ÑπÔ∏è –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T09:36:17.382613Z","iopub.execute_input":"2025-10-29T09:36:17.383002Z","iopub.status.idle":"2025-10-29T09:36:17.392509Z","shell.execute_reply.started":"2025-10-29T09:36:17.382976Z","shell.execute_reply":"2025-10-29T09:36:17.391741Z"}},"outputs":[{"name":"stdout","text":"ENV diagnostic:\n  TF_CPP_MIN_LOG_LEVEL= 3\n  XLA_PYTHON_CLIENT_PREALLOCATE= false\n  XLA_PYTHON_CLIENT_MEM_FRACTION= 0.0\n  JAX_PLATFORM_NAME= cpu\n  JAX_PLATFORMS= cpu\nDetected potentially conflicting packages:\n  jax: present\n  jaxlib: present\n  tensorflow: present\n  torch_xla: not found\n\n‚ÑπÔ∏è –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# === KAGGLE SETUP & CHECKS ===\n# –≠—Ç–∞ —è—á–µ–π–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –±–∞–∑–æ–≤—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ Kaggle –∏ –¥–∞—ë—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.\nimport os\nimport sys\nimport textwrap\n\n# –ó–∞—â–∏—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º print_separator –µ—Å–ª–∏ —è—á–µ–π–∫–∞ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ\nif 'print_separator' not in globals():\n    def print_separator(nl_before=True):\n        SEP = '=' * 60\n        if nl_before:\n            print('\\n' + SEP)\n        else:\n            print(SEP + '\\n')\n\nis_kaggle = any(p.startswith('/kaggle') for p in (os.getcwd(),)) or os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None\nprint_separator()\nprint('üß≠ KAGGLE CHECK')\nprint_separator(nl_before=False)\nprint('Running in Kaggle environment:', is_kaggle)\n\n# GPU check (non-blocking): try to detect torch without blocking the notebook\nimport importlib.util\nimport subprocess\nimport json\n\ntry:\n    if importlib.util.find_spec('torch') is None:\n        print('Torch not installed ‚Äî GPU check skipped (will be checked again in import cell).')\n    else:\n        print('Torch package detected ‚Äî running lightweight subprocess check (timeout 12s) to avoid hanging import...')\n        try:\n            cmd = [sys.executable, '-c', 'import torch, json; print(json.dumps({\"cuda\": torch.cuda.is_available(), \"device_count\": torch.cuda.device_count(), \"device_name\": (torch.cuda.get_device_name(0).strip() if torch.cuda.is_available() else \"no gpu\")}))']\n            # timeout can be adjusted via env var KAGGLE_TORCH_CHECK_TIMEOUT (seconds)\n            _timeout = int(os.environ.get('KAGGLE_TORCH_CHECK_TIMEOUT', '12'))\n            print(f'(torch subprocess timeout set to {_timeout}s)')\n            res = subprocess.run(cmd, capture_output=True, text=True, timeout=_timeout)\n            if res.returncode == 0 and res.stdout:\n                try:\n                    info = json.loads(res.stdout.strip())\n                    cuda_avail = info.get('cuda', False)\n                    device_name = info.get('device_name', 'no gpu')\n                    print(f'GPU available: {cuda_avail} ‚Äî {device_name}')\n                except Exception:\n                    print('‚úì torch detected but could not parse subprocess output:', res.stdout.strip())\n            else:\n                print('‚ö†Ô∏è torch subprocess failed or produced no output. stderr:', res.stderr.strip())\n        except subprocess.TimeoutExpired:\n            print('‚ö†Ô∏è Torch import timed out (subprocess). Skipping GPU check to avoid hanging the notebook.')\nexcept Exception as _e:\n    print('Torch check skipped (error):', _e)\n\n# Check for Hugging Face token in environment or common Kaggle input path\nhf_token = os.environ.get('HUGGINGFACE_HUB_TOKEN') or os.environ.get('HF_TOKEN')\n# First try the canonical path /kaggle/input/hf-token/token.txt\nhf_token_file = '/kaggle/input/hf-token/token.txt'\nfound_token_path = None\nif not hf_token and os.path.exists(hf_token_file):\n    try:\n        with open(hf_token_file, 'r', encoding='utf-8') as f:\n            hf_token = f.read().strip()\n            os.environ['HUGGINGFACE_HUB_TOKEN'] = hf_token\n            found_token_path = hf_token_file\n            print(f'‚úì Hugging Face token found in {hf_token_file} and set to HUGGINGFACE_HUB_TOKEN')\n    except Exception as e:\n        print('‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å token file:', e)\n\n# If still not found, search all /kaggle/input/** for token*.txt (flexible)\nif not hf_token:\n    try:\n        import glob\n        candidates = glob.glob('/kaggle/input/**/token*.txt', recursive=True)\n        if candidates:\n            # pick the first reasonable candidate\n            for c in candidates:\n                try:\n                    with open(c, 'r', encoding='utf-8') as f:\n                        t = f.read().strip()\n                    if t:\n                        hf_token = t\n                        os.environ['HUGGINGFACE_HUB_TOKEN'] = hf_token\n                        found_token_path = c\n                        print(f'‚úì Hugging Face token found in {c} and set to HUGGINGFACE_HUB_TOKEN')\n                        break\n                except Exception:\n                    continue\n    except Exception as _e:\n        print('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ token files:', _e)\n\nif hf_token:\n    print('‚úì Hugging Face token available via environment.')\n    if found_token_path:\n        print('  (token loaded from:', found_token_path + ')')\nelse:\n    print('\\n‚ö†Ô∏è Hugging Face token not found.')\n    print(textwrap.dedent('''\n    –ß—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ —Å Hugging Face –≤ Kaggle, –¥–æ–±–∞–≤—å—Ç–µ –≤–∞—à —Ç–æ–∫–µ–Ω —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n\n    1) –í –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ Kaggle: Add Data -> —Å–æ–∑–¥–∞–π—Ç–µ dataset —Å —Ñ–∞–π–ª–æ–º token.txt (—Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞—à —Ç–æ–∫–µ–Ω) –∏ –ø–æ–¥–∫–ª—é—á–∏—Ç–µ –µ–≥–æ –∫ –Ω–æ—É—Ç–±—É–∫—É –∫–∞–∫ /kaggle/input/hf-token\n    2) –õ–∏–±–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –ø—Ä—è–º–æ –≤ –Ω–æ—É—Ç–±—É–∫–µ (–≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–µ):\n\n       import os\n       os.environ['HUGGINGFACE_HUB_TOKEN'] = '–í–ê–®_–¢–û–ö–ï–ù'\n\n    –ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ç–æ–∫–µ–Ω–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ kernel.\n    '''))\n\n# ipywidgets hint\ntry:\n    import ipywidgets  # type: ignore\n    print('‚úì ipywidgets –¥–æ—Å—Ç—É–ø–µ–Ω')\nexcept Exception:\n    print('\\n‚ö†Ô∏è ipywidgets –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî GUI –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å.')\n    print('  –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ipywidgets –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–µ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ kernel:')\n    print('\\n```bash\\n!pip install ipywidgets -q\\n```\\n')\n\n# Quick safe defaults suggestion for Kaggle (optional)\nif is_kaggle:\n    print('\\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ Kaggle:')\n    print('  - –í–∫–ª—é—á–∏—Ç–µ GPU –≤ Settings -> Accelerator -> GPU')\n    print('  - –î–ª—è —Ç–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ–±–æ–ª—å—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: WIDTH=256, HEIGHT=256, NUM_FRAMES=4, STEPS=15')\n    print('  - –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ –ø–∞–º—è—Ç—å, —É–º–µ–Ω—å—à–∏—Ç–µ WIDTH/NUM_FRAMES –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ model_cpu_offload() (pipeline —É–∂–µ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è —Å —ç—Ç–∏–º —Ñ–ª–∞–≥–æ–º)')\n\nprint_separator()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T15:00:36.799482Z","iopub.execute_input":"2025-10-27T15:00:36.799978Z","iopub.status.idle":"2025-10-27T15:00:38.743154Z","shell.execute_reply.started":"2025-10-27T15:00:36.799955Z","shell.execute_reply":"2025-10-27T15:00:38.742423Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüß≠ KAGGLE CHECK\n============================================================\n\nRunning in Kaggle environment: True\nTorch package detected ‚Äî running lightweight subprocess check (timeout 12s) to avoid hanging import...\n(torch subprocess timeout set to 12s)\nGPU available: True ‚Äî Tesla T4\n‚úì Hugging Face token available via environment.\n‚úì ipywidgets –¥–æ—Å—Ç—É–ø–µ–Ω\n\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ Kaggle:\n  - –í–∫–ª—é—á–∏—Ç–µ GPU –≤ Settings -> Accelerator -> GPU\n  - –î–ª—è —Ç–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ–±–æ–ª—å—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: WIDTH=256, HEIGHT=256, NUM_FRAMES=4, STEPS=15\n  - –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ –ø–∞–º—è—Ç—å, —É–º–µ–Ω—å—à–∏—Ç–µ WIDTH/NUM_FRAMES –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ model_cpu_offload() (pipeline —É–∂–µ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è —Å —ç—Ç–∏–º —Ñ–ª–∞–≥–æ–º)\n\n============================================================\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# === SMOKE TEST (–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è prompts.json –∏ Hugging Face token) ===\nimport glob, os, json\nprint_separator()\nprint('üîé SMOKE TEST ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ prompts.json –∏ Hugging Face token')\nprint_separator(nl_before=False)\n\n# –ü–æ–∫–∞–∂–µ–º –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ input'—ã\ninputs = glob.glob('/kaggle/input/*') if os.path.exists('/kaggle/input') else []\nprint('Connected input datasets:', inputs)\n\n# –ò—â–µ–º prompts.json\nprompts_candidates = glob.glob('/kaggle/input/**/prompts.json', recursive=True) if os.path.exists('/kaggle/input') else []\nif not prompts_candidates and os.path.exists('/kaggle/working/prompts.json'):\n    prompts_candidates = ['/kaggle/working/prompts.json']\n\nif prompts_candidates:\n    p = prompts_candidates[0]\n    print('‚úì prompts.json found at:', p)\n    try:\n        with open(p, 'r', encoding='utf-8') as f:\n            data = json.load(f)\n        print('  keys:', list(data.keys()))\n        # preview safe snippets\n        base = (data.get('BASE_PROMPT') or '')[:200]\n        motion = (data.get('MOTION_PROMPT') or '')[:120]\n        print('  BASE_PROMPT preview:', base)\n        print('  MOTION_PROMPT preview:', motion)\n    except Exception as e:\n        print('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ prompts.json:', e)\nelse:\n    print('‚ö†Ô∏è prompts.json not found in /kaggle/input or /kaggle/working. Attach dataset or upload file.')\n    print(\"  Tips: Add Data -> attach 'noxfvr/comfy-gojo-dataset' or upload prompts.json to working dir.\")\n\n# –ü—Ä–æ–≤–µ—Ä—è–µ–º Hugging Face token (–±–µ–∑ –≤—ã–≤–æ–¥–∞ –ø–æ–ª–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è)\ntoken = os.environ.get('HUGGINGFACE_HUB_TOKEN') or os.environ.get('HF_TOKEN')\nif token:\n    print('\\n‚úì HUGGINGFACE_HUB_TOKEN found in environment (masked):')\n    try:\n        print('  length:', len(token), 'prefix:', token[:6] + '...')\n    except Exception:\n        print('  (cannot preview token)')\n    # –ü—ã—Ç–∞–µ–º—Å—è –≤–∞–ª–∏–¥–∞—Ü–∏—é, –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω huggingface_hub\n    try:\n        from huggingface_hub import HfApi\n        api = HfApi()\n        info = api.whoami(token=token)\n        user = info.get('name') or info.get('user') or info\n        print('  HF token appears valid; user:', user)\n    except Exception as e:\n        print('  Could not validate token with huggingface_hub (not installed or error):', e)\n        print(\"  To validate: run '!pip install -q huggingface_hub' and re-run this cell\")\nelse:\n    print('\\n‚ö†Ô∏è HUGGINGFACE_HUB_TOKEN not found in environment.')\n    print('  If you have hf-token dataset attached, ensure it contains token.txt and restart the kernel.')\n\nprint_separator()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T15:00:45.392979Z","iopub.execute_input":"2025-10-27T15:00:45.393386Z","iopub.status.idle":"2025-10-27T15:00:45.640887Z","shell.execute_reply.started":"2025-10-27T15:00:45.393350Z","shell.execute_reply":"2025-10-27T15:00:45.640118Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"\n============================================================\nüîé SMOKE TEST ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ prompts.json –∏ Hugging Face token\n============================================================\n\nConnected input datasets: ['/kaggle/input/comfy-gojo-dataset', '/kaggle/input/hf-token', '/kaggle/input/comfyui-models-gojo', '/kaggle/input/generate-shim']\n‚úì prompts.json found at: /kaggle/input/comfy-gojo-dataset/prompts.json\n  keys: ['BASE_PROMPT', 'MOTION_PROMPT', 'EXTRA_PROMPT', 'NEGATIVE_PROMPT']\n  BASE_PROMPT preview: cinematic portrait of gojo satoru, white spiky hair, black blindfold, confident expression, anime style, highly detailed, 8k, professional lighting\n  MOTION_PROMPT preview: turning head, hair flowing, smooth motion\n\n‚úì HUGGINGFACE_HUB_TOKEN found in environment (masked):\n  length: 37 prefix: hf_rfx...\n  HF token appears valid; user: noxfvr\n\n============================================================\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# ============================================\n# üìù –ù–ê–°–¢–†–û–ô–ö–ò - –ú–ï–ù–Ø–ô –¢–û–õ–¨–ö–û –≠–¢–û!\n# ============================================\n# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Å—Ç–∞—Ö)\nDEFAULT_BASE_PROMPT = \"cinematic portrait of gojo satoru, white spiky hair, black blindfold, confident expression, anime style, highly detailed, 8k, professional lighting\"\nDEFAULT_NEGATIVE_PROMPT = \"blurry, deformed, low quality, watermark, text, bad anatomy, multiple heads, duplicate\"\n\nPROMPT = DEFAULT_BASE_PROMPT\nNEGATIVE_PROMPT = DEFAULT_NEGATIVE_PROMPT\n\n# –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã\nUSE_ANIMATEDIFF = True  # True = –Ω–∞—Å—Ç–æ—è—â–∞—è –∞–Ω–∏–º–∞—Ü–∏—è, False = —Å—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã + RIFE\n\n# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\nWIDTH = 512\nHEIGHT = 768\nNUM_FRAMES = 16 if USE_ANIMATEDIFF else 8  # AnimateDiff: 16-24, –æ–±—ã—á–Ω—ã–π: 8-12\nSTEPS = 25 if USE_ANIMATEDIFF else 20  # –î–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ steps\nCFG_SCALE = 7.5 if USE_ANIMATEDIFF else 7\nFPS = 8  # FPS –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ\n\n# –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è RIFE (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\nUSE_RIFE = True  # –ü—Ä–∏–º–µ–Ω–∏—Ç—å RIFE –¥–ª—è –µ—â—ë –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω–æ–π –∞–Ω–∏–º–∞—Ü–∏–∏\nRIFE_EXP = 4 if USE_ANIMATEDIFF else 5  # AnimateDiff: 4 (16‚Üí256), –æ–±—ã—á–Ω—ã–π: 5 (8‚Üí256)\n# –ò–º—è —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–ø—Å–∫–µ–π–ª–∞ (Real-ESRGAN)\nUPSCALE_MODEL_NAME = '4x-UltraSharp.pth'\n# ============================================\n\n# === PROMPTS ‚Äî –í–ê–®–ò PROMPT'–´ –î–õ–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –ò –ê–ù–ò–ú–ê–¶–ò–ò (–ø–µ—Ä–µ–º–µ—â–µ–Ω–∞) ===\n# –≠—Ç–∞ —è—á–µ–π–∫–∞ —Ç–µ–ø–µ—Ä—å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø—Ä—è–º–æ –ø–æ—Å–ª–µ –±–ª–æ–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫. –†–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –∑–¥–µ—Å—å BASE/MOTION/EXTRA/NEGATIVE\nimport os\nfrom IPython.display import display, clear_output\n\n# –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤\nPROMPTS_FILE = os.path.join(os.getcwd(), 'prompts.json')\n\n# –ù–∞–±–æ—Ä –ø—Ä–µ—Å–µ—Ç–æ–≤: –∏–º—è -> (base, motion, extra, negative)\nPRESETS = {\n    'default': (\n        DEFAULT_BASE_PROMPT,\n        \"turning head, hair flowing, smooth motion\",\n        \"dramatic rim lighting, soft bloom, depth of field\",\n        DEFAULT_NEGATIVE_PROMPT\n    ),\n    'slow pan': (\n        \"cinematic portrait, highly detailed, 8k, beautiful face\",\n        \"slow camera pan left, subtle head turn\",\n        \"soft warm lighting, cinematic\",\n        \"blurry, low quality, watermark, text\"\n    ),\n    'head turn': (\n        \"close-up portrait, detailed, professional lighting\",\n        \"turning head to left then right, hair movement\",\n        \"rim light, subtle bloom\",\n        \"multiple heads, deformed, watermark\"\n    ),\n    'blinking': (\n        \"portrait, soft lighting, anime style\",\n        \"subtle blink, small head tilt\",\n        \"soft bokeh, cinematic lighting\",\n        \"blurry, artifact, watermark\"\n    )\n}\n\n# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ—Å–µ—Ç (–µ—Å–ª–∏ PROMPT —É–∂–µ –∑–∞–¥–∞–Ω, –ø—ã—Ç–∞–µ–º—Å—è —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å)\ndef load_preset(name):\n    if name in PRESETS:\n        base, motion, extra, negative = PRESETS[name]\n        return {'BASE_PROMPT': base, 'MOTION_PROMPT': motion, 'EXTRA_PROMPT': extra, 'NEGATIVE_PROMPT': negative}\n    return None\n\n# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ prompts.json\ndef save_prompts_file(data, path=PROMPTS_FILE):\n    try:\n        import json\n        with open(path, 'w', encoding='utf-8') as f:\n            json.dump(data, f, ensure_ascii=False, indent=2)\n        print(f\"‚úì Prompts saved to {path}\")\n    except Exception as e:\n        print('‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å prompts.json:', e)\n\n# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ prompts.json\ndef load_prompts_file(path=PROMPTS_FILE):\n    try:\n        import json\n        if os.path.exists(path):\n            with open(path, 'r', encoding='utf-8') as f:\n                return json.load(f)\n    except Exception as e:\n        print('‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å prompts.json:', e)\n    return None\n\n# –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–∏—Ç—å ipywidgets; –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –≤—ã–≤–æ–¥–∏–º fallback –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏\ndef create_prompts_gui():\n    try:\n        import ipywidgets as widgets\n    except Exception:\n        print('‚ö†Ô∏è ipywidgets –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî GUI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ipywidgets')\n        # Fallback: –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞—ë–º PROMP–¢ –∏–∑ —Ç–µ–∫—É—â –∫–æ–Ω—Å—Ç–∞–Ω—Ç\n        parts = [p for p in (globals().get('PROMPT', ''), '') if p]\n        globals()['PROMPT'] = globals().get('PROMPT', '')\n        globals()['NEGATIVE_PROMPT'] = globals().get('NEGATIVE_PROMPT', '')\n        print('\\nPROMPT (fallback):', globals()['PROMPT'])\n        return\n\n    # –í–∏–¥–∂–µ—Ç—ã\n    preset_dropdown = widgets.Dropdown(options=list(PRESETS.keys()), value='default', description='Preset:')\n    base_ta = widgets.Textarea(value=PRESETS['default'][0], description='Base:', layout=widgets.Layout(width='100%', height='80px'))\n    motion_ta = widgets.Textarea(value=PRESETS['default'][1], description='Motion:', layout=widgets.Layout(width='100%', height='60px'))\n    extra_ta = widgets.Textarea(value=PRESETS['default'][2], description='Extra:', layout=widgets.Layout(width='100%', height='60px'))\n    negative_ta = widgets.Textarea(value=PRESETS['default'][3], description='Negative:', layout=widgets.Layout(width='100%', height='60px'))\n\n    save_btn = widgets.Button(description='Save to prompts.json', button_style='success')\n    load_btn = widgets.Button(description='Load from prompts.json')\n    update_btn = widgets.Button(description='Update PROMPT', button_style='primary')\n    out = widgets.Output()\n\n    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏\n    def on_preset_change(change):\n        if change['type'] == 'change' and change['name'] == 'value':\n            vals = load_preset(change['new'])\n            if vals:\n                base_ta.value = vals['BASE_PROMPT']\n                motion_ta.value = vals['MOTION_PROMPT']\n                extra_ta.value = vals['EXTRA_PROMPT']\n                negative_ta.value = vals['NEGATIVE_PROMPT']\n\n    def on_save_clicked(b):\n        data = {\n            'BASE_PROMPT': base_ta.value,\n            'MOTION_PROMPT': motion_ta.value,\n            'EXTRA_PROMPT': extra_ta.value,\n            'NEGATIVE_PROMPT': negative_ta.value\n        }\n        save_prompts_file(data)\n\n    def on_load_clicked(b):\n        data = load_prompts_file()\n        if data:\n            base_ta.value = data.get('BASE_PROMPT', base_ta.value)\n            motion_ta.value = data.get('MOTION_PROMPT', motion_ta.value)\n            extra_ta.value = data.get('EXTRA_PROMPT', extra_ta.value)\n            negative_ta.value = data.get('NEGATIVE_PROMPT', negative_ta.value)\n            with out:\n                clear_output()\n                print('‚úì Prompts loaded into GUI (not yet applied)')\n        else:\n            with out:\n                clear_output()\n                print('‚ö†Ô∏è prompts.json –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω')\n\n    def on_update_clicked(b):\n        # –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π PROMPT\n        parts = [p.strip() for p in (base_ta.value, motion_ta.value, extra_ta.value) if p and p.strip()]\n        final = ', '.join(parts)\n        globals()['PROMPT'] = final\n        globals()['NEGATIVE_PROMPT'] = negative_ta.value\n        with out:\n            clear_output()\n            print('‚úì PROMPT –æ–±–Ω–æ–≤–ª—ë–Ω')\n            print('\\nPROMPT:')\n            print(final)\n            print('\\nNEGATIVE_PROMPT:')\n            print(negative_ta.value)\n\n    preset_dropdown.observe(on_preset_change)\n    save_btn.on_click(on_save_clicked)\n    load_btn.on_click(on_load_clicked)\n    update_btn.on_click(on_update_clicked)\n\n    # Layout\n    controls = widgets.VBox([\n        preset_dropdown,\n        base_ta,\n        motion_ta,\n        extra_ta,\n        negative_ta,\n        widgets.HBox([update_btn, save_btn, load_btn]),\n        out\n    ])\n\n    display(controls)\n    # –ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å prompts.json –≤ GUI –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏\n    data = load_prompts_file()\n    if data:\n        base_ta.value = data.get('BASE_PROMPT', base_ta.value)\n        motion_ta.value = data.get('MOTION_PROMPT', motion_ta.value)\n        extra_ta.value = data.get('EXTRA_PROMPT', extra_ta.value)\n        negative_ta.value = data.get('NEGATIVE_PROMPT', negative_ta.value)\n        with out:\n            print('‚úì prompts.json –∑–∞–≥—Ä—É–∂–µ–Ω –≤ GUI')\n\n# –í—ã–∑—ã–≤–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ GUI\ncreate_prompts_gui()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T09:36:40.467467Z","iopub.execute_input":"2025-10-29T09:36:40.468191Z","iopub.status.idle":"2025-10-29T09:36:40.614908Z","shell.execute_reply.started":"2025-10-29T09:36:40.468166Z","shell.execute_reply":"2025-10-29T09:36:40.614126Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(Dropdown(description='Preset:', options=('default', 'slow pan', 'head turn', 'blinking'), value‚Ä¶","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3587b83503d0452187b0bdb84038dbf5"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ===\nimport os\nimport time\nfrom IPython.display import FileLink, display\n\nWORKSPACE = \"/kaggle/working\"\nFRAMES_DIR = f\"{WORKSPACE}/frames\"\nDATASET_DIR = \"/kaggle/input/comfyui-models-gojo\"\n\nos.makedirs(FRAMES_DIR, exist_ok=True)\nprint(\"‚úì –ü–∞–ø–∫–∏ —Å–æ–∑–¥–∞–Ω—ã\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T09:37:04.891351Z","iopub.execute_input":"2025-10-29T09:37:04.891733Z","iopub.status.idle":"2025-10-29T09:37:04.897071Z","shell.execute_reply.started":"2025-10-29T09:37:04.891706Z","shell.execute_reply":"2025-10-29T09:37:04.896114Z"}},"outputs":[{"name":"stdout","text":"‚úì –ü–∞–ø–∫–∏ —Å–æ–∑–¥–∞–Ω—ã\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# === –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô ===\nprint(\"üîß –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...\\n\")\n\nimport sys\nimport importlib.util\n\ndef check_package(package_name):\n    \"\"\"–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–∞–∫–µ—Ç–∞ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞\"\"\"\n    return importlib.util.find_spec(package_name) is not None\n\n# –°–ø–∏—Å–æ–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤\npackages_to_install = []\n\nif not check_package(\"diffusers\"):\n    packages_to_install.append(\"diffusers[torch]\")\n    packages_to_install.append(\"transformers\")\n    packages_to_install.append(\"accelerate\")\nelse:\n    print(\"‚úì diffusers —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n\nif not check_package(\"cv2\"):\n    packages_to_install.append(\"opencv-python\")\nelse:\n    print(\"‚úì opencv-python —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n\nif USE_ANIMATEDIFF and not check_package(\"imageio\"):\n    packages_to_install.append(\"imageio\")\n    packages_to_install.append(\"imageio-ffmpeg\")\nelif USE_ANIMATEDIFF:\n    print(\"‚úì imageio —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n\n# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º ipywidgets –¥–ª—è GUI, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç\nif not check_package(\"ipywidgets\"):\n    packages_to_install.append(\"ipywidgets\")\nelse:\n    print(\"‚úì ipywidgets —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n\n# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –ø–∞–∫–µ—Ç—ã –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π (—á–µ—Ä–µ–∑ subprocess –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∏–º–æ—Å—Ç–∏)\nif packages_to_install:\n    print(f\"\\n–£—Å—Ç–∞–Ω–æ–≤–∫–∞: {', '.join(packages_to_install)}...\")\n    import subprocess\n    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Python interpreter –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ —Ç–µ–∫—É—â–µ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ\n    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + packages_to_install)\n    print(\"‚úì –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n    # –ü—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–µ ipywidgets –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ kernel –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã GUI\n    if 'ipywidgets' in packages_to_install:\n        print('\\n‚ö†Ô∏è ipywidgets —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ kernel (Restart Kernel) –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ Kaggle, —á—Ç–æ–±—ã GUI –∑–∞—Ä–∞–±–æ—Ç–∞–ª –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.')\n\nprint(\"\\n‚úì –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≥–æ—Ç–æ–≤—ã!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-29T09:37:07.325770Z","iopub.execute_input":"2025-10-29T09:37:07.326390Z","iopub.status.idle":"2025-10-29T09:37:07.336554Z","shell.execute_reply.started":"2025-10-29T09:37:07.326367Z","shell.execute_reply":"2025-10-29T09:37:07.335941Z"}},"outputs":[{"name":"stdout","text":"üîß –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...\n\n‚úì diffusers —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n‚úì opencv-python —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n‚úì imageio —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n‚úì ipywidgets —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n\n‚úì –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≥–æ—Ç–æ–≤—ã!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#=== –ü–û–î–ê–í–õ–ï–ù–ò–ï –®–£–ú–ê –û–¢ XLA / TensorFlow / absl ===\n# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –î–û –∏–º–ø–æ—Ä—Ç–æ–≤, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä—É—é—â–µ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ CUDA-–ø–ª–∞–≥–∏–Ω–æ–≤\nimport os\n# –°–∫—Ä—ã—Ç—å INFO/WARNING TensorFlow-–ª–æ–≥–∏ (–µ—Å–ª–∏ TF –ø–æ–¥–≥—Ä—É–∂–∞–µ—Ç—Å—è –∫–æ—Å–≤–µ–Ω–Ω–æ)\nos.environ.setdefault('TF_CPP_MIN_LOG_LEVEL', '3')\n# –û—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–µ–¥–∞–ª–æ–∫–∞—Ü–∏—é –ø–∞–º—è—Ç–∏ —É XLA –∫–ª–∏–µ–Ω—Ç–∞ (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω jax/xla)\nos.environ.setdefault('XLA_PYTHON_CLIENT_PREALLOCATE', 'false')\nos.environ.setdefault('XLA_PYTHON_CLIENT_MEM_FRACTION', '0.0')\n\n# –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∞–≤–∏—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è absl —É–∂–µ –Ω–∞ —ç—Ç–∞–ø–µ –∏–º–ø–æ—Ä—Ç–∞ (–±–µ–∑ –ø–∞–¥–µ–Ω–∏–π, –µ—Å–ª–∏ absl –Ω–µ—Ç)\ntry:\n    import absl.logging\n    # –ù–µ –ø–∏—Å–∞—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ stderr\n    absl.logging._warn_preinit_stderr = False\n    absl.logging.set_verbosity(absl.logging.WARNING)\nexcept Exception:\n    pass\n\n# === –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö ===\n# –ó–∞—â–∏—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è print_separator –Ω–µ –±—ã–ª–∞ —Ä–∞–Ω–µ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ (—è—á–µ–π–∫–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª–∞—Å—å),\n# –æ–ø—Ä–µ–¥–µ–ª–∏–º –ø—Ä–æ—Å—Ç—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é –≤–µ—Ä—Å–∏—é, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å NameError –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–∏.\nif \"print_separator\" not in globals():\n    def print_separator(nl_before=True):\n        SEP = '=' * 60\n        if nl_before:\n            print('\\n' + SEP)\n        else:\n            print(SEP + '\\n')\n\nprint_separator()\nprint(\"üé® –ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å ~30 —Å–µ–∫)...\\n\")\n\nimport torch\nfrom PIL import Image\n\nprint(\"‚úì PyTorch –∏ PIL –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\nprint(f\"‚úì CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:31:33.162468Z","iopub.execute_input":"2025-10-27T14:31:33.162699Z","iopub.status.idle":"2025-10-27T14:31:34.821306Z","shell.execute_reply.started":"2025-10-27T14:31:33.162682Z","shell.execute_reply":"2025-10-27T14:31:34.820511Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüé® –ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å ~30 —Å–µ–∫)...\n\n‚úì PyTorch –∏ PIL –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n‚úì CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: True\n‚úì GPU: Tesla T4\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# === –ó–ê–ì–†–£–ó–ö–ê ANIMATEDIFF PIPELINE (–æ—Ç–¥–µ–ª—å–Ω–∞—è —è—á–µ–π–∫–∞) ===\n# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –ø–µ—Ä–µ–¥ —è—á–µ–π–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å –∏ —Å—ç–∫–æ–Ω–æ–º–∏—Ç—å –≤—Ä–µ–º—è –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\nif 'USE_ANIMATEDIFF' in globals() and USE_ANIMATEDIFF:\n    if 'pipe' in globals() and 'adapter' in globals():\n        print('‚úì AnimateDiff pipeline —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω (pipe, adapter –≤ globals).')\n    else:\n        print('–ó–∞–≥—Ä—É–∑–∫–∞ AnimateDiff pipeline...')\n        try:\n            from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n            from diffusers.utils import export_to_video\n            import torch\n\n            adapter = MotionAdapter.from_pretrained(\n                \"guoyww/animatediff-motion-adapter-v1-5-2\",\n                torch_dtype=torch.float16\n            )\n\n            # AnimateDiff —Ä–∞–±–æ—Ç–∞–µ—Ç —Å SD 1.5\n            pipe = AnimateDiffPipeline.from_pretrained(\n                \"runwayml/stable-diffusion-v1-5\",\n                motion_adapter=adapter,\n                torch_dtype=torch.float16\n            ).to(\"cuda\")\n\n            pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n            pipe.enable_vae_slicing()\n            pipe.enable_model_cpu_offload()\n\n            print('‚úì AnimateDiff –≥–æ—Ç–æ–≤! (adapter & pipe –∑–∞–≥—Ä—É–∂–µ–Ω—ã)')\n        except Exception as _e:\n            print('‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å AnimateDiff pipeline:', _e)\n            print('  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É diffusers, –¥–æ—Å—Ç—É–ø –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ –Ω–∞–ª–∏—á–∏–µ CUDA/GPU.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:31:34.822135Z","iopub.execute_input":"2025-10-27T14:31:34.822415Z","iopub.status.idle":"2025-10-27T14:33:04.988865Z","shell.execute_reply.started":"2025-10-27T14:31:34.822391Z","shell.execute_reply":"2025-10-27T14:33:04.987996Z"}},"outputs":[{"name":"stdout","text":"–ó–∞–≥—Ä—É–∑–∫–∞ AnimateDiff pipeline...\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761575503.244423      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761575503.295751      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py:202: UserWarning: The `local_dir_use_symlinks` argument is deprecated and ignored in `hf_hub_download`. Downloading to a local directory does not use symlinks anymore.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/455 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf3e0b068b8b4c178cbdea4382457067"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"diffusion_pytorch_model.safetensors:   0%|          | 0.00/1.82G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5f5a4d55d6945f19901d2f76e7879dc"}},"metadata":{}},{"name":"stderr","text":"The config attributes {'motion_activation_fn': 'geglu', 'motion_attention_bias': False, 'motion_cross_attention_dim': None} were passed to MotionAdapter, but are not expected and will be ignored. Please verify your config.json configuration file.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1461eb0af1f4f8aa59fbc0e34aa9533"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4624242994f49dfba7eecf5abc3da48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e43b5b22e22451cb395218da561eced"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a87f981f5b94e14ae0e1bae3178e051"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f3e59958e1348eb930934f4463a7178"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e655475868449ce9c851e011e3ce928"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13dc5bc7b6f84639890a1b6944da0d7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4f2e333bfcb4c7a9020e1d19ab54ab2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cfed61caef345a5a4000cee743f40f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"safety_checker/model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15aabc29a9d14eb1ad580d0c1ab60403"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04a1f5a2616e4f07b4741ed67faa9238"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"822c0371a99c4823bf8f1884307d7dea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67ef2f6af1b645158cdad256b62e8c1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"732a06d8917740e2ad51564b3592996c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e535f55160514024832abb395c0d5e02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d0fac951ab343f58eeb1f4b7fb21bed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d072e23c2f214cc7b805630d03e17f3e"}},"metadata":{}},{"name":"stdout","text":"‚úì AnimateDiff –≥–æ—Ç–æ–≤! (adapter & pipe –∑–∞–≥—Ä—É–∂–µ–Ω—ã)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# === –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–î–†–û–í / –ê–ù–ò–ú–ê–¶–ò–ò ===\n# –ó–∞—â–∏—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–ø–æ–ª–Ω–∏–ª —Ç–æ–ª—å–∫–æ —ç—Ç—É —è—á–µ–π–∫—É, —Ç–æ —É—Å—Ç–∞–Ω–æ–≤–∏–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\nimport os\nimport time\n_defaults = {\n    'PROMPT': \"cinematic portrait of gojo satoru, white spiky hair, black blindfold, confident expression, anime style, highly detailed, 8k, professional lighting\",\n    'NEGATIVE_PROMPT': \"blurry, deformed, low quality, watermark, text, bad anatomy, multiple heads, duplicate\",\n    'USE_ANIMATEDIFF': True,\n    'USE_RIFE': True,\n    'WIDTH': 512,\n    'HEIGHT': 768,\n    'NUM_FRAMES': 16,\n    'STEPS': 25,\n    'CFG_SCALE': 7.5,\n    'FPS': 8,\n    'RIFE_EXP': 4,\n    'WORKSPACE': os.getcwd()\n}\nfor _k, _v in _defaults.items():\n    if _k not in globals():\n        globals()[_k] = _v\n        print(f\"‚ö†Ô∏è –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è {_k} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {_v}\")\n\n# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫–∞–¥—Ä–æ–≤ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\nif 'FRAMES_DIR' not in globals():\n    FRAMES_DIR = f\"{WORKSPACE}/frames\"\nos.makedirs(FRAMES_DIR, exist_ok=True)\n\nprint_separator()\nprint(f\"üé® {'–ì–ï–ù–ï–†–ê–¶–ò–Ø –ê–ù–ò–ú–ê–¶–ò–ò' if USE_ANIMATEDIFF else '–ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–î–†–û–í'}\")\nprint_separator(nl_before=False)\nprint(f\"–ü—Ä–æ–º–ø—Ç: {PROMPT[:80]}...\")\nprint(f\"–†–∞–∑–º–µ—Ä: {WIDTH}x{HEIGHT}, Steps: {STEPS}, CFG: {CFG_SCALE}\")\nprint(f\"–ö–∞–¥—Ä–æ–≤: {NUM_FRAMES}\\n\")\n\nif USE_ANIMATEDIFF:\n    # === –†–ï–ñ–ò–ú ANIMATEDIFF - –ù–ê–°–¢–û–Ø–©–ê–Ø –ê–ù–ò–ú–ê–¶–ò–Ø ===\n    # –¢–µ–ø–µ—Ä—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π `pipe` (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å). –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å —è—á–µ–π–∫—É –∑–∞–≥—Ä—É–∑–∫–∏.\n    if 'pipe' not in globals():\n        print(\"‚ö†Ô∏è AnimateDiff pipeline –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ—Ç–¥–µ–ª—å–Ω—É—é —è—á–µ–π–∫—É '–ó–ê–ì–†–£–ó–ö–ê AN–ò–ú–ê–¶–ò–ò PIPELINE' –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É, —á—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å –µ–≥–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.\")\n        # –ü–æ–ø—Ä–æ–±—É–µ–º –≤—Å—ë –∂–µ –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å inline (fallback):\n        try:\n            from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n            from diffusers.utils import export_to_video\n            import torch\n\n            print('–ó–∞–≥—Ä—É–∑–∫–∞ AnimateDiff pipeline (fallback inline)...')\n            adapter = MotionAdapter.from_pretrained(\n                \"guoyww/animatediff-motion-adapter-v1-5-2\",\n                torch_dtype=torch.float16\n            )\n            pipe = AnimateDiffPipeline.from_pretrained(\n                \"runwayml/stable-diffusion-v1-5\",\n                motion_adapter=adapter,\n                torch_dtype=torch.float16\n            ).to(\"cuda\")\n            pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n            pipe.enable_vae_slicing()\n            pipe.enable_model_cpu_offload()\n\n        except Exception as e:\n            raise RuntimeError('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å AnimateDiff pipeline –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: ' + str(e))\n\n    print('–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∏–º–∞—Ü–∏–∏ (—ç—Ç–æ –∑–∞–π–º–µ—Ç ~3-7 –º–∏–Ω—É—Ç)...')\n\n    start_time = time.time()\n\n    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–∏–º–∞—Ü–∏—é\n    output = pipe(\n        prompt=PROMPT,\n        negative_prompt=NEGATIVE_PROMPT,\n        num_frames=NUM_FRAMES,\n        width=WIDTH,\n        height=HEIGHT,\n        num_inference_steps=STEPS,\n        guidance_scale=CFG_SCALE,\n        generator=torch.Generator(\"cuda\").manual_seed(42)\n    )\n\n    frames = output.frames[0]\n    total_gen_time = time.time() - start_time\n\n    print(f\"\\n‚úÖ –ê–Ω–∏–º–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞ –∑–∞ {total_gen_time:.1f}s!\\n\")\n\n    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä—ã\n    for i, frame in enumerate(frames):\n        frame.save(f\"{FRAMES_DIR}/{i}.png\")\n\n    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤–æ–µ –≤–∏–¥–µ–æ\n    base_video = f\"{WORKSPACE}/ANIMATED_BASE.mp4\"\n    export_to_video(frames, base_video, fps=FPS)\n    print(f\"‚úì –ë–∞–∑–æ–≤–æ–µ –≤–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ ({len(frames)} –∫–∞–¥—Ä–æ–≤, {FPS} fps)\")\n\n    del pipe, adapter\n    torch.cuda.empty_cache()\n\nelse:\n    # === –†–ï–ñ–ò–ú –°–¢–ê–¢–ò–ß–ù–´–• –ö–ê–î–†–û–í ===\n    from diffusers import StableDiffusionXLPipeline\n\n    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–ª–∏ HuggingFace\n    model_path = f\"{DATASET_DIR}/sd_xl_base_1.0.safetensors\"\n\n    if not os.path.exists(model_path):\n        print(\"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º HuggingFace...\")\n        model_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n\n    print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SDXL...\")\n    pipe = StableDiffusionXLPipeline.from_single_file(\n        model_path,\n        torch_dtype=torch.float16,\n        use_safetensors=True\n    ).to(\"cuda\")\n\n    pipe.enable_attention_slicing()\n    pipe.enable_vae_slicing()\n\n    print(\"‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!\\n\")\n\n    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–¥—Ä—ã\n    start_time = time.time()\n    for i in range(NUM_FRAMES):\n        print(f\"–ö–∞–¥—Ä {i+1}/{NUM_FRAMES}...\", end=\" \")\n\n        generator = torch.Generator(device=\"cuda\").manual_seed(42 + i)\n\n        image = pipe(\n            prompt=PROMPT,\n            negative_prompt=NEGATIVE_PROMPT,\n            width=WIDTH,\n            height=HEIGHT,\n            num_inference_steps=STEPS,\n            guidance_scale=CFG_SCALE,\n            generator=generator\n        ).images[0]\n\n        image.save(f\"{FRAMES_DIR}/{i}.png\")\n        print(f\"‚úì ({time.time() - start_time:.1f}s)\")\n\n    total_gen_time = time.time() - start_time\n    print(f\"\\n‚úÖ {NUM_FRAMES} –∫–∞–¥—Ä–æ–≤ –∑–∞ {total_gen_time:.1f}s!\\n\")\n\n    del pipe\n    torch.cuda.empty_cache()\n\nprint(f\"‚úì –ö–∞–¥—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {FRAMES_DIR}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:33:04.989839Z","iopub.execute_input":"2025-10-27T14:33:04.990462Z","iopub.status.idle":"2025-10-27T14:35:05.909622Z","shell.execute_reply.started":"2025-10-27T14:33:04.990444Z","shell.execute_reply":"2025-10-27T14:35:05.908778Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüé® –ì–ï–ù–ï–†–ê–¶–ò–Ø –ê–ù–ò–ú–ê–¶–ò–ò\n============================================================\n\n–ü—Ä–æ–º–ø—Ç: cinematic portrait of gojo satoru, white spiky hair, black blindfold, confident ...\n–†–∞–∑–º–µ—Ä: 512x768, Steps: 25, CFG: 7.5\n–ö–∞–¥—Ä–æ–≤: 16\n\n–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∏–º–∞—Ü–∏–∏ (—ç—Ç–æ –∑–∞–π–º–µ—Ç ~3-7 –º–∏–Ω—É—Ç)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6106de626ae447b4b656567caa267c93"}},"metadata":{}},{"name":"stdout","text":"\n‚úÖ –ê–Ω–∏–º–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞ –∑–∞ 116.5s!\n\n‚úì –ë–∞–∑–æ–≤–æ–µ –≤–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ (16 –∫–∞–¥—Ä–æ–≤, 8 fps)\n‚úì –ö–∞–¥—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: /kaggle/working/frames\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# –Ø—á–µ–π–∫–∞: –∞—Ç–æ–º–∞—Ä–Ω–æ —Å–æ–∑–¥–∞—Ç—å/–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞—Ç—å shim –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–∏–Ω—Ç–∞–∫—Å–∏—Å\nimport os, io, py_compile, traceback\n\nOUT_DIR = \"/kaggle/working/Real-ESRGAN\"\nOUT_PATH = os.path.join(OUT_DIR, \"inference_with_shim_full.py\")\n\nSHIM = \"\"\"import sys, types, os, re, runpy\n\n# Compatibility shim for torchvision.transforms.functional_tensor and torchvision.utils\ntry:\n    import torchvision.transforms.functional_tensor as _ft\nexcept Exception:\n    try:\n        import torchvision.transforms.functional as _f\n        mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\n        mod_ft.rgb_to_grayscale = getattr(_f, 'rgb_to_grayscale', None)\n        mod_ft.convert_image_dtype = getattr(_f, 'convert_image_dtype', None)\n        sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\n    except Exception:\n        # best-effort fallback: create a stub module with conservative placeholders\n        mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\n        def _rgb_to_grayscale(x):\n            raise ImportError('rgb_to_grayscale not available')\n        def _convert_image_dtype(x, dtype):\n            raise ImportError('convert_image_dtype not available')\n        mod_ft.rgb_to_grayscale = _rgb_to_grayscale\n        mod_ft.convert_image_dtype = _convert_image_dtype\n        sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\n\n# Minimal torchvision.utils.make_grid fallback\nif 'torchvision.utils' not in sys.modules:\n    mod_utils = types.ModuleType('torchvision.utils')\n    def make_grid(x, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0):\n        try:\n            if isinstance(x, (list, tuple)) and len(x) > 0:\n                return x[0]\n            return x\n        except Exception:\n            return x\n    mod_utils.make_grid = make_grid\n    sys.modules['torchvision.utils'] = mod_utils\n\n# Provide a minimal realesrgan.version module if missing\nif 'realesrgan.version' not in sys.modules:\n    vermod = types.ModuleType('realesrgan.version')\n    vermod.__version__ = '0.3.0'\n    vermod.__all__ = ['__version__']\n    sys.modules['realesrgan.version'] = vermod\n\n# Helper to infer numeric scale (netscale) from argv\ndef _infer_netscale(argv):\n    for i, a in enumerate(argv):\n        if a in ('-n', '--name', '--model') and i+1 < len(argv):\n            m = re.match(r\"(\\\\d+)x\", argv[i+1])\n            if m:\n                try:\n                    return int(m.group(1))\n                except Exception:\n                    pass\n    for i, a in enumerate(argv):\n        if a in ('-s', '--scale') and i+1 < len(argv):\n            try:\n                return int(argv[i+1])\n            except Exception:\n                pass\n    return 4\n\n# Try to detect a reasonable default model file inside ./weights/\ndef _detect_weight_file():\n    try:\n        wdir = os.path.join(os.getcwd(), 'weights')\n        if not os.path.isdir(wdir):\n            return None\n        exts = ('.pth', '.pt', '.safetensors')\n        candidates = [f for f in os.listdir(wdir) if f.lower().endswith(exts)]\n        if not candidates:\n            return None\n        for name in candidates:\n            if '4x' in name.lower() or 'ultrasharp' in name.lower():\n                return os.path.join(wdir, name)\n        return os.path.join(wdir, candidates[0])\n    except Exception:\n        return None\n\n# Forward to the original inference_realesrgan.py but ensure safe globals are defined\nif __name__ == '__main__':\n    argv = sys.argv[1:]\n    netscale = _infer_netscale(argv)\n\n    # try to detect a local model in ./weights\n    detected_model = _detect_weight_file()\n\n    script_path = os.path.join(os.getcwd(), 'inference_realesrgan.py')\n    try:\n        with open(script_path, 'r', encoding='utf-8') as _f:\n            _code = _f.read()\n    except Exception:\n        # fallback: run by runpy if file cannot be read\n        sys.argv = [script_path] + argv\n        runpy.run_path('inference_realesrgan.py', run_name='__main__')\n    else:\n        _globals = {\n            '__name__': '__main__',\n            '__file__': script_path,\n            'netscale': netscale,\n            'model': detected_model,\n            'outscale': netscale,\n            'scale': netscale,\n        }\n        _globals['sys'] = sys\n        sys.argv = [script_path] + argv\n        exec(compile(_code, script_path, 'exec'), _globals)\n\"\"\"\n\n# --- write atomically ---\ntry:\n    os.makedirs(OUT_DIR, exist_ok=True)\n    tmp_path = OUT_PATH + \".tmp\"\n    with io.open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(SHIM)\n    os.replace(tmp_path, OUT_PATH)\n    print(\"Wrote shim to:\", OUT_PATH)\nexcept Exception as e:\n    print(\"Failed to write shim:\", e)\n    raise\n\n# --- syntax check ---\ntry:\n    py_compile.compile(OUT_PATH, doraise=True)\n    print(\"Syntax check: OK (py_compile passed)\")\nexcept Exception:\n    print(\"Syntax check: FAILED\")\n    traceback.print_exc()\n\n# --- quick preview ---\ntry:\n    with io.open(OUT_PATH, \"r\", encoding=\"utf-8\") as f:\n        head = \"\".join([next(f) for _ in range(40)])  # –ø–µ—Ä–≤—ã–µ 40 —Å—Ç—Ä–æ–∫\n    print(\"--- file head ---\")\n    print(head)\nexcept StopIteration:\n    print(\"--- file is shorter than 40 lines; printed full file ---\")\nexcept Exception as e:\n    print(\"Failed to open/read shim for preview:\", e)\n\nprint(\"Final path exists:\", os.path.exists(OUT_PATH))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:59:58.990529Z","iopub.execute_input":"2025-10-27T14:59:58.991183Z","iopub.status.idle":"2025-10-27T14:59:59.001806Z","shell.execute_reply.started":"2025-10-27T14:59:58.991158Z","shell.execute_reply":"2025-10-27T14:59:59.001073Z"}},"outputs":[{"name":"stdout","text":"Wrote shim to: /kaggle/working/Real-ESRGAN/inference_with_shim_full.py\nSyntax check: OK (py_compile passed)\n--- file head ---\nimport sys, types, os, re, runpy\n\n# Compatibility shim for torchvision.transforms.functional_tensor and torchvision.utils\ntry:\n    import torchvision.transforms.functional_tensor as _ft\nexcept Exception:\n    try:\n        import torchvision.transforms.functional as _f\n        mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\n        mod_ft.rgb_to_grayscale = getattr(_f, 'rgb_to_grayscale', None)\n        mod_ft.convert_image_dtype = getattr(_f, 'convert_image_dtype', None)\n        sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\n    except Exception:\n        # best-effort fallback: create a stub module with conservative placeholders\n        mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\n        def _rgb_to_grayscale(x):\n            raise ImportError('rgb_to_grayscale not available')\n        def _convert_image_dtype(x, dtype):\n            raise ImportError('convert_image_dtype not available')\n        mod_ft.rgb_to_grayscale = _rgb_to_grayscale\n        mod_ft.convert_image_dtype = _convert_image_dtype\n        sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\n\n# Minimal torchvision.utils.make_grid fallback\nif 'torchvision.utils' not in sys.modules:\n    mod_utils = types.ModuleType('torchvision.utils')\n    def make_grid(x, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0):\n        try:\n            if isinstance(x, (list, tuple)) and len(x) > 0:\n                return x[0]\n            return x\n        except Exception:\n            return x\n    mod_utils.make_grid = make_grid\n    sys.modules['torchvision.utils'] = mod_utils\n\n# Provide a minimal realesrgan.version module if missing\nif 'realesrgan.version' not in sys.modules:\n    vermod = types.ModuleType('realesrgan.version')\n    vermod.__version__ = '0.3.0'\n\nFinal path exists: True\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# === UPSCALE –° REAL-ESRGAN (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) ===\nprint_separator()\nprint(\"üìà –ê–ü–°–ö–ï–ô–õ –ö–ê–î–†–û–í –° REAL-ESRGAN\")\nprint_separator(nl_before=False)\n\n# === CELL 1: minimal guards (idempotent when run separately) ===\nimport os, sys, shutil, subprocess\nif 'WORKSPACE' not in globals():\n    WORKSPACE = os.getcwd()\n    print(f\"‚ö†Ô∏è WORKSPACE not set ‚Äî using {WORKSPACE}\")\nif 'FRAMES_DIR' not in globals():\n    FRAMES_DIR = f\"{WORKSPACE}/frames\"\n    print(f\"‚ö†Ô∏è FRAMES_DIR not set ‚Äî using {FRAMES_DIR}\")\nif 'DATASET_DIR' not in globals():\n    DATASET_DIR = f\"{WORKSPACE}/dataset\"\n    print(f\"‚ö†Ô∏è DATASET_DIR not set ‚Äî using {DATASET_DIR}\")\n\nos.makedirs(FRAMES_DIR, exist_ok=True)\nos.makedirs(DATASET_DIR, exist_ok=True)\n\nUPSCALE_MODEL_NAME = globals().get('UPSCALE_MODEL_NAME', '4x-UltraSharp.pth')\nupscale_model = f\"{DATASET_DIR}/{UPSCALE_MODEL_NAME}\"\nprint('upscale_model =', upscale_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:05.910745Z","iopub.execute_input":"2025-10-27T14:35:05.911667Z","iopub.status.idle":"2025-10-27T14:35:05.919745Z","shell.execute_reply.started":"2025-10-27T14:35:05.911637Z","shell.execute_reply":"2025-10-27T14:35:05.918979Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nüìà –ê–ü–°–ö–ï–ô–õ –ö–ê–î–†–û–í –° REAL-ESRGAN\n============================================================\n\nupscale_model = /kaggle/input/comfyui-models-gojo/4x-UltraSharp.pth\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# === CELL 2: repo check & optional clone ===\nREPO_DIR = os.path.join(WORKSPACE, 'Real-ESRGAN')\nprint('REPO_DIR =', REPO_DIR)\nif os.path.exists(upscale_model):\n    print('Upscale model found at', upscale_model)\n    if not os.path.exists(REPO_DIR):\n        print('Cloning Real-ESRGAN into', REPO_DIR)\n        try:\n            subprocess.check_call(['git', 'clone', 'https://github.com/xinntao/Real-ESRGAN', REPO_DIR])\n            print('Clone OK')\n        except Exception as e:\n            print('‚ö†Ô∏è Clone failed:', e)\nelse:\n    print('Upscale model not present ‚Äî to run upscale place model at', upscale_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:05.922711Z","iopub.execute_input":"2025-10-27T14:35:05.922903Z","iopub.status.idle":"2025-10-27T14:35:05.936527Z","shell.execute_reply.started":"2025-10-27T14:35:05.922888Z","shell.execute_reply":"2025-10-27T14:35:05.935852Z"}},"outputs":[{"name":"stdout","text":"REPO_DIR = /kaggle/working/Real-ESRGAN\nUpscale model found at /kaggle/input/comfyui-models-gojo/4x-UltraSharp.pth\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# === CELL 3: chdir to repo and prepare logs/install_cmd ===\nif os.path.exists(REPO_DIR):\n    os.chdir(REPO_DIR)\n    print('CWD ->', os.getcwd())\nelse:\n    print('Repo not present; skipping chdir')\n\nLOG_DIR = os.path.join(WORKSPACE, 'logs')\nos.makedirs(LOG_DIR, exist_ok=True)\nINSTALL_LOG = os.path.join(LOG_DIR, 'real_esrgan_install.log')\nINFERENCE_LOG = os.path.join(LOG_DIR, 'real_esrgan_inference.log')\ninstall_cmd = [sys.executable, '-m', 'pip', 'install', '--upgrade', 'torchvision', '-f', 'https://download.pytorch.org/whl/torch_stable.html']\nprint('INFERENCE_LOG =', INFERENCE_LOG)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:05.937118Z","iopub.execute_input":"2025-10-27T14:35:05.937376Z","iopub.status.idle":"2025-10-27T14:35:05.946429Z","shell.execute_reply.started":"2025-10-27T14:35:05.937354Z","shell.execute_reply":"2025-10-27T14:35:05.945814Z"}},"outputs":[{"name":"stdout","text":"CWD -> /kaggle/working/Real-ESRGAN\nINFERENCE_LOG = /kaggle/working/logs/real_esrgan_inference.log\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# === CELL 4a: build src_candidates list ===\nsrc_candidates = []\nif 'upscale_model' in globals() and upscale_model:\n    src_candidates.append(upscale_model)\nsrc_candidates.append(os.path.join(DATASET_DIR, UPSCALE_MODEL_NAME))\nsrc_candidates.append(os.path.join(WORKSPACE, 'dataset', UPSCALE_MODEL_NAME))\nsrc_candidates.append(os.path.join(WORKSPACE, 'models', UPSCALE_MODEL_NAME))\nprint('src_candidates:')\nfor p in src_candidates:\n    print(' -', p)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:05.947011Z","iopub.execute_input":"2025-10-27T14:35:05.947182Z","iopub.status.idle":"2025-10-27T14:35:05.958259Z","shell.execute_reply.started":"2025-10-27T14:35:05.947169Z","shell.execute_reply":"2025-10-27T14:35:05.957649Z"}},"outputs":[{"name":"stdout","text":"src_candidates:\n - /kaggle/input/comfyui-models-gojo/4x-UltraSharp.pth\n - /kaggle/input/comfyui-models-gojo/4x-UltraSharp.pth\n - /kaggle/working/dataset/4x-UltraSharp.pth\n - /kaggle/working/models/4x-UltraSharp.pth\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# === CELL 4b: copy first existing candidate into weights/ ===\nif os.path.exists(REPO_DIR) and src_candidates:\n    try:\n        weights_dir = os.path.join(os.getcwd(), 'weights')\n        os.makedirs(weights_dir, exist_ok=True)\n        copied = False\n        for src in src_candidates:\n            try:\n                if src and os.path.exists(src):\n                    shutil.copy(src, weights_dir)\n                    print('Copied', src, '->', weights_dir)\n                    copied = True\n                    break\n            except Exception as _e:\n                print('Warning copying', src, ':', _e)\n        if not copied:\n            print('No candidate found to copy into weights')\n    except Exception as e:\n        print('‚ö†Ô∏è Error preparing weights:', e)\nelse:\n    print('Skipping weights copy (repo or candidates missing)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:05.959017Z","iopub.execute_input":"2025-10-27T14:35:05.959276Z","iopub.status.idle":"2025-10-27T14:35:11.490792Z","shell.execute_reply.started":"2025-10-27T14:35:05.959255Z","shell.execute_reply":"2025-10-27T14:35:11.490001Z"}},"outputs":[{"name":"stdout","text":"Copied /kaggle/input/comfyui-models-gojo/4x-UltraSharp.pth -> /kaggle/working/Real-ESRGAN/weights\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# === CELL 5a: candidate_shims list ===\ncandidate_shims = [\n    os.path.join(WORKSPACE, 'tmp_inference_shim.py'),\n    os.path.join(os.getcwd(), 'tmp_inference_shim.py'),\n    os.path.join('/kaggle/working', 'tmp_inference_shim.py'),\n    os.path.join('/apps/ComfyCloud_My_Work_Flow', 'tmp_inference_shim.py'),\n]\nprint('candidate_shims:')\nfor c in candidate_shims:\n    print(' -', c)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.491646Z","iopub.execute_input":"2025-10-27T14:35:11.492035Z","iopub.status.idle":"2025-10-27T14:35:11.496819Z","shell.execute_reply.started":"2025-10-27T14:35:11.492017Z","shell.execute_reply":"2025-10-27T14:35:11.496138Z"}},"outputs":[{"name":"stdout","text":"candidate_shims:\n - /kaggle/working/tmp_inference_shim.py\n - /kaggle/working/Real-ESRGAN/tmp_inference_shim.py\n - /kaggle/working/tmp_inference_shim.py\n - /apps/ComfyCloud_My_Work_Flow/tmp_inference_shim.py\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# === CELL 5b: try copy prepared shim ===\nshim_path = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\nwrote = False\nfor c in candidate_shims:\n    try:\n        if c and os.path.exists(c):\n            shutil.copy(c, shim_path)\n            wrote = os.path.exists(shim_path)\n            print('Copied shim from', c)\n            break\n    except Exception as e:\n        print('Failed to copy shim from', c, ':', e)\nprint('shim_path exists:', os.path.exists(shim_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.497611Z","iopub.execute_input":"2025-10-27T14:35:11.498395Z","iopub.status.idle":"2025-10-27T14:35:11.514319Z","shell.execute_reply.started":"2025-10-27T14:35:11.498377Z","shell.execute_reply":"2025-10-27T14:35:11.513582Z"}},"outputs":[{"name":"stdout","text":"shim_path exists: True\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# === CELL 6a: build shim content (parts) ===\nshim_lines_part1 = 'import sys, os, runpy, types, re'\nshim_lines_part2 = '# Minimal compatibility shim: define netscale/model/outscale and exec the original script'\nshim_lines_part3 = 'def _infer_netscale(argv):'\nshim_lines_part4 = '    for i,a in enumerate(argv):'\nprint('shim parts defined')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.515159Z","iopub.execute_input":"2025-10-27T14:35:11.515384Z","iopub.status.idle":"2025-10-27T14:35:11.523870Z","shell.execute_reply.started":"2025-10-27T14:35:11.515369Z","shell.execute_reply":"2025-10-27T14:35:11.523144Z"}},"outputs":[{"name":"stdout","text":"shim parts defined\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# === CELL 6b: compose shim_lines and write shim file (if needed) ===\nif (not os.path.exists(shim_path)) and os.path.exists(REPO_DIR):\n    shim_code = \"\"\"import sys, os, runpy, types, re\n# Minimal compatibility shim: define netscale/model/outscale and exec the original script\ndef _infer_netscale(argv):\n    import re\n    for i, a in enumerate(argv):\n        if a in ('-n','--name','--model') and i+1 < len(argv):\n            m = re.match(r\"(\\\\d+)x\", argv[i+1])\n            if m:\n                try:\n                    return int(m.group(1))\n                except Exception:\n                    pass\n    for i, a in enumerate(argv):\n        if a in ('-s','--scale') and i+1 < len(argv):\n            try:\n                return int(argv[i+1])\n            except Exception:\n                pass\n    return 4\n\nif __name__ == '__main__':\n    argv = sys.argv[1:]\n    netscale = _infer_netscale(argv)\n    script_path = os.path.join(os.getcwd(), 'inference_realesrgan.py')\n    try:\n        with open(script_path, 'r', encoding='utf-8') as f:\n            code = f.read()\n    except Exception:\n        sys.argv = [script_path] + argv\n        runpy.run_path('inference_realesrgan.py', run_name='__main__')\n    else:\n        _globals = {'__name__':'__main__', '__file__':script_path, 'netscale':netscale, 'model':None, 'outscale':netscale, 'scale':netscale}\n        _globals['sys'] = sys\n        sys.argv = [script_path] + argv\n        exec(compile(code, script_path, 'exec'), _globals)\n\"\"\"\n    try:\n        with open(shim_path, 'w', encoding='utf-8') as sf:\n            sf.write(shim_code)\n        wrote = os.path.exists(shim_path)\n        if wrote:\n            print(f\"Wrote minimal shim to {shim_path}\")\n    except Exception as _w_e:\n        print(f\"WARNING: failed to write shim at {shim_path}: {_w_e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:36:19.508476Z","iopub.execute_input":"2025-10-27T14:36:19.509054Z","iopub.status.idle":"2025-10-27T14:36:19.513997Z","shell.execute_reply.started":"2025-10-27T14:36:19.509031Z","shell.execute_reply":"2025-10-27T14:36:19.513409Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# === CELL 7a: construct fallback safe_argv & args_literal ===\nsafe_argv = ['-n','4x-UltraSharp','-i', FRAMES_DIR, '-o', FRAMES_DIR + '_upscaled', '--fp32', '--outscale', '4']\nargs_literal = '[' + ','.join(repr(a) for a in safe_argv) + ']'\nprint('safe_argv ->', safe_argv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:57:29.713907Z","iopub.execute_input":"2025-10-27T14:57:29.714418Z","iopub.status.idle":"2025-10-27T14:57:29.719116Z","shell.execute_reply.started":"2025-10-27T14:57:29.714394Z","shell.execute_reply":"2025-10-27T14:57:29.718400Z"}},"outputs":[{"name":"stdout","text":"safe_argv -> ['-n', '4x-UltraSharp', '-i', '/kaggle/working/frames', '-o', '/kaggle/working/frames_upscaled', '--fp32', '--outscale', '4']\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# === CELL 7b: build run_cmd (shim vs fallback) ‚Äî inspect but don't run ===\nrun_cmd = None\nif os.path.exists(REPO_DIR):\n    shim_path = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\n    if os.path.exists(shim_path):\n        run_cmd = [sys.executable, shim_path, '-n','4x-UltraSharp','-i',FRAMES_DIR,'-o',FRAMES_DIR + '_upscaled','--fp32','--outscale','4']\n    else:\n        pycmd = (\n            \"import runpy,sys,os,re; argv=\" + args_literal + \"; sys.argv=[os.path.join(os.getcwd(),'inference_realesrgan.py')]+argv; \"\n            \"def _infer(argv):\\n    import re\\n    for i,a in enumerate(argv):\\n        if a in ('-n','--name','--model') and i+1<len(argv):\\n            m=re.match(r'(\\\\d+)x',argv[i+1]);\\n            if m: return int(m.group(1))\\n    for i,a in enumerate(argv):\\n        if a in ('-s','--scale') and i+1<len(argv):\\n            try: return int(argv[i+1])\\n            except: pass\\n    return 4\\n\"\n            \"netscale=_infer(argv)\\nrunpy.run_path('inference_realesrgan.py', run_name='__main__')\"\n        )\n        run_cmd = [sys.executable, '-c', pycmd]\nprint('Prepared run_cmd:')\nprint(run_cmd)\nprint('\\nWhen ready ‚Äî run the next cell to execute inference.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:57:42.934379Z","iopub.execute_input":"2025-10-27T14:57:42.934914Z","iopub.status.idle":"2025-10-27T14:57:42.940318Z","shell.execute_reply.started":"2025-10-27T14:57:42.934894Z","shell.execute_reply":"2025-10-27T14:57:42.939616Z"}},"outputs":[{"name":"stdout","text":"Prepared run_cmd:\n['/usr/bin/python3', '/kaggle/working/Real-ESRGAN/inference_with_shim_full.py', '-n', '4x-UltraSharp', '-i', '/kaggle/working/frames', '-o', '/kaggle/working/frames_upscaled', '--fp32', '--outscale', '4']\n\nWhen ready ‚Äî run the next cell to execute inference.\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# === CELL 8: execute run_cmd (inference) ‚Äî run only after inspection ===\nif run_cmd is None:\n    print('run_cmd undefined ‚Äî build it first (previous cell)')\nelse:\n    print('Running:', run_cmd)\n    try:\n        res = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600)\n    except Exception as e:\n        print('Failed to run subprocess:', e)\n        res = None\n    if res is not None:\n        try:\n            with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                lf.write('=== STDOUT ===\\n')\n                lf.write(res.stdout or '')\n                lf.write('\\n=== STDERR ===\\n')\n                lf.write(res.stderr or '')\n        except Exception:\n            pass\n        print('Return code =', getattr(res,'returncode',None))\n        if res.returncode == 0:\n            print('‚úì Inference completed ‚Äî see', INFERENCE_LOG)\n        else:\n            print('‚úó Inference failed ‚Äî see', INFERENCE_LOG)\n            globals()['last_inference_stderr'] = res.stderr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:57:47.509564Z","iopub.execute_input":"2025-10-27T14:57:47.510209Z","iopub.status.idle":"2025-10-27T14:57:51.919996Z","shell.execute_reply.started":"2025-10-27T14:57:47.510186Z","shell.execute_reply":"2025-10-27T14:57:51.919382Z"}},"outputs":[{"name":"stdout","text":"Running: ['/usr/bin/python3', '/kaggle/working/Real-ESRGAN/inference_with_shim_full.py', '-n', '4x-UltraSharp', '-i', '/kaggle/working/frames', '-o', '/kaggle/working/frames_upscaled', '--fp32', '--outscale', '4']\nReturn code = 1\n‚úó Inference failed ‚Äî see /kaggle/working/logs/real_esrgan_inference.log\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# === CELL 9a: If stderr mentions functional_tensor ‚Äî prepare minimal stub strings ===\n# (define strings separately so user can inspect before writing)\nif 'last_inference_stderr' in globals():\n    _stderr_preview = (globals().get('last_inference_stderr') or '').lower()\nelse:\n    _stderr_preview = ''\nprint('stderr preview contains functional_tensor:', 'functional_tensor' in _stderr_preview)\n\n# Prepare stub strings (do not write yet)\ntv_init = \"\"\"# Minimal stub torchvision package for Real-ESRGAN/basicsr compatibility\nfrom . import utils\nfrom . import transforms\n__all__ = ['utils','transforms']\n\"\"\"\n\nutils_code = \"\"\"# Minimal stub for torchvision.utils.make_grid\ntry:\n    from torchvision.utils import make_grid as _make_grid\n    def make_grid(tensor, nrow=8, padding=2, normalize=False):\n        return _make_grid(tensor, nrow=nrow, padding=padding, normalize=normalize)\nexcept Exception:\n    import numpy as _np\n    from PIL import Image as _Image\n    import torch as _torch\n    def make_grid(tensor, nrow=8, padding=2, normalize=False):\n        if isinstance(tensor, (list, tuple)):\n            tensor = _torch.stack(tensor, dim=0)\n        if not isinstance(tensor, _torch.Tensor):\n            raise TypeError('Fallback make_grid expects a torch.Tensor or list of tensors')\n        t = tensor.detach().cpu()\n        if t.dim() == 3:\n            t = t.unsqueeze(0)\n        B,C,H,W = t.shape\n        if normalize:\n            t = (t - t.min()) / (t.max() - t.min() + 1e-8)\n        else:\n            if t.max() > 50:\n                t = t / 255.0\n        def to_uint8(x):\n            arr = (x.numpy().transpose(1,2,0) * 255.0).clip(0,255).astype(_np.uint8)\n            if arr.shape[2] == 1:\n                arr = _np.repeat(arr, 3, axis=2)\n            return _Image.fromarray(arr)\n        imgs = [to_uint8(t[i]) for i in range(B)]\n        rows = (B + nrow - 1) // nrow\n        grid_h = rows * H + padding * (rows - 1)\n        grid_w = nrow * W + padding * (nrow - 1)\n        grid = _Image.new('RGB', (grid_w, grid_h), (0,0,0))\n        for idx, img in enumerate(imgs):\n            r = idx // nrow\n            c = idx % nrow\n            grid.paste(img, (c * (W + padding), r * (H + padding)))\n        arr = _np.array(grid).transpose(2,0,1).astype(_np.float32) / 255.0\n        return _torch.from_numpy(arr)\n\"\"\"\n\ntr_init = \"\"\"# transforms package stub\nfrom . import functional_tensor\n__all__ = ['functional_tensor']\n\"\"\"\n\nfunc_code = \"\"\"# Auto-generated stub: try to import the real functional_tensor, otherwise delegate to torchvision.transforms.functional\ntry:\n    from torchvision.transforms.functional_tensor import *  # type: ignore\nexcept Exception:\n    try:\n        from torchvision.transforms import functional as _f\n    except Exception:\n        def rgb_to_grayscale(x):\n            raise ImportError('rgb_to_grayscale not available in this environment')\n        def convert_image_dtype(x, dtype):\n            raise ImportError('convert_image_dtype not available in this environment')\n    else:\n        rgb_to_grayscale = getattr(_f, 'rgb_to_grayscale', None)\n        convert_image_dtype = getattr(_f, 'convert_image_dtype', None)\n    __all__ = [n for n in ('rgb_to_grayscale','convert_image_dtype') if globals().get(n) is not None]\n\"\"\"\n\nprint('Prepared stub strings (not written yet)')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.681023Z","iopub.execute_input":"2025-10-27T14:35:11.681372Z","iopub.status.idle":"2025-10-27T14:35:11.687716Z","shell.execute_reply.started":"2025-10-27T14:35:11.681347Z","shell.execute_reply":"2025-10-27T14:35:11.687065Z"}},"outputs":[{"name":"stdout","text":"stderr preview contains functional_tensor: False\nPrepared stub strings (not written yet)\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# === CELL 9b: write stub files and retry run_cmd with PYTHONPATH adjusted ===\nif 'functional_tensor' in _stderr_preview or 'functional_tensor' in (tail(INFERENCE_LOG, 50) or '').lower():\n    try:\n        stub_root = os.path.join(WORKSPACE, 'torchvision_stub')\n        torchvision_pkg = os.path.join(stub_root, 'torchvision')\n        transforms_pkg = os.path.join(torchvision_pkg, 'transforms')\n        shutil.rmtree(stub_root, ignore_errors=True)\n        os.makedirs(transforms_pkg, exist_ok=True)\n\n        with open(os.path.join(torchvision_pkg, '__init__.py'), 'w', encoding='utf-8') as f_init:\n            f_init.write(tv_init)\n        with open(os.path.join(torchvision_pkg, 'utils.py'), 'w', encoding='utf-8') as f_utils:\n            f_utils.write(utils_code)\n        with open(os.path.join(transforms_pkg, '__init__.py'), 'w', encoding='utf-8') as f_tr:\n            f_tr.write(tr_init)\n        with open(os.path.join(transforms_pkg, 'functional_tensor.py'), 'w', encoding='utf-8') as f_ft:\n            f_ft.write(func_code)\n\n        env = os.environ.copy()\n        prev_pp = env.get('PYTHONPATH', '')\n        env['PYTHONPATH'] = stub_root + (os.pathsep + prev_pp if prev_pp else '')\n\n        print('Running run_cmd with stub PYTHONPATH...')\n        if run_cmd is None:\n            print('run_cmd undefined ‚Äî cannot retry')\n        else:\n            res_stub = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600, env=env)\n            print('Stub attempt returncode:', getattr(res_stub,'returncode',None))\n            try:\n                with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                    lf.write('\\n=== STUB SUBPROCESS STDOUT ===\\n')\n                    lf.write(res_stub.stdout or '')\n                    lf.write('\\n=== STUB SUBPROCESS STDERR ===\\n')\n                    lf.write(res_stub.stderr or '')\n            except Exception:\n                pass\n            if res_stub.returncode == 0:\n                print('‚úì Inference completed using local stub; see', INFERENCE_LOG)\n            else:\n                print('Stub attempt failed with code', res_stub.returncode)\n                print('Attempting editable install of Real-ESRGAN package then torchvision install and retry...')\n                try:\n                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                        lf.write('\\n=== Ensuring Real-ESRGAN package is installed (editable) ===\\n')\n                except Exception:\n                    pass\n                try:\n                    res_pkg = subprocess.run([sys.executable, '-m', 'pip', 'install', '-e', '.'], capture_output=True, text=True, timeout=900)\n                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                        lf.write('\\n=== PKG INSTALL STDOUT ===\\n')\n                        lf.write(res_pkg.stdout or '')\n                        lf.write('\\n=== PKG INSTALL STDERR ===\\n')\n                        lf.write(res_pkg.stderr or '')\n                except Exception as _pkg_e:\n                    print('Editable install failed:', _pkg_e)\n\n                try:\n                    res_install = subprocess.run(install_cmd, capture_output=True, text=True, timeout=900)\n                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                        lf.write('\\n=== TORCHVISION INSTALL STDOUT ===\\n')\n                        lf.write(res_install.stdout or '')\n                        lf.write('\\n=== TORCHVISION INSTALL STDERR ===\\n')\n                        lf.write(res_install.stderr or '')\n                except Exception as _ie:\n                    print('torchvision install failed:', _ie)\n                    res_install = None\n\n                if res_install and res_install.returncode == 0:\n                    print('torchvision installed; retrying inference (with stub PYTHONPATH)')\n                    res2 = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600, env=env)\n                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                        lf.write('\\n=== RETRY STDOUT ===\\n')\n                        lf.write(res2.stdout or '')\n                        lf.write('\\n=== RETRY STDERR ===\\n')\n                        lf.write(res2.stderr or '')\n                    if res2.returncode == 0:\n                        print('‚úì Real-ESRGAN inference completed after installing torchvision; see', INFERENCE_LOG)\n                    else:\n                        print('Retry also failed ‚Äî see', INFERENCE_LOG)\n                else:\n                    print('Could not install torchvision ‚Äî see', INFERENCE_LOG)\n    except Exception as e:\n        print('Exception during stub/install/retry:', e)\nelse:\n    print('No functional_tensor error detected in stderr tail ‚Äî skip stub flow')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.688519Z","iopub.execute_input":"2025-10-27T14:35:11.688772Z","iopub.status.idle":"2025-10-27T14:35:11.951704Z","shell.execute_reply.started":"2025-10-27T14:35:11.688750Z","shell.execute_reply":"2025-10-27T14:35:11.950473Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/1071473925.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# === CELL 9b: write stub files and retry run_cmd with PYTHONPATH adjusted ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;34m'functional_tensor'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_stderr_preview\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'functional_tensor'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFERENCE_LOG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mstub_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORKSPACE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'torchvision_stub'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtorchvision_pkg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstub_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'torchvision'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tail' is not defined"],"ename":"NameError","evalue":"name 'tail' is not defined","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"# === CELL 10: final move/rename upscaled frames into FRAMES_DIR (if present) ===\ntry:\n    if os.path.exists(FRAMES_DIR + '_upscaled'):\n        print('Moving upscaled frames into', FRAMES_DIR)\n        shutil.rmtree(FRAMES_DIR, ignore_errors=True)\n        shutil.move(FRAMES_DIR + '_upscaled', FRAMES_DIR)\n        import glob\n        upscaled_files = sorted(glob.glob(f\"{FRAMES_DIR}/*_out.png\"))\n        for i, filepath in enumerate(upscaled_files):\n            try:\n                os.rename(filepath, f\"{FRAMES_DIR}/{i}.png\")\n            except Exception:\n                pass\n        print('‚úì Upscaled frames moved/renamed')\n    else:\n        print('No upscaled frames dir found ‚Äî nothing to move')\nexcept Exception as e:\n    print('Error while moving/renaming upscaled frames:', e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.952104Z","iopub.status.idle":"2025-10-27T14:35:11.952321Z","shell.execute_reply.started":"2025-10-27T14:35:11.952201Z","shell.execute_reply":"2025-10-27T14:35:11.952210Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === UPSCALE –° REAL-ESRGAN (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) ===\nprint_separator()\nprint(\"üìà –ê–ü–°–ö–ï–ô–õ –ö–ê–î–†–û–í –° REAL-ESRGAN\")\nprint_separator(nl_before=False)\n\n# === CELL 1: minimal guards (idempotent when run separately) ===\nimport os, sys, shutil, subprocess\nif 'WORKSPACE' not in globals():\n    WORKSPACE = os.getcwd()\n    print(f\"‚ö†Ô∏è WORKSPACE not set ‚Äî using {WORKSPACE}\")\nif 'FRAMES_DIR' not in globals():\n    FRAMES_DIR = f\"{WORKSPACE}/frames\"\n    print(f\"‚ö†Ô∏è FRAMES_DIR not set ‚Äî using {FRAMES_DIR}\")\nif 'DATASET_DIR' not in globals():\n    DATASET_DIR = f\"{WORKSPACE}/dataset\"\n    print(f\"‚ö†Ô∏è DATASET_DIR not set ‚Äî using {DATASET_DIR}\")\n\nos.makedirs(FRAMES_DIR, exist_ok=True)\nos.makedirs(DATASET_DIR, exist_ok=True)\n\nUPSCALE_MODEL_NAME = globals().get('UPSCALE_MODEL_NAME', '4x-UltraSharp.pth')\nupscale_model = f\"{DATASET_DIR}/{UPSCALE_MODEL_NAME}\"\nprint('upscale_model =', upscale_model)\n\n# === CELL 2: repo check & optional clone ===\nREPO_DIR = os.path.join(WORKSPACE, 'Real-ESRGAN')\nprint('REPO_DIR =', REPO_DIR)\nif os.path.exists(upscale_model):\n    print('Upscale model found at', upscale_model)\n    if not os.path.exists(REPO_DIR):\n        print('Cloning Real-ESRGAN into', REPO_DIR)\n        try:\n            subprocess.check_call(['git', 'clone', 'https://github.com/xinntao/Real-ESRGAN', REPO_DIR])\n            print('Clone OK')\n        except Exception as e:\n            print('‚ö†Ô∏è Clone failed:', e)\nelse:\n    print('Upscale model not present ‚Äî to run upscale place model at', upscale_model)\n\n# === CELL 3: chdir to repo and prepare logs/install_cmd ===\nif os.path.exists(REPO_DIR):\n    os.chdir(REPO_DIR)\n    print('CWD ->', os.getcwd())\nelse:\n    print('Repo not present; skipping chdir')\n\nLOG_DIR = os.path.join(WORKSPACE, 'logs')\nos.makedirs(LOG_DIR, exist_ok=True)\nINSTALL_LOG = os.path.join(LOG_DIR, 'real_esrgan_install.log')\nINFERENCE_LOG = os.path.join(LOG_DIR, 'real_esrgan_inference.log')\ninstall_cmd = [sys.executable, '-m', 'pip', 'install', '--upgrade', 'torchvision', '-f', 'https://download.pytorch.org/whl/torch_stable.html']\nprint('INFERENCE_LOG =', INFERENCE_LOG)\n\n# === CELL 4a: build src_candidates list ===\nsrc_candidates = []\nif 'upscale_model' in globals() and upscale_model:\n    src_candidates.append(upscale_model)\nsrc_candidates.append(os.path.join(DATASET_DIR, UPSCALE_MODEL_NAME))\nsrc_candidates.append(os.path.join(WORKSPACE, 'dataset', UPSCALE_MODEL_NAME))\nsrc_candidates.append(os.path.join(WORKSPACE, 'models', UPSCALE_MODEL_NAME))\nprint('src_candidates:')\nfor p in src_candidates:\n    print(' -', p)\n\n# === CELL 4b: copy first existing candidate into weights/ ===\nif os.path.exists(REPO_DIR) and src_candidates:\n    try:\n        weights_dir = os.path.join(os.getcwd(), 'weights')\n        os.makedirs(weights_dir, exist_ok=True)\n        copied = False\n        for src in src_candidates:\n            try:\n                if src and os.path.exists(src):\n                    shutil.copy(src, weights_dir)\n                    print('Copied', src, '->', weights_dir)\n                    copied = True\n                    break\n            except Exception as _e:\n                print('Warning copying', src, ':', _e)\n        if not copied:\n            print('No candidate found to copy into weights')\n    except Exception as e:\n        print('‚ö†Ô∏è Error preparing weights:', e)\nelse:\n    print('Skipping weights copy (repo or candidates missing)')\n\n# === CELL 5a: candidate_shims list ===\ncandidate_shims = [\n    os.path.join(WORKSPACE, 'tmp_inference_shim.py'),\n    os.path.join(os.getcwd(), 'tmp_inference_shim.py'),\n    os.path.join('/kaggle/working', 'tmp_inference_shim.py'),\n    os.path.join('/apps/ComfyCloud_My_Work_Flow', 'tmp_inference_shim.py'),\n]\nprint('candidate_shims:')\nfor c in candidate_shims:\n    print(' -', c)\n\n# === CELL 5b: try copy prepared shim ===\nshim_path = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\nwrote = False\nfor c in candidate_shims:\n    try:\n        if c and os.path.exists(c):\n            shutil.copy(c, shim_path)\n            wrote = os.path.exists(shim_path)\n            print('Copied shim from', c)\n            break\n    except Exception as e:\n        print('Failed to copy shim from', c, ':', e)\nprint('shim_path exists:', os.path.exists(shim_path))\n\n# === CELL 6a: build shim content (parts) ===\nshim_lines_part1 = 'import sys, os, runpy, types, re'\nshim_lines_part2 = '# Minimal compatibility shim: define netscale/model/outscale and exec the original script'\nshim_lines_part3 = 'def _infer_netscale(argv):'\nshim_lines_part4 = '    for i,a in enumerate(argv):'\nprint('shim parts defined')\n\n# === CELL 6b: compose shim_lines and write shim file (if needed) ===\nif (not os.path.exists(shim_path)) and os.path.exists(REPO_DIR):\n    shim_lines = [\n        shim_lines_part1,\n        shim_lines_part2,\n        shim_lines_part3,\n        shim_lines_part4,\n        \"    if a in ('-n','--name','--model') and i+1<len(argv):\",\n        \"        m = re.match(r'(\\\\d+)x', argv[i+1])\",\n        \"        if m:\",\n        \"            try: return int(m.group(1))\\\\n            except: pass\",\n        \"    for i,a in enumerate(argv):\",\n        \"        if a in ('-s','--scale') and i+1<len(argv):\",\n        \"            try: return int(argv[i+1])\\\\n            except: pass\",\n        \"    return 4\",\n        \"if __name__ == '__main__':\",\n        \"    argv = sys.argv[1:]\",\n        \"    netscale = _infer_netscale(argv)\",\n        \"    script_path = os.path.join(os.getcwd(), 'inference_realesrgan.py')\",\n        \"    try:\",\n        \"        with open(script_path, 'r', encoding='utf-8') as f:\",\n        \"            code = f.read()\",\n        \"    except Exception:\",\n        \"        sys.argv = [script_path] + argv\",\n        \"        runpy.run_path('inference_realesrgan.py', run_name='__main__')\",\n        \"    else:\",\n        \"        _globals = {'__name__':'__main__', '__file__':script_path, 'netscale':netscale, 'model':None, 'outscale':netscale, 'scale':netscale}\",\n        \"        _globals['sys'] = sys\",\n        \"        sys.argv = [script_path] + argv\",\n        \"        exec(compile(code, script_path, 'exec'), _globals)\",\n    ]\n    try:\n        with open(shim_path, 'w', encoding='utf-8') as sf:\n            sf.write('\\n'.join(shim_lines))\n        wrote = os.path.exists(shim_path)\n        if wrote:\n            print('Wrote shim to', shim_path)\n    except Exception as e:\n        print('Warning: failed to write shim:', e)\nelse:\n    print('Shim exists or repo missing; shim_path exists =', os.path.exists(shim_path))\n\n# === CELL 7a: construct fallback safe_argv & args_literal ===\nsafe_argv = ['-n','4x-UltraSharp','-i', FRAMES_DIR, '-o', FRAMES_DIR + '_upscaled', '--fp32', '--outscale', '4']\nargs_literal = '[' + ','.join(repr(a) for a in safe_argv) + ']'\nprint('safe_argv ->', safe_argv)\n\n# === CELL 7b: build run_cmd (shim vs fallback) ‚Äî inspect but don't run ===\nrun_cmd = None\nif os.path.exists(REPO_DIR):\n    shim_path = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\n    if os.path.exists(shim_path):\n        run_cmd = [sys.executable, shim_path, '-n','4x-UltraSharp','-i',FRAMES_DIR,'-o',FRAMES_DIR + '_upscaled','--fp32','--outscale','4']\n    else:\n        pycmd = (\n            \"import runpy,sys,os,re; argv=\" + args_literal + \"; sys.argv=[os.path.join(os.getcwd(),'inference_realesrgan.py')]+argv; \"\n            \"def _infer(argv):\\n    import re\\n    for i,a in enumerate(argv):\\n        if a in ('-n','--name','--model') and i+1<len(argv):\\n            m=re.match(r'(\\\\d+)x',argv[i+1]);\\n            if m: return int(m.group(1))\\n    for i,a in enumerate(argv):\\n        if a in ('-s','--scale') and i+1<len(argv):\\n            try: return int(argv[i+1])\\n            except: pass\\n    return 4\\n\"\n            \"netscale=_infer(argv)\\nrunpy.run_path('inference_realesrgan.py', run_name='__main__')\"\n        )\n        run_cmd = [sys.executable, '-c', pycmd]\nprint('Prepared run_cmd:')\nprint(run_cmd)\nprint('\\nWhen ready ‚Äî run the next cell to execute inference.')\n\n# === CELL 8: execute run_cmd (inference) ‚Äî run only after inspection ===\nif run_cmd is None:\n    print('run_cmd undefined ‚Äî build it first (previous cell)')\nelse:\n    print('Running:', run_cmd)\n    try:\n        res = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600)\n    except Exception as e:\n        print('Failed to run subprocess:', e)\n        res = None\n    if res is not None:\n        try:\n            with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                lf.write('=== STDOUT ===\\n')\n                lf.write(res.stdout or '')\n                lf.write('\\n=== STDERR ===\\n')\n                lf.write(res.stderr or '')\n        except Exception:\n            pass\n        print('Return code =', getattr(res,'returncode',None))\n        if res.returncode == 0:\n            print('‚úì Inference completed ‚Äî see', INFERENCE_LOG)\n        else:\n            print('‚úó Inference failed ‚Äî see', INFERENCE_LOG)\n            globals()['last_inference_stderr'] = res.stderr\n\n# === CELL 9a: If stderr mentions functional_tensor ‚Äî prepare minimal stub strings ===\n# (define strings separately so user can inspect before writing)\nif 'last_inference_stderr' in globals():\n    _stderr_preview = (globals().get('last_inference_stderr') or '').lower()\nelse:\n    _stderr_preview = ''\nprint('stderr preview contains functional_tensor:', 'functional_tensor' in _stderr_preview)\n\n# Prepare stub strings (do not write yet)\ntv_init = \"\"\"# Minimal stub torchvision package for Real-ESRGAN/basicsr compatibility\nfrom . import utils\nfrom . import transforms\n__all__ = ['utils','transforms']\n\"\"\"\n\nutils_code = \"\"\"# Minimal stub for torchvision.utils.make_grid\ntry:\n    from torchvision.utils import make_grid as _make_grid\n    def make_grid(tensor, nrow=8, padding=2, normalize=False):\n        return _make_grid(tensor, nrow=nrow, padding=padding, normalize=normalize)\nexcept Exception:\n    import numpy as _np\n    from PIL import Image as _Image\n    import torch as _torch\n    def make_grid(tensor, nrow=8, padding=2, normalize=False):\n        if isinstance(tensor, (list, tuple)):\n            tensor = _torch.stack(tensor, dim=0)\n        if not isinstance(tensor, _torch.Tensor):\n            raise TypeError('Fallback make_grid expects a torch.Tensor or list of tensors')\n        t = tensor.detach().cpu()\n        if t.dim() == 3:\n            t = t.unsqueeze(0)\n        B,C,H,W = t.shape\n        if normalize:\n            t = (t - t.min()) / (t.max() - t.min() + 1e-8)\n        else:\n            if t.max() > 50:\n                t = t / 255.0\n        def to_uint8(x):\n            arr = (x.numpy().transpose(1,2,0) * 255.0).clip(0,255).astype(_np.uint8)\n            if arr.shape[2] == 1:\n                arr = _np.repeat(arr, 3, axis=2)\n            return _Image.fromarray(arr)\n        imgs = [to_uint8(t[i]) for i in range(B)]\n        rows = (B + nrow - 1) // nrow\n        grid_h = rows * H + padding * (rows - 1)\n        grid_w = nrow * W + padding * (nrow - 1)\n        grid = _Image.new('RGB', (grid_w, grid_h), (0,0,0))\n        for idx, img in enumerate(imgs):\n            r = idx // nrow\n            c = idx % nrow\n            grid.paste(img, (c * (W + padding), r * (H + padding)))\n        arr = _np.array(grid).transpose(2,0,1).astype(_np.float32) / 255.0\n        return _torch.from_numpy(arr)\n\"\"\"\n\ntr_init = \"\"\"# transforms package stub\nfrom . import functional_tensor\n__all__ = ['functional_tensor']\n\"\"\"\n\nfunc_code = \"\"\"# Auto-generated stub: try to import the real functional_tensor, otherwise delegate to torchvision.transforms.functional\ntry:\n    from torchvision.transforms.functional_tensor import *  # type: ignore\nexcept Exception:\n    try:\n        from torchvision.transforms import functional as _f\n    except Exception:\n        def rgb_to_grayscale(x):\n            raise ImportError('rgb_to_grayscale not available in this environment')\n        def convert_image_dtype(x, dtype):\n            raise ImportError('convert_image_dtype not available in this environment')\n    else:\n        rgb_to_grayscale = getattr(_f, 'rgb_to_grayscale', None)\n        convert_image_dtype = getattr(_f, 'convert_image_dtype', None)\n    __all__ = [n for n in ('rgb_to_grayscale','convert_image_dtype') if globals().get(n) is not None]\n\"\"\"\n\nprint('Prepared stub strings (not written yet)')\n\n# === CELL 9b: write stub files and retry run_cmd with PYTHONPATH adjusted ===\nif 'functional_tensor' in _stderr_preview or 'functional_tensor' in (tail(INFERENCE_LOG, 50) or '').lower():\n    try:\n        stub_root = os.path.join(WORKSPACE, 'torchvision_stub')\n        torchvision_pkg = os.path.join(stub_root, 'torchvision')\n        transforms_pkg = os.path.join(torchvision_pkg, 'transforms')\n        shutil.rmtree(stub_root, ignore_errors=True)\n        os.makedirs(transforms_pkg, exist_ok=True)\n\n        with open(os.path.join(torchvision_pkg, '__init__.py'), 'w', encoding='utf-8') as f_init:\n            f_init.write(tv_init)\n        with open(os.path.join(torchvision_pkg, 'utils.py'), 'w', encoding='utf-8') as f_utils:\n            f_utils.write(utils_code)\n        with open(os.path.join(transforms_pkg, '__init__.py'), 'w', encoding='utf-8') as f_tr:\n            f_tr.write(tr_init)\n        with open(os.path.join(transforms_pkg, 'functional_tensor.py'), 'w', encoding='utf-8') as f_ft:\n            f_ft.write(func_code)\n\n        env = os.environ.copy()\n        prev_pp = env.get('PYTHONPATH', '')\n        env['PYTHONPATH'] = stub_root + (os.pathsep + prev_pp if prev_pp else '')\n\n        print('Running run_cmd with stub PYTHONPATH...')\n        if run_cmd is None:\n            print('run_cmd undefined ‚Äî cannot retry')\n        else:\n            res_stub = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600, env=env)\n            print('Stub attempt returncode:', getattr(res_stub,'returncode',None))\n            try:\n                with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                    lf.write('\\n=== STUB SUBPROCESS STDOUT ===\\n')\n                    lf.write(res_stub.stdout or '')\n                    lf.write('\\n=== STUB SUBPROCESS STDERR ===\\n')\n                    lf.write(res_stub.stderr or '')\n            except Exception:\n                pass\n            if res_stub.returncode == 0:\n                print('‚úì Inference completed using local stub; see', INFERENCE_LOG)\n            else:\n                print('Stub attempt failed with code', res_stub.returncode)\n                print('Attempting editable install of Real-ESRGAN package then torchvision install and retry...')\n                try:\n                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                        lf.write('\\n=== Ensuring Real-ESRGAN package is installed (editable) ===\\n')\n                except Exception:\n                    pass\n                try:\n                    res_pkg = subprocess.run([sys.executable, '-m', 'pip', 'install', '-e', '.'], capture_output=True, text=True, timeout=900)\n                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                        lf.write('\\n=== PKG INSTALL STDOUT ===\\n')\n                        lf.write(res_pkg.stdout or '')\n                        lf.write('\\n=== PKG INSTALL STDERR ===\\n')\n                        lf.write(res_pkg.stderr or '')\n                except Exception as _pkg_e:\n                    print('Editable install failed:', _pkg_e)\n\n                try:\n                    res_install = subprocess.run(install_cmd, capture_output=True, text=True, timeout=900)\n                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                        lf.write('\\n=== TORCHVISION INSTALL STDOUT ===\\n')\n                        lf.write(res_install.stdout or '')\n                        lf.write('\\n=== TORCHVISION INSTALL STDERR ===\\n')\n                        lf.write(res_install.stderr or '')\n                except Exception as _ie:\n                    print('torchvision install failed:', _ie)\n                    res_install = None\n\n                if res_install and res_install.returncode == 0:\n                    print('torchvision installed; retrying inference (with stub PYTHONPATH)')\n                    res2 = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600, env=env)\n                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n                        lf.write('\\n=== RETRY STDOUT ===\\n')\n                        lf.write(res2.stdout or '')\n                        lf.write('\\n=== RETRY STDERR ===\\n')\n                        lf.write(res2.stderr or '')\n                    if res2.returncode == 0:\n                        print('‚úì Real-ESRGAN inference completed after installing torchvision; see', INFERENCE_LOG)\n                    else:\n                        print('Retry also failed ‚Äî see', INFERENCE_LOG)\n                else:\n                    print('Could not install torchvision ‚Äî see', INFERENCE_LOG)\n    except Exception as e:\n        print('Exception during stub/install/retry:', e)\nelse:\n    print('No functional_tensor error detected in stderr tail ‚Äî skip stub flow')\n\n# === CELL 10: final move/rename upscaled frames into FRAMES_DIR (if present) ===\ntry:\n    if os.path.exists(FRAMES_DIR + '_upscaled'):\n        print('Moving upscaled frames into', FRAMES_DIR)\n        shutil.rmtree(FRAMES_DIR, ignore_errors=True)\n        shutil.move(FRAMES_DIR + '_upscaled', FRAMES_DIR)\n        import glob\n        upscaled_files = sorted(glob.glob(f\"{FRAMES_DIR}/*_out.png\"))\n        for i, filepath in enumerate(upscaled_files):\n            try:\n                os.rename(filepath, f\"{FRAMES_DIR}/{i}.png\")\n            except Exception:\n                pass\n        print('‚úì Upscaled frames moved/renamed')\n    else:\n        print('No upscaled frames dir found ‚Äî nothing to move')\nexcept Exception as e:\n    print('Error while moving/renaming upscaled frames:', e)\n","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.953784Z","iopub.status.idle":"2025-10-27T14:35:11.954352Z","shell.execute_reply.started":"2025-10-27T14:35:11.954141Z","shell.execute_reply":"2025-10-27T14:35:11.954157Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === –ò–¢–û–ì–ò ===\n# –ó–∞—â–∏—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è total_gen_time –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ (—è—á–µ–π–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª–∞—Å—å),\n# —Å—Ç–∞–≤–∏–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 0.0\nif 'total_gen_time' not in globals():\n    total_gen_time = 0.0\n\nprint_separator()\nprint(\"üìã –ò–¢–û–ì–ò –ì–ï–ù–ï–†–ê–¶–ò–ò\")\nprint_separator(nl_before=False)\nprint(f\"–†–µ–∂–∏–º: {'AnimateDiff (–∞–Ω–∏–º–∞—Ü–∏—è)' if USE_ANIMATEDIFF else '–°—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã'}\")\nprint(f\"–ü—Ä–æ–º–ø—Ç: {PROMPT[:50]}...\")\nprint(f\"–†–∞–∑–º–µ—Ä: {WIDTH}x{HEIGHT}\")\nprint(f\"–ö–∞–¥—Ä–æ–≤: {NUM_FRAMES}\" + (f\" ‚Üí {NUM_FRAMES * (2**RIFE_EXP)}\" if USE_RIFE else \"\"))\nprint(f\"–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {total_gen_time:.1f}s\")\n\nif USE_ANIMATEDIFF:\n    print(f\"\\n{'=\"*60}\")\n    print(\"üí° –°–û–í–ï–¢–´ –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø –ê–ù–ò–ú–ê–¶–ò–ò\")\n    print(f\"{'='*60}\")\n    print(\"–î–æ–±–∞–≤—å—Ç–µ –≤ –ø—Ä–æ–º–ø—Ç:\")\n    print(\"  ‚Ä¢ 'turning head', 'blinking', 'hair flowing'\")\n    print(\"  ‚Ä¢ 'smooth motion', 'cinematic camera movement'\")\n    print(\"  ‚Ä¢ 'dynamic pose', 'wind blowing'\")\n    print(\"\\n–î–æ–±–∞–≤—å—Ç–µ –≤ negative:\")\n    print(\"  ‚Ä¢ 'static', 'frozen', 'choppy animation'\")\n    print(\"  ‚Ä¢ 'stiff', 'rigid', 'still image'\")\n\nprint(f\"\\n{'='*60}\")\nprint(\"‚úÖ –í–°–Å –ì–û–¢–û–í–û!\")\nprint(f\"{'='*60}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.955221Z","iopub.status.idle":"2025-10-27T14:35:11.955520Z","shell.execute_reply.started":"2025-10-27T14:35:11.955379Z","shell.execute_reply":"2025-10-27T14:35:11.955392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === UNLOAD PIPE (–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ pipeline –∏ VRAM) ===\n# –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É, —á—Ç–æ–±—ã —É–¥–∞–ª–∏—Ç—å `pipe` –∏ `adapter` –∏–∑ globals –∏ –æ—á–∏—Å—Ç–∏—Ç—å VRAM.\ndef unload_pipe():\n    \"\"\"–£–¥–∞–ª—è–µ—Ç pipe/adapter –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –∏ –æ—á–∏—â–∞–µ—Ç VRAM (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω torch).\"\"\"\n    import gc\n    removed = []\n    try:\n        if 'pipe' in globals():\n            try:\n                del globals()['pipe']\n                removed.append('pipe')\n            except Exception:\n                pass\n        if 'adapter' in globals():\n            try:\n                del globals()['adapter']\n                removed.append('adapter')\n            except Exception:\n                pass\n        # –ü–æ–ø—Ä–æ–±—É–µ–º –æ—Å–≤–æ–±–æ–¥–∏—Ç—å GPU –ø–∞–º—è—Ç—å\n        try:\n            import torch\n            torch.cuda.empty_cache()\n            removed.append('cuda_cache_cleared')\n        except Exception:\n            pass\n        # –û–±—â–∞—è —É–±–æ—Ä–∫–∞ –ø–∞–º—è—Ç–∏\n        gc.collect()\n        print(f\"‚úì –£–¥–∞–ª–µ–Ω–æ: {', '.join(removed) if removed else '–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\")\n    except Exception as e:\n        print('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ pipe:', e)\n\n# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É –µ—Å–ª–∏ ipywidgets –¥–æ—Å—Ç—É–ø–µ–Ω, –∏–Ω–∞—á–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é\ntry:\n    import ipywidgets as widgets\n    from IPython.display import display\n    btn_unload = widgets.Button(description='Unload pipe (free VRAM)', button_style='warning')\n    def _on_unload_click(b):\n        unload_pipe()\n    btn_unload.on_click(_on_unload_click)\n    display(btn_unload)\nexcept Exception:\n    print('\\n‚ÑπÔ∏è –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ —è—á–µ–π–∫–µ: unload_pipe()')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.956763Z","iopub.status.idle":"2025-10-27T14:35:11.956962Z","shell.execute_reply.started":"2025-10-27T14:35:11.956867Z","shell.execute_reply":"2025-10-27T14:35:11.956875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === QUICK SMOKE GENERATION ‚Äî –±—ã—Å—Ç—Ä—ã–π placeholder –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ workflow ===\n# –°–æ–∑–¥–∞—ë—Ç –ø—Ä–æ—Å—Ç—ã–µ –∫–∞–¥—Ä—ã —Å –¥–≤–∏–∂—É—â–∏–º—Å—è —Ç–µ–∫—Å—Ç–æ–º/—ç–ª–µ–º–µ–Ω—Ç–æ–º –∏ —Å–æ–±–∏—Ä–∞–µ—Ç MP4 —á–µ—Ä–µ–∑ ffmpeg.\nimport os\nimport subprocess\nfrom PIL import Image, ImageDraw, ImageFont\n\nprint_separator()\nprint('‚ö° QUICK SMOKE GENERATION ‚Äî —Å–æ–∑–¥–∞—ë–º placeholder-–∫–∞–¥—Ä—ã')\nprint_separator(nl_before=False)\n\n# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –Ω–µ–±–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)\nSMOKE_WIDTH = 256\nSMOKE_HEIGHT = 256\nSMOKE_FRAMES = 8\nSMOKE_FPS = 8\n\n# –ü—É—Ç—å –¥–ª—è –∫–∞–¥—Ä–æ–≤\nif 'WORKSPACE' not in globals():\n    WORKSPACE = os.getcwd()\nSMOKE_FRAMES_DIR = f\"{WORKSPACE}/smoke_frames\"\nos.makedirs(SMOKE_FRAMES_DIR, exist_ok=True)\n\n# –ü—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\nprompt_text = globals().get('PROMPT', 'Test generation ‚Äî change PROMPT cell')\ntext_preview = (prompt_text or '')[:120]\n\n# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–¥—Ä—ã\nfor i in range(SMOKE_FRAMES):\n    # —Ñ–æ–Ω –∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç\n    r = (30 + i * 20) % 256\n    g = (80 + i * 10) % 256\n    b = (160 + i * 5) % 256\n    img = Image.new('RGB', (SMOKE_WIDTH, SMOKE_HEIGHT), (r, g, b))\n    draw = ImageDraw.Draw(img)\n    try:\n        font = ImageFont.load_default()\n    except Exception:\n        font = None\n    # –¥–≤–∏–∂—É—â–∏–π—Å—è —Ç–µ–∫—Å—Ç\n    w, h = draw.textsize(text_preview, font=font)\n    x = int((SMOKE_WIDTH - w) * i / max(1, SMOKE_FRAMES - 1))\n    y = SMOKE_HEIGHT // 2 - h // 2\n    draw.text((x, y), text_preview, fill=(255, 255, 255), font=font)\n    # –¥–≤–∏–∂—É—â–∏–π—Å—è –∫—Ä—É–∂–æ–∫\n    cx = int(SMOKE_WIDTH * (0.2 + 0.6 * (i / max(1, SMOKE_FRAMES - 1))))\n    cy = int(SMOKE_HEIGHT * 0.25)\n    r0 = 12\n    draw.ellipse((cx - r0, cy - r0, cx + r0, cy + r0), fill=(255, 200, 0))\n    # –ø–æ–¥–ø–∏—Å—å –∫–∞–¥—Ä–∞\n    draw.text((6, SMOKE_HEIGHT - 14), f'frame {i+1}/{SMOKE_FRAMES}', fill=(230,230,230), font=font)\n    path = os.path.join(SMOKE_FRAMES_DIR, f\"{i}.png\")\n    img.save(path)\n    print(f'  saved {path}')\n\n# –°–æ–±–∏—Ä–∞–µ–º MP4 —á–µ—Ä–µ–∑ ffmpeg\nsmoke_video = f\"{WORKSPACE}/SMOKE_OUTPUT.mp4\"\nffmpeg_cmd = [\n    'ffmpeg', '-y', '-framerate', str(SMOKE_FPS), '-i', f\"{SMOKE_FRAMES_DIR}/%d.png\",\n    '-c:v', 'libx264', '-pix_fmt', 'yuv420p', '-preset', 'fast', smoke_video\n]\nprint('\\n–ó–∞–ø—É—Å–∫ ffmpeg...')\ntry:\n    subprocess.check_call(ffmpeg_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n    print(f'‚úì Smoke video saved: {smoke_video}')\n    try:\n        from IPython.display import FileLink, display\n        display(FileLink(smoke_video))\n    except Exception:\n        pass\nexcept Exception as e:\n    print('‚ö†Ô∏è ffmpeg failed or not available:', e)\n    print('  You can manually assemble frames using:')\n    print(f\"  ffmpeg -framerate {SMOKE_FPS} -i {SMOKE_FRAMES_DIR}/%d.png -c:v libx264 -pix_fmt yuv420p -preset fast {smoke_video}\")\n\nprint_separator()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.957960Z","iopub.status.idle":"2025-10-27T14:35:11.958159Z","shell.execute_reply.started":"2025-10-27T14:35:11.958065Z","shell.execute_reply":"2025-10-27T14:35:11.958073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === SHOW REAL-ESRGAN LOGS ===\n# –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—á–∞–ª–æ –ª–æ–≥–æ–≤ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ Real-ESRGAN, –µ—Å–ª–∏ –æ–Ω–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç\nimport os\nLOG_DIR = os.path.join(os.getcwd(), 'logs')\ninstall_log = os.path.join(LOG_DIR, 'real_esrgan_install.log')\ninf_log = os.path.join(LOG_DIR, 'real_esrgan_inference.log')\n\ndef show_log(path, max_chars=20000):\n    if os.path.exists(path):\n        print('\\n' + '='*40)\n        print('LOG:', path)\n        print('='*40)\n        try:\n            with open(path, 'r', encoding='utf-8', errors='replace') as f:\n                data = f.read()\n            print(data[:max_chars])\n            if len(data) > max_chars:\n                print('\\n... (truncated) ...')\n        except Exception as e:\n            print('Could not read log:', e)\n    else:\n        print(f'Log not found: {path}')\n\nprint('Checking Real-ESRGAN logs in', LOG_DIR)\nshow_log(install_log)\nshow_log(inf_log)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T14:35:11.959572Z","iopub.status.idle":"2025-10-27T14:35:11.960086Z","shell.execute_reply.started":"2025-10-27T14:35:11.959918Z","shell.execute_reply":"2025-10-27T14:35:11.959932Z"}},"outputs":[],"execution_count":null}]}