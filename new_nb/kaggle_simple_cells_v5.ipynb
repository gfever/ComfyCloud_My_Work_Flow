{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "```jupyter\n",
    "# Comfy Gojo — компактный и надёжный Kaggle workflow\n",
    "\n",
    "Этот ноутбук — упрощённая, исправленная и оптимизированная версия вашего `kaggle-simple-cells-v4` для запуска в Kaggle.\n",
    "\n",
    "Цели:\n",
    "\n",
    "- Настроить окружение (безопасно для XLA/TensorFlow/JAX)\n",
    "- Подготовить и сохранить prompts.json\n",
    "- Сгенерировать кадры (AnimateDiff или Stable Diffusion),\n",
    "- Надёжно подготовить shim для Real-ESRGAN и выполнить апскейл (опционально),\n",
    "- Логирование и понятная отладка при ошибках."
   ],
   "id": "f7b3275444431bfa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1) ENV: установить переменные до любых heavy импортов (выполните сразу)\n",
    "import os, importlib\n",
    "\n",
    "_changed = False\n",
    "\n",
    "def _set(k,v):\n",
    "    global _changed\n",
    "    if os.environ.get(k) != v:\n",
    "        os.environ[k] = v\n",
    "        _changed = True\n",
    "# подавляем XLA/TensorFlow шумы\n",
    "_set('TF_CPP_MIN_LOG_LEVEL','3')\n",
    "_set('XLA_PYTHON_CLIENT_PREALLOCATE','false')\n",
    "_set('XLA_PYTHON_CLIENT_MEM_FRACTION','0.0')\n",
    "_set('JAX_PLATFORM_NAME','cpu')\n",
    "_set('JAX_PLATFORMS','cpu')\n",
    "print('ENV set. Restart kernel AFTER you change these and BEFORE importing heavy libs if _changed = True')\n",
    "print('changed_env =', _changed)"
   ],
   "id": "d2efa414a7f3f20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2) KAGGLE checks: basic hints and GPU info\n",
    "import os, sys, importlib, subprocess, json\n",
    "print('Running in Kaggle:', any(p.startswith('/kaggle') for p in (os.getcwd(),)) or os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None)\n",
    "# lightweight torch check (subprocess to avoid heavy import delays)\n",
    "try:\n",
    "    cmd = [sys.executable, '-c', 'import torch, json; print(json.dumps({\"cuda\": torch.cuda.is_available(), \"device_count\": torch.cuda.device_count(), \"name\": (torch.cuda.get_device_name(0).strip() if torch.cuda.is_available() else \"no gpu\")}))']\n",
    "    res = subprocess.run(cmd, capture_output=True, text=True, timeout=12)\n",
    "    print('torch probe:', res.stdout.strip())\n",
    "except Exception as e:\n",
    "    print('Torch probe skipped:', e)\n",
    "# HF token hint\n",
    "print('HF token present in env:', bool(os.environ.get('HUGGINGFACE_HUB_TOKEN') or os.environ.get('HF_TOKEN')))"
   ],
   "id": "111f9f2f19049598"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3) Optional: install deps (uncomment to run)\n",
    "# Для ускорения повторных запусков — выполняйте только при отсутствии пакетов\n",
    "# !pip install -q diffusers[torch] transformers accelerate imageio imageio-ffmpeg ipywidgets opencv-python\n",
    "# Если планируете запуск Real-ESRGAN:\n",
    "# !pip install -q basicsr facexlib gfpgan realesrgan\n",
    "print('Deps: оставлены как опция — устанавливайте вручную при необходимости')"
   ],
   "id": "2c801005559203de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prompts — редактируемая часть (меняйте только здесь)",
   "id": "e23272092a023cea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4) Prompts: сохранение и короткая GUI fallback\n",
    "import json, os\n",
    "PROMPTS = {\n",
    "  'BASE_PROMPT': 'cinematic portrait of gojo satoru, white spiky hair, black blindfold, confident expression, anime style, highly detailed',\n",
    "  'MOTION_PROMPT': 'turning head, hair flowing, smooth motion',\n",
    "  'EXTRA_PROMPT': 'dramatic rim lighting, soft bloom',\n",
    "  'NEGATIVE_PROMPT': 'blurry, deformed, watermark, text, bad anatomy'\n",
    "}\n",
    "with open('prompts.json','w',encoding='utf-8') as f:\n",
    "    json.dump(PROMPTS,f,ensure_ascii=False,indent=2)\n",
    "print('Saved prompts.json (edit PROMPTS dict above to change)')"
   ],
   "id": "f7b1b7808426f9b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Генерация (AnimateDiff или SDXL) — запустите только нужную ячейку",
   "id": "86fb35b07ac45ab4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 5a) AnimateDiff generation (fast path) — включите/настройте флаги и запустите\n",
    "USE_ANIMATEDIFF = True\n",
    "NUM_FRAMES = 8\n",
    "WIDTH = 512\n",
    "HEIGHT = 768\n",
    "STEPS = 20\n",
    "from pathlib import Path\n",
    "FRAMES_DIR = Path('/kaggle/working/frames')\n",
    "FRAMES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "if USE_ANIMATEDIFF:\n",
    "    try:\n",
    "        from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
    "        import torch\n",
    "        adapter = MotionAdapter.from_pretrained('guoyww/animatediff-motion-adapter-v1-5-2', torch_dtype=torch.float16)\n",
    "        pipe = AnimateDiffPipeline.from_pretrained('runwayml/stable-diffusion-v1-5', motion_adapter=adapter, torch_dtype=torch.float16).to('cuda')\n",
    "        pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "        pipe.enable_vae_slicing(); pipe.enable_model_cpu_offload()\n",
    "        out = pipe(prompt= (open('prompts.json','r',encoding='utf-8').read()), num_frames=NUM_FRAMES, width=WIDTH, height=HEIGHT, num_inference_steps=STEPS, guidance_scale=7.5, generator=torch.Generator('cuda').manual_seed(42))\n",
    "        frames = out.frames[0]\n",
    "        for i,im in enumerate(frames):\n",
    "            im.save(FRAMES_DIR / f'{i}.png')\n",
    "        print('Saved', len(frames), 'frames to', FRAMES_DIR)\n",
    "    except Exception as e:\n",
    "        print('AnimateDiff failed:', e)\n",
    "else:\n",
    "    print('AnimateDiff disabled — run SDXL cell вместо')"
   ],
   "id": "b58ac9c7b8f8337a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 5b) SDXL static frame generation (alternative) — uncomment to use instead of AnimateDiff\n",
    "# from diffusers import StableDiffusionXLPipeline\n",
    "# import torch\n",
    "# pipe = StableDiffusionXLPipeline.from_pretrained('stabilityai/stable-diffusion-xl-base-1.0', torch_dtype=torch.float16).to('cuda')\n",
    "# pipe.enable_attention_slicing(); pipe.enable_vae_slicing()\n",
    "# for i in range(NUM_FRAMES):\n",
    "#     img = pipe(prompt=... ).images[0]; img.save(FRAMES_DIR / f'{i}.png')\n",
    "# print('Saved static frames')\n",
    "print('SDXL cell ready as alternative — uncomment to run')"
   ],
   "id": "b80ba139079eab61"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Real-ESRGAN upscaling — надежная подготовка shim и запуск",
   "id": "82665e992c40182f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 6) Robust shim writer (writes to /kaggle/working/Real-ESRGAN/inference_with_shim_full.py or falls back)\n",
    "import os, textwrap, py_compile\n",
    "OUT_DIR = '/kaggle/working/Real-ESRGAN'\n",
    "OUT_PATH = os.path.join(OUT_DIR, 'inference_with_shim_full.py')\n",
    "SHIM = textwrap.dedent('''\n",
    "    import sys\n",
    "    import os\n",
    "    import types\n",
    "    import re\n",
    "    import runpy\n",
    "    \n",
    "    try:\n",
    "        import torchvision.transforms.functional_tensor as _ft\n",
    "    except Exception:\n",
    "        try:\n",
    "            import torchvision.transforms.functional as _f\n",
    "            mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\n",
    "            mod_ft.rgb_to_grayscale = getattr(_f, 'rgb_to_grayscale', None)\n",
    "            mod_ft.convert_image_dtype = getattr(_f, 'convert_image_dtype', None)\n",
    "            sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\n",
    "        except Exception:\n",
    "            mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\n",
    "            def _rgb_to_grayscale(x):\n",
    "                raise ImportError('rgb_to_grayscale not available')\n",
    "            def _convert_image_dtype(x, dtype):\n",
    "                raise ImportError('convert_image_dtype not available')\n",
    "            mod_ft.rgb_to_grayscale = _rgb_to_grayscale\n",
    "            mod_ft.convert_image_dtype = _convert_image_dtype\n",
    "            sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\n",
    "    \n",
    "    if 'torchvision.utils' not in sys.modules:\n",
    "        mod_utils = types.ModuleType('torchvision.utils')\n",
    "        def make_grid(x, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0):\n",
    "            try:\n",
    "                if isinstance(x, (list, tuple)) and len(x) > 0:\n",
    "                    return x[0]\n",
    "                return x\n",
    "            except Exception:\n",
    "                return x\n",
    "        mod_utils.make_grid = make_grid\n",
    "        sys.modules['torchvision.utils'] = mod_utils\n",
    "    \n",
    "    if 'realesrgan.version' not in sys.modules:\n",
    "        vermod = types.ModuleType('realesrgan.version')\n",
    "        vermod.__version__ = '0.3.0'\n",
    "        vermod.__all__ = ['__version__']\n",
    "        sys.modules['realesrgan.version'] = vermod\n",
    "    \n",
    "    def _infer_netscale(argv):\n",
    "        for i, a in enumerate(argv):\n",
    "            if a in ('-n', '--name', '--model') and i+1 < len(argv):\n",
    "                m = re.match(r\"(\\\\d+)x\", argv[i+1])\n",
    "                if m:\n",
    "                    try:\n",
    "                        return int(m.group(1))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "        for i, a in enumerate(argv):\n",
    "            if a in ('-s', '--scale') and i+1 < len(argv):\n",
    "                try:\n",
    "                    return int(argv[i+1])\n",
    "                except Exception:\n",
    "                    pass\n",
    "        return 4\n",
    "    \n",
    "    def _detect_weight_file():\n",
    "        try:\n",
    "            wdir = os.path.join(os.getcwd(), 'weights')\n",
    "            if not os.path.isdir(wdir):\n",
    "                return None\n",
    "            exts = ('.pth', '.pt', '.safetensors')\n",
    "            candidates = [f for f in os.listdir(wdir) if f.lower().endswith(exts)]\n",
    "            if not candidates:\n",
    "                return None\n",
    "            for name in candidates:\n",
    "                if '4x' in name.lower() or 'ultrasharp' in name.lower():\n",
    "                    return os.path.join(wdir, name)\n",
    "            return os.path.join(wdir, candidates[0])\n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        argv = sys.argv[1:]\n",
    "        netscale = _infer_netscale(argv)\n",
    "        detected_model = _detect_weight_file()\n",
    "        script_path = os.path.join(os.getcwd(), 'inference_realesrgan.py')\n",
    "        try:\n",
    "            with open(script_path, 'r', encoding='utf-8') as _f:\n",
    "                _code = _f.read()\n",
    "        except Exception:\n",
    "            sys.argv = [script_path] + argv\n",
    "            runpy.run_path('inference_realesrgan.py', run_name='__main__')\n",
    "        else:\n",
    "            _globals = {'__name__': '__main__', '__file__': script_path, 'netscale': netscale, 'model': detected_model, 'outscale': netscale, 'scale': netscale}\n",
    "            _globals['sys'] = sys\n",
    "            sys.argv = [script_path] + argv\n",
    "            exec(compile(_code, script_path, 'exec'), _globals)\n",
    "    ''')\n",
    "# write shim with safe fallbacks\n",
    "try:\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    with open(OUT_PATH, 'w', encoding='utf-8', newline='\\n') as f:\n",
    "        f.write(SHIM)\n",
    "    py_compile.compile(OUT_PATH, doraise=True)\n",
    "    print('Shim written and compiled:', OUT_PATH)\n",
    "except Exception as e:\n",
    "    fallback = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\n",
    "    with open(fallback, 'w', encoding='utf-8') as f:\n",
    "        f.write(SHIM)\n",
    "    print('Fallback shim written to', fallback, 'due to', e)"
   ],
   "id": "8bcf6f53cbf2142c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 7) Prepare Real-ESRGAN repo, copy weights and prepare run_cmd (do not auto-run)\n",
    "import os, shutil, subprocess, sys\n",
    "WORKSPACE = '/kaggle/working'\n",
    "REPO_DIR = os.path.join(WORKSPACE, 'Real-ESRGAN')\n",
    "UPSCALE_MODEL_NAME = '4x-UltraSharp.pth'\n",
    "# candidate weight in datasets (adjust to your dataset mount)\n",
    "c1 = os.path.join('/kaggle/input/comfyui-models-gojo', UPSCALE_MODEL_NAME)\n",
    "weights_copied = False\n",
    "if os.path.exists(c1) and os.path.exists(REPO_DIR):\n",
    "    try:\n",
    "        wd = os.path.join(REPO_DIR, 'weights')\n",
    "        os.makedirs(wd, exist_ok=True)\n",
    "        shutil.copy(c1, wd)\n",
    "        weights_copied = True\n",
    "        print('Copied weight to', wd)\n",
    "    except Exception as e:\n",
    "        print('Failed to copy weight:', e)\n",
    "else:\n",
    "    print('Either dataset weight or Real-ESRGAN repo missing; you may need to clone or attach dataset')\n",
    "# Build run_cmd (prefer running the real script directly to avoid shim exec quirks)\n",
    "shim_path = os.path.join(REPO_DIR, 'inference_with_shim_full.py')\n",
    "script_path = os.path.join(REPO_DIR, 'inference_realesrgan.py')\n",
    "run_cwd = None\n",
    "if os.path.exists(script_path):\n",
    "    # run the actual script directly (safest for argument parsing and avoids UnboundLocalError from exec)\n",
    "    run_cmd = [sys.executable, script_path, '-n', '4x-UltraSharp', '-i', str(FRAMES_DIR), '-o', str(FRAMES_DIR) + '_upscaled', '--fp32', '--outscale', '4']\n",
    "    run_cwd = REPO_DIR\n",
    "elif os.path.exists(shim_path):\n",
    "    # fallback to shim if script not present\n",
    "    run_cmd = [sys.executable, shim_path, '-n', '4x-UltraSharp', '-i', str(FRAMES_DIR), '-o', str(FRAMES_DIR) + '_upscaled', '--fp32', '--outscale', '4']\n",
    "    run_cwd = REPO_DIR\n",
    "else:\n",
    "    run_cmd = None\n",
    "    run_cwd = None\n",
    "print('Prepared run_cmd:', run_cmd, 'run_cwd:', run_cwd)"
   ],
   "id": "2270015720a9e7da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 8) Debug + optional retry runner for Real-ESRGAN (replacement for fragile cells)\n",
    "import os, subprocess, time, shutil\n",
    "\n",
    "# User toggle: set to True to actually run the prepared command(s)\n",
    "retry_now = True  # <<< set to False to do a dry-run; currently enabled to run injector/shim when you execute this cell\n",
    "\n",
    "def tail(path, max_chars=8000):\n",
    "    try:\n",
    "        with open(path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            data = f.read()\n",
    "        return data[-max_chars:]\n",
    "    except Exception:\n",
    "        return ''\n",
    "\n",
    "INFERENCE_LOG = os.path.join('/kaggle/working', 'logs', 'real_esrgan_inference.log')\n",
    "os.makedirs(os.path.dirname(INFERENCE_LOG), exist_ok=True)\n",
    "print('INFERENCE_LOG ->', INFERENCE_LOG)\n",
    "\n",
    "# Ensure run_cwd points to REPO_DIR if possible\n",
    "if not globals().get('run_cwd') and os.path.exists(REPO_DIR) and os.path.exists(os.path.join(REPO_DIR, 'inference_realesrgan.py')):\n",
    "    run_cwd = REPO_DIR\n",
    "    print('Auto-set run_cwd ->', run_cwd)\n",
    "\n",
    "# If inference_realesrgan.py is missing in run_cwd, attempt to fetch it automatically (clone or download)\n",
    "if run_cwd and not os.path.exists(os.path.join(run_cwd, 'inference_realesrgan.py')):\n",
    "    print('inference_realesrgan.py not found in', run_cwd, '-> attempting to fetch from upstream Real-ESRGAN repo')\n",
    "    try:\n",
    "        tmp_dir = os.path.join(WORKSPACE, 'Real-ESRGAN_tmp_clone')\n",
    "        if os.path.exists(tmp_dir):\n",
    "            try: shutil.rmtree(tmp_dir)\n",
    "            except Exception: pass\n",
    "        print('Cloning Real-ESRGAN into temporary dir:', tmp_dir)\n",
    "        r = subprocess.run(['git', 'clone', '--depth', '1', 'https://github.com/xinntao/Real-ESRGAN', tmp_dir], capture_output=True, text=True, timeout=240)\n",
    "        if r.returncode == 0 and os.path.exists(os.path.join(tmp_dir, 'inference_realesrgan.py')):\n",
    "            shutil.copy(os.path.join(tmp_dir, 'inference_realesrgan.py'), os.path.join(run_cwd, 'inference_realesrgan.py'))\n",
    "            print('Copied inference_realesrgan.py into', run_cwd)\n",
    "            try: shutil.rmtree(tmp_dir)\n",
    "            except Exception: pass\n",
    "        else:\n",
    "            print('Clone did not produce inference_realesrgan.py or clone failed:', r.returncode)\n",
    "            print('git stderr (first 400 chars):', (r.stderr or '')[:400])\n",
    "            # Try downloading raw file as fallback\n",
    "            raw_url = 'https://raw.githubusercontent.com/xinntao/Real-ESRGAN/master/inference_realesrgan.py'\n",
    "            out_path = os.path.join(run_cwd, 'inference_realesrgan.py')\n",
    "            try:\n",
    "                print('Attempting to download raw file from', raw_url)\n",
    "                d = subprocess.run(['curl', '-fsSL', raw_url, '-o', out_path], capture_output=True, text=True, timeout=30)\n",
    "                if d.returncode == 0 and os.path.exists(out_path):\n",
    "                    print('Downloaded inference_realesrgan.py to', out_path)\n",
    "                else:\n",
    "                    print('curl failed or file not present after download. rc=', d.returncode, 'stderr=', (d.stderr or '')[:400])\n",
    "            except Exception as e:\n",
    "                print('curl attempt failed:', e)\n",
    "    except Exception as e:\n",
    "        print('Auto-fetch attempt failed:', e)\n",
    "\n",
    "# Summary before running\n",
    "print('Prepared run_cmd:', run_cmd)\n",
    "print('run_cwd:', run_cwd)\n",
    "\n",
    "# Execution + robust retry\n",
    "if retry_now:\n",
    "    print('Running run_cmd...')\n",
    "    start = time.time()\n",
    "    try:\n",
    "        # Prepare compat root and wrapper\n",
    "        if run_cwd:\n",
    "            compat_root = os.path.join(run_cwd, 'compat_site')\n",
    "            wrapper_path = os.path.join(run_cwd, 'run_with_compat.py')\n",
    "        else:\n",
    "            compat_root = os.path.join(os.getcwd(), 'compat_site')\n",
    "            wrapper_path = os.path.join(os.getcwd(), 'run_with_compat.py')\n",
    "\n",
    "        # ensure compat package exists (may have been created earlier)\n",
    "        try:\n",
    "            os.makedirs(compat_root, exist_ok=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # write wrapper that injects compat_root and provides a synthetic functional_tensor module if needed\n",
    "        wrapper_code = f'''import sys, os, runpy, types\n",
    "# Insert compat_site at front so imports see our shim\n",
    "compat = os.path.join(os.path.dirname(__file__), 'compat_site')\n",
    "if os.path.exists(compat) and compat not in sys.path:\n",
    "    sys.path.insert(0, compat)\n",
    "# Ensure a minimal torchvision.transforms.functional_tensor module exists in sys.modules before imports\n",
    "try:\n",
    "    import importlib\n",
    "    spec = importlib.util.find_spec('torchvision.transforms.functional_tensor')\n",
    "except Exception:\n",
    "    spec = None\n",
    "if spec is None:\n",
    "    try:\n",
    "        # attempt to create a synthetic module using torchvision.transforms.functional\n",
    "        from torchvision import transforms as _trans\n",
    "        try:\n",
    "            _func = _trans.functional\n",
    "        except Exception:\n",
    "            _func = None\n",
    "        mod = types.ModuleType('torchvision.transforms.functional_tensor')\n",
    "        if _func is not None:\n",
    "            rgb = getattr(_func, 'rgb_to_grayscale', None)\n",
    "            conv = getattr(_func, 'convert_image_dtype', None)\n",
    "            if rgb is not None:\n",
    "                mod.rgb_to_grayscale = rgb\n",
    "            if conv is not None:\n",
    "                mod.convert_image_dtype = conv\n",
    "        # fallback placeholders\n",
    "        if not hasattr(mod, 'rgb_to_grayscale'):\n",
    "            def _rgb_fail(x):\n",
    "                raise ImportError('rgb_to_grayscale not available')\n",
    "            mod.rgb_to_grayscale = _rgb_fail\n",
    "        if not hasattr(mod, 'convert_image_dtype'):\n",
    "            def _conv_fail(x, dtype):\n",
    "                raise ImportError('convert_image_dtype not available')\n",
    "            mod.convert_image_dtype = _conv_fail\n",
    "        import sys as _sys\n",
    "        _sys.modules['torchvision.transforms.functional_tensor'] = mod\n",
    "    except Exception:\n",
    "        pass\n",
    "# Determine script to run from argv[1]\n",
    "if len(sys.argv) < 2:\n",
    "    print('run_with_compat: missing script argument', file=sys.stderr)\n",
    "    sys.exit(2)\n",
    "script = sys.argv[1]\n",
    "# propagate CLI args: keep script as argv[0]\n",
    "sys.argv = [script] + sys.argv[2:]\n",
    "runpy.run_path(script, run_name='__main__')\n",
    "'''\n",
    "        try:\n",
    "            with open(wrapper_path, 'w', encoding='utf-8') as wf:\n",
    "                wf.write(wrapper_code)\n",
    "            os.chmod(wrapper_path, 0o755)\n",
    "            print('Wrote wrapper script to', wrapper_path)\n",
    "        except Exception as _e:\n",
    "            print('Could not write wrapper script:', _e)\n",
    "\n",
    "        # write an injector script that preloads compat and injects a synthetic module before running the script\n",
    "        try:\n",
    "            if run_cwd:\n",
    "                inject_path = os.path.join(run_cwd, 'inject_and_exec.py')\n",
    "            else:\n",
    "                inject_path = os.path.join(os.getcwd(), 'inject_and_exec.py')\n",
    "            inject_code = '''import sys, os, runpy, types, re\n",
    "# insert compat_site at front\n",
    "compat = os.path.join(os.path.dirname(__file__), 'compat_site')\n",
    "if os.path.exists(compat) and compat not in sys.path:\n",
    "    sys.path.insert(0, compat)\n",
    "# ensure sys.modules has torchvision.transforms.functional_tensor to bypass package-level lookup\n",
    "modname = 'torchvision.transforms.functional_tensor'\n",
    "if modname not in sys.modules:\n",
    "    try:\n",
    "        from torchvision import transforms as _trans\n",
    "        try:\n",
    "            _func = _trans.functional\n",
    "        except Exception:\n",
    "            _func = None\n",
    "        mod = types.ModuleType(modname)\n",
    "        if _func is not None:\n",
    "            rgb = getattr(_func, 'rgb_to_grayscale', None)\n",
    "            conv = getattr(_func, 'convert_image_dtype', None)\n",
    "            if rgb is not None:\n",
    "                mod.rgb_to_grayscale = rgb\n",
    "            if conv is not None:\n",
    "                mod.convert_image_dtype = conv\n",
    "        # fallbacks\n",
    "        if not hasattr(mod, 'rgb_to_grayscale'):\n",
    "            def _rgb_fail(x):\n",
    "                raise ImportError('rgb_to_grayscale not available')\n",
    "            mod.rgb_to_grayscale = _rgb_fail\n",
    "        if not hasattr(mod, 'convert_image_dtype'):\n",
    "            def _conv_fail(x, dtype):\n",
    "                raise ImportError('convert_image_dtype not available')\n",
    "            mod.convert_image_dtype = _conv_fail\n",
    "        sys.modules[modname] = mod\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# get target script and args\n",
    "if len(sys.argv) < 2:\n",
    "    print('inject_and_exec: missing script argument', file=sys.stderr)\n",
    "    sys.exit(2)\n",
    "script = sys.argv[1]\n",
    "args = sys.argv[2:]\n",
    "base = os.path.basename(script)\n",
    "\n",
    "if base == 'inference_realesrgan.py':\n",
    "    # infer netscale from args (look for -n NAME or -s SCALE) or env\n",
    "    joined = [script] + args\n",
    "    netscale = None\n",
    "    for i, a in enumerate(joined):\n",
    "        if a in ('-n', '--name', '--model') and i+1 < len(joined):\n",
    "            m = re.match(r\"(\\d+)x\", joined[i+1])\n",
    "            if m:\n",
    "                try:\n",
    "                    netscale = int(m.group(1))\n",
    "                    break\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if netscale is None:\n",
    "        for i, a in enumerate(joined):\n",
    "            if a in ('-s', '--scale') and i+1 < len(joined):\n",
    "                try:\n",
    "                    netscale = int(joined[i+1])\n",
    "                    break\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if netscale is None:\n",
    "        netscale = int(os.environ.get('NETSCALE') or os.environ.get('SCALE') or 4)\n",
    "    # read and exec with prepared globals so netscale is defined\n",
    "    try:\n",
    "        with open(script, 'r', encoding='utf-8') as f:\n",
    "            code = f.read()\n",
    "        _globals = {'__name__': '__main__', '__file__': script, 'netscale': netscale, 'scale': netscale, 'outscale': netscale}\n",
    "        _globals['sys'] = sys\n",
    "        sys.argv = [script] + args\n",
    "        exec(compile(code, script, 'exec'), _globals)\n",
    "    except Exception:\n",
    "        # fallback to runpy if exec fails\n",
    "        sys.argv = [script] + args\n",
    "        runpy.run_path(script, run_name='__main__')\n",
    "else:\n",
    "    # generic path: just run\n",
    "    sys.argv = [script] + args\n",
    "    runpy.run_path(script, run_name='__main__')\n",
    "'''\n",
    "            with open(inject_path, 'w', encoding='utf-8') as inf:\n",
    "                inf.write(inject_code)\n",
    "            os.chmod(inject_path, 0o755)\n",
    "            print('Wrote injector script to', inject_path)\n",
    "        except Exception as _e:\n",
    "            print('Could not write injector script:', _e)\n",
    "\n",
    "        # Decide command to execute: prefer wrapper so compat is injected before any import\n",
    "        exec_cmd = None\n",
    "        if run_cmd and len(run_cmd) >= 2 and (run_cmd[1].endswith('inference_realesrgan.py') or run_cmd[1].endswith('inference_with_shim_full.py')) and os.path.exists(wrapper_path):\n",
    "            # pass the target script path as the first argument to wrapper\n",
    "            exec_cmd = [run_cmd[0], wrapper_path, run_cmd[1]] + run_cmd[2:]\n",
    "        else:\n",
    "            exec_cmd = run_cmd\n",
    "\n",
    "        # Force execution to use the injector script so module injection happens before imports\n",
    "        exec_cmd = None\n",
    "        if run_cmd and len(run_cmd) >= 2 and (run_cmd[1].endswith('inference_realesrgan.py') or run_cmd[1].endswith('inference_with_shim_full.py')) and os.path.exists(inject_path):\n",
    "            # build command: [python, inject_and_exec.py, target_script] + original args after the script\n",
    "            exec_cmd = [run_cmd[0], inject_path, run_cmd[1]] + run_cmd[2:]\n",
    "        else:\n",
    "            exec_cmd = run_cmd\n",
    "\n",
    "        # Run process with env and cwd\n",
    "        if run_cwd:\n",
    "            res = subprocess.run(exec_cmd, capture_output=True, text=True, timeout=3600, cwd=run_cwd, env=env)\n",
    "        else:\n",
    "            res = subprocess.run(exec_cmd, capture_output=True, text=True, timeout=3600, env=env)\n",
    "\n",
    "        dur = time.time() - start\n",
    "        print('Return code =', res.returncode, 'duration=', dur)\n",
    "        stderr_tail = (res.stderr or '')[:8000]\n",
    "        with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n",
    "            lf.write('\\n=== ATTEMPT STDOUT ===\\n')\n",
    "            lf.write(res.stdout or '')\n",
    "            lf.write('\\n=== ATTEMPT STDERR ===\\n')\n",
    "            lf.write(res.stderr or '')\n",
    "        print('\\n--- subprocess stderr tail ---\\n')\n",
    "        print(stderr_tail)\n",
    "        globals()['last_inference_stderr'] = res.stderr\n",
    "\n",
    "        # Determine whether a retry is needed\n",
    "        need_retry = False\n",
    "        if res.returncode != 0:\n",
    "            err = (res.stderr or '').lower()\n",
    "            if 'unboundlocalerror' in err or 'netscale' in err or 'local variable' in err:\n",
    "                need_retry = True\n",
    "            if 'no module named \"torchvision.transforms.functional_tensor\"' in err or 'no module named \\'torchvision.transforms.functional_tensor\\'' in err or ('functional_tensor' in err and 'module' in err):\n",
    "                need_retry = True\n",
    "\n",
    "        # Retry path with augmented flags and same env\n",
    "        if need_retry:\n",
    "            print('\\nDetected netscale/unboundlocal error or missing functional_tensor; retrying with explicit flags and env override...')\n",
    "            aug_cmd = list(run_cmd)\n",
    "            if '-s' not in aug_cmd:\n",
    "                aug_cmd += ['-s', '4']\n",
    "            if '--outscale' not in aug_cmd:\n",
    "                aug_cmd += ['--outscale', '4']\n",
    "            env.update({'NETSCALE': '4', 'SCALE': '4', 'OUTSCALE': '4'})\n",
    "            print('Retry command:', aug_cmd)\n",
    "            try:\n",
    "                # If injector is available, run aug_cmd through it to ensure compat shim and netscale injection\n",
    "                if run_cwd:\n",
    "                    possible_inject = os.path.join(run_cwd, 'inject_and_exec.py')\n",
    "                else:\n",
    "                    possible_inject = os.path.join(os.getcwd(), 'inject_and_exec.py')\n",
    "                if os.path.exists(possible_inject) and len(aug_cmd) >= 2:\n",
    "                    target_script = aug_cmd[1]\n",
    "                    augmented_args = aug_cmd[2:]\n",
    "                    exec_aug_cmd = [aug_cmd[0], possible_inject, target_script] + augmented_args\n",
    "                else:\n",
    "                    exec_aug_cmd = aug_cmd\n",
    "                if run_cwd:\n",
    "                    res2 = subprocess.run(exec_aug_cmd, capture_output=True, text=True, timeout=3600, cwd=run_cwd, env=env)\n",
    "                else:\n",
    "                    res2 = subprocess.run(exec_aug_cmd, capture_output=True, text=True, timeout=3600, env=env)\n",
    "                dur2 = time.time() - start\n",
    "                print('Retry return code =', res2.returncode, 'duration=', dur2)\n",
    "                with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n",
    "                    lf.write('\\n=== RETRY STDOUT ===\\n')\n",
    "                    lf.write(res2.stdout or '')\n",
    "                    lf.write('\\n=== RETRY STDERR ===\\n')\n",
    "                    lf.write(res2.stderr or '')\n",
    "                print('\\n--- retry stderr tail ---\\n')\n",
    "                print((res2.stderr or '')[:8000])\n",
    "                globals()['last_inference_stderr'] = res2.stderr\n",
    "            except Exception as e2:\n",
    "                print('Retry attempt failed to execute:', e2)\n",
    "    except Exception as e:\n",
    "        print('Run failed:', e)\n",
    "else:\n",
    "    print('Dry-run: not executing. Set retry_now = True and re-run this cell to execute the prepared run_cmd.')"
   ],
   "id": "cb1d918457e5c232"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 9) Move upscaled frames into frames dir if present (safe rename)\n",
    "import os, shutil, glob\n",
    "UP_DIR = str(FRAMES_DIR) + '_upscaled'\n",
    "if os.path.exists(UP_DIR):\n",
    "    print('Found upscaled dir -> moving into frames')\n",
    "    try:\n",
    "        # remove old frames (be careful)\n",
    "        shutil.rmtree(str(FRAMES_DIR), ignore_errors=True)\n",
    "        shutil.move(UP_DIR, str(FRAMES_DIR))\n",
    "        # optional rename of *_out.png to index.png\n",
    "        ups = sorted(glob.glob(str(FRAMES_DIR) + '/*'))\n",
    "        for i,p in enumerate(ups):\n",
    "            try: os.rename(p, os.path.join(str(FRAMES_DIR), f'{i}.png'))\n",
    "            except Exception: pass\n",
    "        print('Moved and normalized upscaled frames')\n",
    "    except Exception as e:\n",
    "        print('Error moving upscaled frames:', e)\n",
    "else:\n",
    "    print('No upscaled frames dir found (run Real-ESRGAN first)')"
   ],
   "id": "739804ef91fa0c3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Завершение — краткий отчет",
   "id": "342d1b5d931f545e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print('Workflow ready.\\n- Generate frames (AnimateDiff or SDXL).\\n- Optionally write/verify shim (cell 6).\\n- Prepare repo and weights (cell 7).\\n- Run upscale with run_cmd (cell 8, set retry_now=True).')",
   "id": "8c2a15a027293663"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === AUTO: install + write shim + run (one-click, safe by default) ===\n",
    "# Usage: set confirm=True and other flags below, then run this cell.\n",
    "import os, sys, subprocess, textwrap, time, shutil\n",
    "from pathlib import Path\n",
    "# --- User-configurable flags (safe defaults) ---\n",
    "confirm = False        # must be True to perform actions\n",
    "install = False        # whether to pip install required packages\n",
    "run = False            # whether to run the inference after setup\n",
    "restart_kernel = False # if True, attempt to request a kernel restart at the end (may require manual confirm)\n",
    "# packages to install when install=True\n",
    "deps = ['basicsr', 'facexlib', 'gfpgan', 'realesrgan']\n",
    "# Paths and args (adjust if needed)\n",
    "WORKSPACE = '/kaggle/working'\n",
    "REPO_DIR = os.path.join(WORKSPACE, 'Real-ESRGAN')\n",
    "SHIM_PATH = os.path.join(REPO_DIR, 'inference_with_shim_full.py')\n",
    "FALLBACK_SHIM = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\n",
    "INFERENCE_LOG = os.path.join(WORKSPACE, 'logs', 'real_esrgan_inference.log')\n",
    "os.makedirs(os.path.dirname(INFERENCE_LOG), exist_ok=True)\n",
    "# Default run args for shim (modify before confirm=True if needed)\n",
    "frames_dir = str(Path(WORKSPACE) / 'frames')\n",
    "run_args = ['-n', '4x-UltraSharp', '-i', frames_dir, '-o', frames_dir + '_upscaled', '--fp32', '--outscale', '4']\n",
    "# Shim content (kept minimal and safe; generated via dedent)\n",
    "SHIM = textwrap.dedent('''\n",
    "    import sys\n",
    "    import os\n",
    "    import types\n",
    "    import re\n",
    "    import runpy\n",
    "\n",
    "    try:\n",
    "        import torchvision.transforms.functional_tensor as _ft\n",
    "    except Exception:\n",
    "        try:\n",
    "            import torchvision.transforms.functional as _f\n",
    "            mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\n",
    "            mod_ft.rgb_to_grayscale = getattr(_f, 'rgb_to_grayscale', None)\n",
    "            mod_ft.convert_image_dtype = getattr(_f, 'convert_image_dtype', None)\n",
    "            sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\n",
    "        except Exception:\n",
    "            mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\n",
    "            def _rgb_to_grayscale(x):\n",
    "                raise ImportError('rgb_to_grayscale not available')\n",
    "            def _convert_image_dtype(x, dtype):\n",
    "                raise ImportError('convert_image_dtype not available')\n",
    "            mod_ft.rgb_to_grayscale = _rgb_to_grayscale\n",
    "            mod_ft.convert_image_dtype = _convert_image_dtype\n",
    "            sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\n",
    "\n",
    "    if 'torchvision.utils' not in sys.modules:\n",
    "        mod_utils = types.ModuleType('torchvision.utils')\n",
    "        def make_grid(x, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0):\n",
    "            try:\n",
    "                if isinstance(x, (list, tuple)) and len(x) > 0:\n",
    "                    return x[0]\n",
    "                return x\n",
    "            except Exception:\n",
    "                return x\n",
    "        mod_utils.make_grid = make_grid\n",
    "        sys.modules['torchvision.utils'] = mod_utils\n",
    "\n",
    "    if 'realesrgan.version' not in sys.modules:\n",
    "        vermod = types.ModuleType('realesrgan.version')\n",
    "        vermod.__version__ = '0.3.0'\n",
    "        vermod.__all__ = ['__version__']\n",
    "        sys.modules['realesrgan.version'] = vermod\n",
    "\n",
    "    def _infer_netscale(argv):\n",
    "        for i, a in enumerate(argv):\n",
    "            if a in ('-n', '--name', '--model') and i+1 < len(argv):\n",
    "                m = re.match(r\"(\\\\d+)x\", argv[i+1])\n",
    "                if m:\n",
    "                    try:\n",
    "                        return int(m.group(1))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "        for i, a in enumerate(argv):\n",
    "            if a in ('-s', '--scale') and i+1 < len(argv):\n",
    "                try:\n",
    "                    return int(argv[i+1])\n",
    "                except Exception:\n",
    "                    pass\n",
    "        return 4\n",
    "\n",
    "    def _detect_weight_file():\n",
    "        try:\n",
    "            wdir = os.path.join(os.getcwd(), 'weights')\n",
    "            if not os.path.isdir(wdir):\n",
    "                return None\n",
    "            exts = ('.pth', '.pt', '.safetensors')\n",
    "            candidates = [f for f in os.listdir(wdir) if f.lower().endswith(exts)]\n",
    "            if not candidates:\n",
    "                return None\n",
    "            for name in candidates:\n",
    "                if '4x' in name.lower() or 'ultrasharp' in name.lower():\n",
    "                    return os.path.join(wdir, name)\n",
    "            return os.path.join(wdir, candidates[0])\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        argv = sys.argv[1:]\n",
    "        netscale = _infer_netscale(argv)\n",
    "        detected_model = _detect_weight_file()\n",
    "        script_path = os.path.join(os.getcwd(), 'inference_realesrgan.py')\n",
    "        try:\n",
    "            with open(script_path, 'r', encoding='utf-8') as _f:\n",
    "                _code = _f.read()\n",
    "        except Exception:\n",
    "            sys.argv = [script_path] + argv\n",
    "            runpy.run_path('inference_realesrgan.py', run_name='__main__')\n",
    "        else:\n",
    "            _globals = {'__name__': '__main__', '__file__': script_path, 'netscale': netscale, 'model': detected_model, 'outscale': netscale, 'scale': netscale}\n",
    "            _globals['sys'] = sys\n",
    "            sys.argv = [script_path] + argv\n",
    "            exec(compile(_code, script_path, 'exec'), _globals)\n",
    "    ''')\n",
    "# --- helper funcs ---\n",
    "\n",
    "def safe_run(cmd, timeout=3600):\n",
    "    try:\n",
    "        return subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)\n",
    "    except Exception as e:\n",
    "        return type('R', (), {'returncode': 99, 'stdout': '', 'stderr': str(e)})()\n",
    "# --- main flow (safe guard) ---\n",
    "print('Auto-block status: confirm=', confirm, 'install=', install, 'run=', run, 'restart_kernel=', restart_kernel)\n",
    "if not confirm:\n",
    "    print('Run aborted: set confirm = True after reviewing flags and paths (this cell is safe by default).')\n",
    "    print('\\nPaths to check:')\n",
    "    print('  WORKSPACE =', WORKSPACE)\n",
    "    print('  REPO_DIR =', REPO_DIR)\n",
    "    print('  SHIM_PATH =', SHIM_PATH)\n",
    "    print('  INFERENCE_LOG =', INFERENCE_LOG)\n",
    "    print('  frames_dir (input) =', frames_dir)\n",
    "    print('  proposed run args =', run_args)\n",
    "else:\n",
    "    # 1) optionally install deps\n",
    "    if install:\n",
    "        print('Installing packages:', deps)\n",
    "        r = safe_run([sys.executable, '-m', 'pip', 'install', '-q'] + deps, timeout=1800)\n",
    "        print('pip exit', r.returncode)\n",
    "    # 2) write shim to SHIM_PATH (try workspace, fallback to cwd)\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(SHIM_PATH), exist_ok=True)\n",
    "        with open(SHIM_PATH, 'w', encoding='utf-8', newline='\\n') as f:\n",
    "            f.write(SHIM)\n",
    "        py_compile.compile(SHIM_PATH, doraise=True)\n",
    "        used_shim = SHIM_PATH\n",
    "        print('Wrote shim to', SHIM_PATH)\n",
    "    except Exception as e:\n",
    "        print('Could not write to', SHIM_PATH, '-> falling back to', FALLBACK_SHIM, '; reason:', e)\n",
    "        with open(FALLBACK_SHIM, 'w', encoding='utf-8') as f:\n",
    "            f.write(SHIM)\n",
    "        used_shim = FALLBACK_SHIM\n",
    "        print('Wrote shim to fallback', FALLBACK_SHIM)\n",
    "    # 3) ensure repo exists (clone if missing)\n",
    "    if not os.path.exists(REPO_DIR):\n",
    "        print('Real-ESRGAN repo missing; attempting to clone into', REPO_DIR)\n",
    "        rc = safe_run(['git', 'clone', 'https://github.com/xinntao/Real-ESRGAN', REPO_DIR], timeout=900)\n",
    "        print('git clone rc=', rc.returncode)\n",
    "    # 4) copy candidate weight from common dataset mount (if present)\n",
    "    candidate = os.path.join('/kaggle/input/comfyui-models-gojo', '4x-UltraSharp.pth')\n",
    "    if os.path.exists(candidate) and os.path.exists(REPO_DIR):\n",
    "        try:\n",
    "            wd = os.path.join(REPO_DIR, 'weights')\n",
    "            os.makedirs(wd, exist_ok=True)\n",
    "            shutil.copy(candidate, wd)\n",
    "            print('Copied weight into', wd)\n",
    "        except Exception as e:\n",
    "            print('Failed to copy weight:', e)\n",
    "    # 5) prepare run_cmd using used_shim (shim inside repo preferred)\n",
    "    if os.path.exists(used_shim):\n",
    "        run_cmd = [sys.executable, used_shim] + run_args\n",
    "    else:\n",
    "        run_cmd = None\n",
    "    print('Prepared run_cmd:', run_cmd)\n",
    "    # 6) optionally run and capture logs\n",
    "    if run and run_cmd:\n",
    "        print('Executing run_cmd (timeout=3600s)...')\n",
    "        r = safe_run(run_cmd, timeout=3600)\n",
    "        print('Return code =', r.returncode)\n",
    "        try:\n",
    "            with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n",
    "                lf.write('\\n=== AUTO ATTEMPT STDOUT ===\\n')\n",
    "                lf.write(r.stdout or '')\n",
    "                lf.write('\\n=== AUTO ATTEMPT STDERR ===\\n')\n",
    "                lf.write(r.stderr or '')\n",
    "        except Exception as _e:\n",
    "            print('Could not write inference log:', _e)\n",
    "    elif run:\n",
    "        print('run requested but run_cmd is not prepared; check shim/repo')\n",
    "    # 7) optionally request kernel restart (best effort)\n",
    "    if restart_kernel:\n",
    "        print('Attempting programmatic kernel restart (may require manual confirm in Kaggle UI)...')\n",
    "        try:\n",
    "            from IPython.display import display, Javascript\n",
    "            display(Javascript('Jupyter.notebook.kernel.restart()'))\n",
    "            print('Kernel restart requested. If notebook does не restart автоматически, пожалуйста используйте Kernel -> Restart in the UI.')\n",
    "        except Exception as _e:\n",
    "            print('Programmatic restart not available; please restart kernel manually via UI:', _e)"
   ],
   "id": "6115193322fd6fbd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# OPTIONAL: Install papermill & nbconvert in the current environment (run this in Kaggle if you need to run notebooks programmatically)\n",
    "# Run only when you want to enable papermill-based execution (this may install packages and take a few minutes).\n",
    "# Set confirm_install = True to actually run the install, otherwise this cell just prints инструкции.\n",
    "confirm_install = False\n",
    "if not confirm_install:\n",
    "    print('To enable papermill execution, set confirm_install = True and run this cell; it will install papermill, nbconvert and jupyter_client.')\n",
    "else:\n",
    "    import subprocess, sys\n",
    "    pkgs = ['papermill', 'nbconvert', 'jupyter_client']\n",
    "    print('Installing:', pkgs)\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + pkgs)\n",
    "    print('Installed papermill and related packages. You can now run papermill-based execution.\\n           Example:')\n",
    "    print('  python /apps/ComfyCloud_My_Work_Flow/run_notebook_safe.py <input.ipynb> <output.ipynb> --kernel python3')\n",
    "```\n"
   ],
   "id": "3b79ad337c433c52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
