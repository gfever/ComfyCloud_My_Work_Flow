{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Comfy Gojo — компактный и надёжный Kaggle workflow\\n\",\n",
    "    \"\\n\",\n",
    "    \"Этот ноутбук — упрощённая, исправленная и оптимизированная версия вашего `kaggle-simple-cells-v4` для запуска в Kaggle.\\n\",\n",
    "    \"Цели:\\n\",\n",
    "    \"- Настроить окружение (безопасно для XLA/TensorFlow/JAX)\\n\",\n",
    "    \"- Подготовить и сохранить prompts.json\\n\",\n",
    "    \"- Сгенерировать кадры (AnimateDiff или Stable Diffusion),\\n\",\n",
    "    \"- Надёжно подготовить shim для Real-ESRGAN и выполнить апскейл (опционально),\\n\",\n",
    "    \"- Логирование и понятная отладка при ошибках.\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 1) ENV: установить переменные до любых heavy импортов (выполните сразу)\\n\",\n",
    "    \"import os, importlib\\n\",\n",
    "    \"_changed = False\\n\",\n",
    "    \"def _set(k,v):\\n\",\n",
    "    \"    global _changed\\n\",\n",
    "    \"    if os.environ.get(k) != v:\\n\",\n",
    "    \"        os.environ[k] = v\\n\",\n",
    "    \"        _changed = True\\n\",\n",
    "    \"# подавляем XLA/TensorFlow шумы\\n\",\n",
    "    \"_set('TF_CPP_MIN_LOG_LEVEL','3')\\n\",\n",
    "    \"_set('XLA_PYTHON_CLIENT_PREALLOCATE','false')\\n\",\n",
    "    \"_set('XLA_PYTHON_CLIENT_MEM_FRACTION','0.0')\\n\",\n",
    "    \"_set('JAX_PLATFORM_NAME','cpu')\\n\",\n",
    "    \"_set('JAX_PLATFORMS','cpu')\\n\",\n",
    "    \"print('ENV set. Restart kernel AFTER you change these and BEFORE importing heavy libs if _changed = True')\\n\",\n",
    "    \"print('changed_env =', _changed)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 2) KAGGLE checks: basic hints and GPU info\\n\",\n",
    "    \"import os, sys, importlib, subprocess, json\\n\",\n",
    "    \"print('Running in Kaggle:', any(p.startswith('/kaggle') for p in (os.getcwd(),)) or os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None)\\n\",\n",
    "    \"# lightweight torch check (subprocess to avoid heavy import delays)\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    cmd = [sys.executable, '-c', 'import torch, json; print(json.dumps({\"cuda\": torch.cuda.is_available(), \"device_count\": torch.cuda.device_count(), \"name\": (torch.cuda.get_device_name(0).strip() if torch.cuda.is_available() else \"no gpu\")}))']\\n\",\n",
    "    \"    res = subprocess.run(cmd, capture_output=True, text=True, timeout=12)\\n\",\n",
    "    \"    print('torch probe:', res.stdout.strip())\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print('Torch probe skipped:', e)\\n\",\n",
    "    \"# HF token hint\\n\",\n",
    "    \"print('HF token present in env:', bool(os.environ.get('HUGGINGFACE_HUB_TOKEN') or os.environ.get('HF_TOKEN')))\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 3) Optional: install deps (uncomment to run)\\n\",\n",
    "    \"# Для ускорения повторных запусков — выполняйте только при отсутствии пакетов\\n\",\n",
    "    \"# !pip install -q diffusers[torch] transformers accelerate imageio imageio-ffmpeg ipywidgets opencv-python\\n\",\n",
    "    \"# Если планируете запуск Real-ESRGAN:\\n\",\n",
    "    \"# !pip install -q basicsr facexlib gfpgan realesrgan\\n\",\n",
    "    \"print('Deps: оставлены как опция — устанавливайте вручную при необходимости')\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Prompts — редактируемая часть (меняйте только здесь)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 4) Prompts: сохранение и короткая GUI fallback\\n\",\n",
    "    \"import json, os\\n\",\n",
    "    \"PROMPTS = {\\n\",\n",
    "    \"  'BASE_PROMPT': 'cinematic portrait of gojo satoru, white spiky hair, black blindfold, confident expression, anime style, highly detailed',\\n\",\n",
    "    \"  'MOTION_PROMPT': 'turning head, hair flowing, smooth motion',\\n\",\n",
    "    \"  'EXTRA_PROMPT': 'dramatic rim lighting, soft bloom',\\n\",\n",
    "    \"  'NEGATIVE_PROMPT': 'blurry, deformed, watermark, text, bad anatomy'\\n\",\n",
    "    \"}\\n\",\n",
    "    \"with open('prompts.json','w',encoding='utf-8') as f:\\n\",\n",
    "    \"    json.dump(PROMPTS,f,ensure_ascii=False,indent=2)\\n\",\n",
    "    \"print('Saved prompts.json (edit PROMPTS dict above to change)')\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Генерация (AnimateDiff или SDXL) — запустите только нужную ячейку\" \n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 5a) AnimateDiff generation (fast path) — включите/настройте флаги и запустите\\n\",\n",
    "    \"USE_ANIMATEDIFF = True\\n\",\n",
    "    \"NUM_FRAMES = 8\\n\",\n",
    "    \"WIDTH = 512\\n\",\n",
    "    \"HEIGHT = 768\\n\",\n",
    "    \"STEPS = 20\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"FRAMES_DIR = Path('/kaggle/working/frames')\\n\",\n",
    "    \"FRAMES_DIR.mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"if USE_ANIMATEDIFF:\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\\n\",\n",
    "    \"        import torch\\n\",\n",
    "    \"        adapter = MotionAdapter.from_pretrained('guoyww/animatediff-motion-adapter-v1-5-2', torch_dtype=torch.float16)\\n\",\n",
    "    \"        pipe = AnimateDiffPipeline.from_pretrained('runwayml/stable-diffusion-v1-5', motion_adapter=adapter, torch_dtype=torch.float16).to('cuda')\\n\",\n",
    "    \"        pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\\n\",\n",
    "    \"        pipe.enable_vae_slicing(); pipe.enable_model_cpu_offload()\\n\",\n",
    "    \"        out = pipe(prompt= (open('prompts.json','r',encoding='utf-8').read()), num_frames=NUM_FRAMES, width=WIDTH, height=HEIGHT, num_inference_steps=STEPS, guidance_scale=7.5, generator=torch.Generator('cuda').manual_seed(42))\\n\",\n",
    "    \"        frames = out.frames[0]\\n\",\n",
    "    \"        for i,im in enumerate(frames):\\n\",\n",
    "    \"            im.save(FRAMES_DIR / f'{i}.png')\\n\",\n",
    "    \"        print('Saved', len(frames), 'frames to', FRAMES_DIR)\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print('AnimateDiff failed:', e)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print('AnimateDiff disabled — run SDXL cell instead')\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 5b) SDXL static frame generation (alternative) — uncomment to use instead of AnimateDiff\\n\",\n",
    "    \"# from diffusers import StableDiffusionXLPipeline\\n\",\n",
    "    \"# import torch\\n\",\n",
    "    \"# pipe = StableDiffusionXLPipeline.from_pretrained('stabilityai/stable-diffusion-xl-base-1.0', torch_dtype=torch.float16).to('cuda')\\n\",\n",
    "    \"# pipe.enable_attention_slicing(); pipe.enable_vae_slicing()\\n\",\n",
    "    \"# for i in range(NUM_FRAMES):\\n\",\n",
    "    \"#     img = pipe(prompt=... ).images[0]; img.save(FRAMES_DIR / f'{i}.png')\\n\",\n",
    "    \"# print('Saved static frames')\\n\",\n",
    "    \"print('SDXL cell ready as alternative — uncomment to run')\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Real-ESRGAN upscaling — надежная подготовка shim и запуск\" \n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 6) Robust shim writer (writes to /kaggle/working/Real-ESRGAN/inference_with_shim_full.py or falls back)\\n\",\n",
    "    \"import os, textwrap, py_compile\\n\",\n",
    "    \"OUT_DIR = '/kaggle/working/Real-ESRGAN'\\n\",\n",
    "    \"OUT_PATH = os.path.join(OUT_DIR, 'inference_with_shim_full.py')\\n\",\n",
    "    \"SHIM = textwrap.dedent('''\\n    import sys\\n    import os\\n    import types\\n    import re\\n    import runpy\\n    \\n    try:\\n        import torchvision.transforms.functional_tensor as _ft\\n    except Exception:\\n        try:\\n            import torchvision.transforms.functional as _f\\n            mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\\n            mod_ft.rgb_to_grayscale = getattr(_f, 'rgb_to_grayscale', None)\\n            mod_ft.convert_image_dtype = getattr(_f, 'convert_image_dtype', None)\\n            sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\\n        except Exception:\\n            mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\\n            def _rgb_to_grayscale(x):\\n                raise ImportError('rgb_to_grayscale not available')\\n            def _convert_image_dtype(x, dtype):\\n                raise ImportError('convert_image_dtype not available')\\n            mod_ft.rgb_to_grayscale = _rgb_to_grayscale\\n            mod_ft.convert_image_dtype = _convert_image_dtype\\n            sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\\n    \\n    if 'torchvision.utils' not in sys.modules:\\n        mod_utils = types.ModuleType('torchvision.utils')\\n        def make_grid(x, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0):\\n            try:\\n                if isinstance(x, (list, tuple)) and len(x) > 0:\\n                    return x[0]\\n                return x\\n            except Exception:\\n                return x\\n        mod_utils.make_grid = make_grid\\n        sys.modules['torchvision.utils'] = mod_utils\\n    \\n    if 'realesrgan.version' not in sys.modules:\\n        vermod = types.ModuleType('realesrgan.version')\\n        vermod.__version__ = '0.3.0'\\n        vermod.__all__ = ['__version__']\\n        sys.modules['realesrgan.version'] = vermod\\n    \\n    def _infer_netscale(argv):\\n        for i, a in enumerate(argv):\\n            if a in ('-n', '--name', '--model') and i+1 < len(argv):\\n                m = re.match(r\"(\\\\d+)x\", argv[i+1])\\n                if m:\\n                    try:\\n                        return int(m.group(1))\\n                    except Exception:\\n                        pass\\n        for i, a in enumerate(argv):\\n            if a in ('-s', '--scale') and i+1 < len(argv):\\n                try:\\n                    return int(argv[i+1])\\n                except Exception:\\n                    pass\\n        return 4\\n    \\n    def _detect_weight_file():\\n        try:\\n            wdir = os.path.join(os.getcwd(), 'weights')\\n            if not os.path.isdir(wdir):\\n                return None\\n            exts = ('.pth', '.pt', '.safetensors')\\n            candidates = [f for f in os.listdir(wdir) if f.lower().endswith(exts)]\\n            if not candidates:\\n                return None\\n            for name in candidates:\\n                if '4x' in name.lower() or 'ultrasharp' in name.lower():\\n                    return os.path.join(wdir, name)\\n            return os.path.join(wdir, candidates[0])\\n        except Exception:\\n            return None\\n    \\n    if __name__ == '__main__':\\n        argv = sys.argv[1:]\\n        netscale = _infer_netscale(argv)\\n        detected_model = _detect_weight_file()\\n        script_path = os.path.join(os.getcwd(), 'inference_realesrgan.py')\\n        try:\\n            with open(script_path, 'r', encoding='utf-8') as _f:\\n                _code = _f.read()\\n        except Exception:\\n            sys.argv = [script_path] + argv\\n            runpy.run_path('inference_realesrgan.py', run_name='__main__')\\n        else:\\n            _globals = {'__name__': '__main__', '__file__': script_path, 'netscale': netscale, 'model': detected_model, 'outscale': netscale, 'scale': netscale}\\n            _globals['sys'] = sys\\n            sys.argv = [script_path] + argv\\n            exec(compile(_code, script_path, 'exec'), _globals)\\n    ''')\\n\",\n",
    "    \"# write shim with safe fallbacks\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    os.makedirs(OUT_DIR, exist_ok=True)\\n\",\n",
    "    \"    with open(OUT_PATH, 'w', encoding='utf-8', newline='\\n') as f:\\n\",\n",
    "    \"        f.write(SHIM)\\n\",\n",
    "    \"    py_compile.compile(OUT_PATH, doraise=True)\\n\",\n",
    "    \"    print('Shim written and compiled:', OUT_PATH)\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    fallback = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\\n\",\n",
    "    \"    with open(fallback, 'w', encoding='utf-8') as f:\\n\",\n",
    "    \"        f.write(SHIM)\\n\",\n",
    "    \"    print('Fallback shim written to', fallback, 'due to', e)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 7) Prepare Real-ESRGAN repo, copy weights and prepare run_cmd (do not auto-run)\\n\",\n",
    "    \"import os, shutil, subprocess, sys\\n\",\n",
    "    \"WORKSPACE = '/kaggle/working'\\n\",\n",
    "    \"REPO_DIR = os.path.join(WORKSPACE, 'Real-ESRGAN')\\n\",\n",
    "    \"UPSCALE_MODEL_NAME = '4x-UltraSharp.pth'\\n\",\n",
    "    \"# candidate weight in datasets (adjust to your dataset mount)\\n\",\n",
    "    \"c1 = os.path.join('/kaggle/input/comfyui-models-gojo', UPSCALE_MODEL_NAME)\\n\",\n",
    "    \"weights_copied = False\\n\",\n",
    "    \"if os.path.exists(c1) and os.path.exists(REPO_DIR):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        wd = os.path.join(REPO_DIR, 'weights')\\n\",\n",
    "    \"        os.makedirs(wd, exist_ok=True)\\n\",\n",
    "    \"        shutil.copy(c1, wd)\\n\",\n",
    "    \"        weights_copied = True\\n\",\n",
    "    \"        print('Copied weight to', wd)\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print('Failed to copy weight:', e)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print('Either dataset weight or Real-ESRGAN repo missing; you may need to clone or attach dataset')\\n\",\n",
    "    \"# Build run_cmd (shim preferred)\\n\",\n",
    "    \"shim_path = os.path.join(REPO_DIR, 'inference_with_shim_full.py')\\n\",\n",
    "    \"if os.path.exists(shim_path):\\n\",\n",
    "    \"    run_cmd = [sys.executable, shim_path, '-n', '4x-UltraSharp', '-i', str(FRAMES_DIR), '-o', str(FRAMES_DIR) + '_upscaled', '--fp32', '--outscale', '4']\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    run_cmd = None\\n\",\n",
    "    \"print('Prepared run_cmd:', run_cmd)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 8) Debug + optional retry runner for Real-ESRGAN (replacement for fragile cells)\\n\",\n",
    "    \"import os, subprocess, time\\n\",\n",
    "    \"def tail(path, max_chars=8000):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        with open(path, 'r', encoding='utf-8', errors='replace') as f:\\n\",\n",
    "    \"            data = f.read()\\n\",\n",
    "    \"        return data[-max_chars:]\\n\",\n",
    "    \"    except Exception:\\n\",\n",
    "    \"        return ''\\n\",\n",
    "    \"INFERENCE_LOG = os.path.join('/kaggle/working', 'logs', 'real_esrgan_inference.log')\\n\",\n",
    "    \"os.makedirs(os.path.dirname(INFERENCE_LOG), exist_ok=True)\\n\",\n",
    "    \"print('INFERENCE_LOG ->', INFERENCE_LOG)\\n\",\n",
    "    \"if 'run_cmd' not in globals() or not run_cmd:\\n\",\n",
    "    \"    print('run_cmd not prepared; make sure Real-ESRGAN repo is cloned and shim exists (see previous cell)')\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print('Ready to run. Set retry_now=True below to actually execute.')\\n\",\n",
    "    \"    retry_now = False  # set True to run in this cell\\n\",\n",
    "    \"    if retry_now:\\n\",\n",
    "    \"        print('Running run_cmd...')\\n\",\n",
    "    \"        start = time.time()\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            res = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600)\\n\",\n",
    "    \"            dur = time.time() - start\\n\",\n",
    "    \"            print('Return code =', res.returncode, 'duration=', dur)\\n\",\n",
    "    \"            with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\\n\",\n",
    "    \"                lf.write('\\n=== ATTEMPT STDOUT ===\\n')\\n\",\n",
    "    \"                lf.write(res.stdout or '')\\n\",\n",
    "    \"                lf.write('\\n=== ATTEMPT STDERR ===\\n')\\n\",\n",
    "    \"                lf.write(res.stderr or '')\\n\",\n",
    "    \"            print('\\n--- subprocess stderr tail ---\\n')\\n\",\n",
    "    \"            print((res.stderr or '')[:8000])\\n\",\n",
    "    \"            globals()['last_inference_stderr'] = res.stderr\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            print('Run failed:', e)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print('Dry-run: no execution. To run set retry_now=True and re-run this cell.')\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# 9) Move upscaled frames into frames dir if present (safe rename)\\n\",\n",
    "    \"import os, shutil, glob\\n\",\n",
    "    \"UP_DIR = str(FRAMES_DIR) + '_upscaled'\\n\",\n",
    "    \"if os.path.exists(UP_DIR):\\n\",\n",
    "    \"    print('Found upscaled dir -> moving into frames')\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # remove old frames (be careful)\\n\",\n",
    "    \"        shutil.rmtree(str(FRAMES_DIR), ignore_errors=True)\\n\",\n",
    "    \"        shutil.move(UP_DIR, str(FRAMES_DIR))\\n\",\n",
    "    \"        # optional rename of *_out.png to index.png\\n\",\n",
    "    \"        ups = sorted(glob.glob(str(FRAMES_DIR) + '/*'))\\n\",\n",
    "    \"        for i,p in enumerate(ups):\\n\",\n",
    "    \"            try: os.rename(p, os.path.join(str(FRAMES_DIR), f'{i}.png'))\\n\",\n",
    "    \"            except Exception: pass\\n\",\n",
    "    \"        print('Moved and normalized upscaled frames')\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print('Error moving upscaled frames:', e)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print('No upscaled frames dir found (run Real-ESRGAN first)')\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Завершение — краткий отчет\" \n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print('Workflow ready.\\n- Generate frames (AnimateDiff or SDXL).\\n- Optionally write/verify shim (cell 6).\\n- Prepare repo and weights (cell 7).\\n- Run upscale with run_cmd (cell 8, set retry_now=True).')\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# === AUTO: install + write shim + run (one-click, safe by default) ===\\n\",\n",
    "    \"# Usage: set confirm=True and other flags below, then run this cell.\\n\",\n",
    "    \"import os, sys, subprocess, textwrap, time, shutil\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"# --- User-configurable flags (safe defaults) ---\\n\",\n",
    "    \"confirm = False        # must be True to perform actions\\n\",\n",
    "    \"install = False        # whether to pip install required packages\\n\",\n",
    "    \"run = False            # whether to run the inference after setup\\n\",\n",
    "    \"restart_kernel = False # if True, attempt to request a kernel restart at the end (may require manual confirm)\\n\",\n",
    "    \"# packages to install when install=True\\n\",\n",
    "    \"deps = ['basicsr', 'facexlib', 'gfpgan', 'realesrgan']\\n\",\n",
    "    \"# Paths and args (adjust if needed)\\n\",\n",
    "    \"WORKSPACE = '/kaggle/working'\\n\",\n",
    "    \"REPO_DIR = os.path.join(WORKSPACE, 'Real-ESRGAN')\\n\",\n",
    "    \"SHIM_PATH = os.path.join(REPO_DIR, 'inference_with_shim_full.py')\\n\",\n",
    "    \"FALLBACK_SHIM = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\\n\",\n",
    "    \"INFERENCE_LOG = os.path.join(WORKSPACE, 'logs', 'real_esrgan_inference.log')\\n\",\n",
    "    \"os.makedirs(os.path.dirname(INFERENCE_LOG), exist_ok=True)\\n\",\n",
    "    \"# Default run args for shim (modify before confirm=True if needed)\\n\",\n",
    "    \"frames_dir = str(Path(WORKSPACE) / 'frames')\\n\",\n",
    "    \"run_args = ['-n', '4x-UltraSharp', '-i', frames_dir, '-o', frames_dir + '_upscaled', '--fp32', '--outscale', '4']\\n\",\n",
    "    \"# Shim content (kept minimal and safe; generated via dedent)\\n\",\n",
    "    \"SHIM = textwrap.dedent('''\\n    import sys\\n    import os\\n    import types\\n    import re\\n    import runpy\\n\\n    try:\\n        import torchvision.transforms.functional_tensor as _ft\\n    except Exception:\\n        try:\\n            import torchvision.transforms.functional as _f\\n            mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\\n            mod_ft.rgb_to_grayscale = getattr(_f, 'rgb_to_grayscale', None)\\n            mod_ft.convert_image_dtype = getattr(_f, 'convert_image_dtype', None)\\n            sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\\n        except Exception:\\n            mod_ft = types.ModuleType('torchvision.transforms.functional_tensor')\\n            def _rgb_to_grayscale(x):\\n                raise ImportError('rgb_to_grayscale not available')\\n            def _convert_image_dtype(x, dtype):\\n                raise ImportError('convert_image_dtype not available')\\n            mod_ft.rgb_to_grayscale = _rgb_to_grayscale\\n            mod_ft.convert_image_dtype = _convert_image_dtype\\n            sys.modules['torchvision.transforms.functional_tensor'] = mod_ft\\n\\n    if 'torchvision.utils' not in sys.modules:\\n        mod_utils = types.ModuleType('torchvision.utils')\\n        def make_grid(x, nrow=8, padding=2, normalize=False, range=None, scale_each=False, pad_value=0):\\n            try:\\n                if isinstance(x, (list, tuple)) and len(x) > 0:\\n                    return x[0]\\n                return x\\n            except Exception:\\n                return x\\n        mod_utils.make_grid = make_grid\\n        sys.modules['torchvision.utils'] = mod_utils\\n\\n    if 'realesrgan.version' not in sys.modules:\\n        vermod = types.ModuleType('realesrgan.version')\\n        vermod.__version__ = '0.3.0'\\n        vermod.__all__ = ['__version__']\\n        sys.modules['realesrgan.version'] = vermod\\n\\n    def _infer_netscale(argv):\\n        for i, a in enumerate(argv):\\n            if a in ('-n', '--name', '--model') and i+1 < len(argv):\\n                m = re.match(r\"(\\\\d+)x\", argv[i+1])\\n                if m:\\n                    try:\\n                        return int(m.group(1))\\n                    except Exception:\\n                        pass\\n        for i, a in enumerate(argv):\\n            if a in ('-s', '--scale') and i+1 < len(argv):\\n                try:\\n                    return int(argv[i+1])\\n                except Exception:\\n                    pass\\n        return 4\\n\\n    def _detect_weight_file():\\n        try:\\n            wdir = os.path.join(os.getcwd(), 'weights')\\n            if not os.path.isdir(wdir):\\n                return None\\n            exts = ('.pth', '.pt', '.safetensors')\\n            candidates = [f for f in os.listdir(wdir) if f.lower().endswith(exts)]\\n            if not candidates:\\n                return None\\n            for name in candidates:\\n                if '4x' in name.lower() or 'ultrasharp' in name.lower():\\n                    return os.path.join(wdir, name)\\n            return os.path.join(wdir, candidates[0])\\n        except Exception:\\n            return None\\n\\n    if __name__ == '__main__':\\n        argv = sys.argv[1:]\\n        netscale = _infer_netscale(argv)\\n        detected_model = _detect_weight_file()\\n        script_path = os.path.join(os.getcwd(), 'inference_realesrgan.py')\\n        try:\\n            with open(script_path, 'r', encoding='utf-8') as _f:\\n                _code = _f.read()\\n        except Exception:\\n            sys.argv = [script_path] + argv\\n            runpy.run_path('inference_realesrgan.py', run_name='__main__')\\n        else:\\n            _globals = {'__name__': '__main__', '__file__': script_path, 'netscale': netscale, 'model': detected_model, 'outscale': netscale, 'scale': netscale}\\n            _globals['sys'] = sys\\n            sys.argv = [script_path] + argv\\n            exec(compile(_code, script_path, 'exec'), _globals)\\n    ''')\\n\",\n",
    "    \"# --- helper funcs ---\\n\",\n",
    "    \"def safe_run(cmd, timeout=3600):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        return subprocess.run(cmd, capture_output=True, text=True, timeout=timeout)\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        return type('R', (), {'returncode': 99, 'stdout': '', 'stderr': str(e)})()\\n\",\n",
    "    \"# --- main flow (safe guard) ---\\n\",\n",
    "    \"print('Auto-block status: confirm=', confirm, 'install=', install, 'run=', run, 'restart_kernel=', restart_kernel)\\n\",\n",
    "    \"if not confirm:\\n\",\n",
    "    \"    print('Run aborted: set confirm = True after reviewing flags and paths (this cell is safe by default).')\\n\",\n",
    "    \"    print('\\nPaths to check:')\\n\",\n",
    "    \"    print('  WORKSPACE =', WORKSPACE)\\n\",\n",
    "    \"    print('  REPO_DIR =', REPO_DIR)\\n\",\n",
    "    \"    print('  SHIM_PATH =', SHIM_PATH)\\n\",\n",
    "    \"    print('  INFERENCE_LOG =', INFERENCE_LOG)\\n\",\n",
    "    \"    print('  frames_dir (input) =', frames_dir)\\n\",\n",
    "    \"    print('  proposed run args =', run_args)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    # 1) optionally install deps\\n\",\n",
    "    \"    if install:\\n\",\n",
    "    \"        print('Installing packages:', deps)\\n\",\n",
    "    \"        r = safe_run([sys.executable, '-m', 'pip', 'install', '-q'] + deps, timeout=1800)\\n\",\n",
    "    \"        print('pip exit', r.returncode)\\n\",\n",
    "    \"    # 2) write shim to SHIM_PATH (try workspace, fallback to cwd)\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        os.makedirs(os.path.dirname(SHIM_PATH), exist_ok=True)\\n\",\n",
    "    \"        with open(SHIM_PATH, 'w', encoding='utf-8', newline='\\n') as f:\\n\",\n",
    "    \"            f.write(SHIM)\\n\",\n",
    "    \"        py_compile.compile(SHIM_PATH, doraise=True)\\n\",\n",
    "    \"        used_shim = SHIM_PATH\\n\",\n",
    "    \"        print('Wrote shim to', SHIM_PATH)\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print('Could not write to', SHIM_PATH, '-> falling back to', FALLBACK_SHIM, '; reason:', e)\\n\",\n",
    "    \"        with open(FALLBACK_SHIM, 'w', encoding='utf-8') as f:\\n\",\n",
    "    \"            f.write(SHIM)\\n\",\n",
    "    \"        used_shim = FALLBACK_SHIM\\n\",\n",
    "    \"        print('Wrote shim to fallback', FALLBACK_SHIM)\\n\",\n",
    "    \"    # 3) ensure repo exists (clone if missing)\\n\",\n",
    "    \"    if not os.path.exists(REPO_DIR):\\n\",\n",
    "    \"        print('Real-ESRGAN repo missing; attempting to clone into', REPO_DIR)\\n\",\n",
    "    \"        rc = safe_run(['git', 'clone', 'https://github.com/xinntao/Real-ESRGAN', REPO_DIR], timeout=900)\\n\",\n",
    "    \"        print('git clone rc=', rc.returncode)\\n\",\n",
    "    \"    # 4) copy candidate weight from common dataset mount (if present)\\n\",\n",
    "    \"    candidate = os.path.join('/kaggle/input/comfyui-models-gojo', '4x-UltraSharp.pth')\\n\",\n",
    "    \"    if os.path.exists(candidate) and os.path.exists(REPO_DIR):\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            wd = os.path.join(REPO_DIR, 'weights')\\n\",\n",
    "    \"            os.makedirs(wd, exist_ok=True)\\n\",\n",
    "    \"            shutil.copy(candidate, wd)\\n\",\n",
    "    \"            print('Copied weight into', wd)\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            print('Failed to copy weight:', e)\\n\",\n",
    "    \"    # 5) prepare run_cmd using used_shim (shim inside repo preferred)\\n\",\n",
    "    \"    if os.path.exists(used_shim):\\n\",\n",
    "    \"        run_cmd = [sys.executable, used_shim] + run_args\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        run_cmd = None\\n\",\n",
    "    \"    print('Prepared run_cmd:', run_cmd)\\n\",\n",
    "    \"    # 6) optionally run and capture logs\\n\",\n",
    "    \"    if run and run_cmd:\\n\",\n",
    "    \"        print('Executing run_cmd (timeout=3600s)...')\\n\",\n",
    "    \"        r = safe_run(run_cmd, timeout=3600)\\n\",\n",
    "    \"        print('Return code =', r.returncode)\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\\n\",\n",
    "    \"                lf.write('\\n=== AUTO ATTEMPT STDOUT ===\\n')\\n\",\n",
    "    \"                lf.write(r.stdout or '')\\n\",\n",
    "    \"                lf.write('\\n=== AUTO ATTEMPT STDERR ===\\n')\\n\",\n",
    "    \"                lf.write(r.stderr or '')\\n\",\n",
    "    \"        except Exception as _e:\\n\",\n",
    "    \"            print('Could not write inference log:', _e)\\n\",\n",
    "    \"    elif run:\\n\",\n",
    "    \"        print('run requested but run_cmd is not prepared; check shim/repo')\\n\",\n",
    "    \"    # 7) optionally request kernel restart (best effort)\\n\",\n",
    "    \"    if restart_kernel:\\n\",\n",
    "    \"        print('Attempting programmatic kernel restart (may require manual confirm in Kaggle UI)...')\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            from IPython.display import display, Javascript\\n\",\n",
    "    \"            display(Javascript('Jupyter.notebook.kernel.restart()'))\\n\",\n",
    "    \"            print('Kernel restart requested. If notebook does not restart automatically, please use Kernel -> Restart in the UI.')\\n\",\n",
    "    \"        except Exception as _e:\\n\",\n",
    "    \"            print('Programmatic restart not available; please restart kernel manually via UI:', _e)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# OPTIONAL: Install papermill & nbconvert in the current environment (run this in Kaggle if you need to run notebooks programmatically)\\n\",\n",
    "    \"# Run only when you want to enable papermill-based execution (this may install packages and take a few minutes).\\n\",\n",
    "    \"# Set confirm_install = True to actually run the install, otherwise this cell just prints instructions.\\n\",\n",
    "    \"confirm_install = False\\n\",\n",
    "    \"if not confirm_install:\\n\",\n",
    "    \"    print('To enable papermill execution, set confirm_install = True and run this cell; it will install papermill, nbconvert and jupyter_client.')\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    import subprocess, sys\\n\",\n",
    "    \"    pkgs = ['papermill', 'nbconvert', 'jupyter_client']\\n\",\n",
    "    \"    print('Installing:', pkgs)\\n\",\n",
    "    \"    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + pkgs)\\n\",\n",
    "    \"    print('Installed papermill and related packages. You can now run papermill-based execution.\\n           Example:')\\n\",\n",
    "    \"    print('  python /apps/ComfyCloud_My_Work_Flow/run_notebook_safe.py <input.ipynb> <output.ipynb> --kernel python3')\\n\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.11\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ],
   "id": "552e91db8bd0e0c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
