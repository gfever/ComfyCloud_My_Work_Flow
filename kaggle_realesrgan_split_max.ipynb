{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5,\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\"},\n",
    "  \"language_info\": {\"name\": \"python\", \"version\": \"3.8\"}\n",
    " },\n",
    " \"cells\": [\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"# Real-ESRGAN — Maximal split debug notebook\\n\", \"\\n\", \"Очень мелкие шаги: выполняйте ячейки по одной на Kaggle для точной отладки.\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 0 — Helpers (execute first)\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"import os, sys, shutil, subprocess\\n\", \"def print_separator(nl_before=True):\\n\", \"    SEP = '=' * 60\\n\", \"    if nl_before:\\n\", \"        print('\\n' + SEP)\\n\", \"    else:\\n\", \"        print(SEP + '\\n')\\n\", \"def tail(path, n=200):\\n\", \"    try:\\n\", \"        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\\n\", \"            data = f.read().splitlines()\\n\", \"        return '\\n'.join(data[-n:])\\n\", \"    except Exception as e:\\n\", \"        return f'Could not read {path}: {e}'\\n\", \"print('helpers ready')\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 1 — Minimal env guards\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"if 'WORKSPACE' not in globals():\\n\", \"    WORKSPACE = os.getcwd()\\n\", \"    print('Set WORKSPACE ->', WORKSPACE)\\n\", \"if 'FRAMES_DIR' not in globals():\\n\", \"    FRAMES_DIR = f'{WORKSPACE}/frames'\\n\", \"    print('Set FRAMES_DIR ->', FRAMES_DIR)\\n\", \"if 'DATASET_DIR' not in globals():\\n\", \"    DATASET_DIR = f'{WORKSPACE}/dataset'\\n\", \"    print('Set DATASET_DIR ->', DATASET_DIR)\\n\", \"os.makedirs(FRAMES_DIR, exist_ok=True)\\n\", \"os.makedirs(DATASET_DIR, exist_ok=True)\\n\", \"UPSCALE_MODEL_NAME = globals().get('UPSCALE_MODEL_NAME','4x-UltraSharp.pth')\\n\", \"upscale_model = f'{DATASET_DIR}/{UPSCALE_MODEL_NAME}'\\n\", \"print('upscale_model=', upscale_model)\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 2 — If model exists: prepare REPO_DIR and optionally clone\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"REPO_DIR = os.path.join(WORKSPACE, 'Real-ESRGAN')\\n\", \"print('REPO_DIR =', REPO_DIR)\\n\", \"if os.path.exists(upscale_model):\\n\", \"    print('Model present at', upscale_model)\\n\", \"    if not os.path.exists(REPO_DIR):\\n\", \"        print('Cloning Real-ESRGAN...')\\n\", \"        try:\\n\", \"            subprocess.check_call(['git','clone','https://github.com/xinntao/Real-ESRGAN', REPO_DIR])\\n\", \"            print('Clone OK')\\n\", \"        except Exception as e:\\n\", \"            print('Clone failed:', e)\\n\", \"else:\\n\", \"    print('Model missing; copy model to', upscale_model, 'to enable upscale flow')\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 3 — chdir to repo (if present) and prepare log paths\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"if os.path.exists(REPO_DIR):\\n\", \"    os.chdir(REPO_DIR)\\n\", \"    print('CWD ->', os.getcwd())\\n\", \"else:\\n\", \"    print('Repo not present; skipping chdir')\\n\", \"LOG_DIR = os.path.join(WORKSPACE, 'logs')\\n\", \"os.makedirs(LOG_DIR, exist_ok=True)\\n\", \"INSTALL_LOG = os.path.join(LOG_DIR, 'real_esrgan_install.log')\\n\", \"INFERENCE_LOG = os.path.join(LOG_DIR, 'real_esrgan_inference.log')\\n\", \"install_cmd = [sys.executable, '-m', 'pip', 'install', '--upgrade', 'torchvision', '-f', 'https://download.pytorch.org/whl/torch_stable.html']\\n\", \"print('INFERENCE_LOG =', INFERENCE_LOG)\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 4a — Build list of candidate src paths (weights source)\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"src_candidates = []\\n\", \"if 'upscale_model' in globals() and upscale_model:\\n\", \"    src_candidates.append(upscale_model)\\n\", \"src_candidates.append(os.path.join(DATASET_DIR, UPSCALE_MODEL_NAME))\\n\", \"src_candidates.append(os.path.join(WORKSPACE, 'dataset', UPSCALE_MODEL_NAME))\\n\", \"src_candidates.append(os.path.join(WORKSPACE, 'models', UPSCALE_MODEL_NAME))\\n\", \"print('src_candidates:')\\n\", \"for p in src_candidates:\\n\", \"    print(' -', p)\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 4b — Copy first existing candidate into Real-ESRGAN/weights\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"if os.path.exists(os.path.join(WORKSPACE,'Real-ESRGAN')) and src_candidates:\\n\", \"    weights_dir = os.path.join(os.getcwd(), 'weights')\\n\", \"    os.makedirs(weights_dir, exist_ok=True)\\n\", \"    copied = False\\n\", \"    for src in src_candidates:\\n\", \"        try:\\n\", \"            if src and os.path.exists(src):\\n\", \"                shutil.copy(src, weights_dir)\\n\", \"                print('Copied', src, '->', weights_dir)\\n\", \"                copied = True\\n\", \"                break\\n\", \"        except Exception as e:\\n\", \"            print('Warning copying', src, ':', e)\\n\", \"    if not copied:\\n\", \"        print('No candidate found to copy into weights')\\n\", \"else:\\n\", \"    print('Repo or candidates missing; skip weights copy')\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 5a — Define candidate_shims list (do not copy yet)\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"candidate_shims = [\\n\", \"    os.path.join(WORKSPACE, 'tmp_inference_shim.py'),\\n\", \"    os.path.join(os.getcwd(), 'tmp_inference_shim.py') if os.path.exists(os.getcwd()) else os.path.join('.', 'tmp_inference_shim.py'),\\n\", \"    os.path.join('/kaggle/working', 'tmp_inference_shim.py'),\\n\", \"    os.path.join('/apps/ComfyCloud_My_Work_Flow', 'tmp_inference_shim.py'),\\n\", \"]\\n\", \"print('candidate_shims:')\\n\", \"for c in candidate_shims:\\n\", \"    print(' -', c)\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 5b — Try copying a prepared shim from candidates\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"shim_path = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\\n\", \"wrote = False\\n\", \"for c in candidate_shims:\\n\", \"    try:\\n\", \"        if c and os.path.exists(c):\\n\", \"            shutil.copy(c, shim_path)\\n\", \"            wrote = os.path.exists(shim_path)\\n\", \"            print('Copied shim from', c)\\n\", \"            break\\n\", \"    except Exception as e:\\n\", \"        print('Failed to copy shim from', c, ':', e)\\n\", \"print('shim_path exists:', os.path.exists(shim_path))\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 6a — If no shim, build shim_lines content (define string lines) — small pieces\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"shim_lines_part1 = 'import sys, os, runpy, types, re'\\n\", \"shim_lines_part2 = '# Minimal compatibility shim: define netscale/model/outscale and exec the original script'\\n\", \"shim_lines_part3 = 'def _infer_netscale(argv):'\\n\", \"shim_lines_part4 = \"    for i,a in enumerate(argv):\"\\n\", \"print('shim parts defined')\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 6b — Compose full shim_lines and write shim file\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"if not (os.path.exists(shim_path)) and os.path.exists(REPO_DIR):\\n\", \"    shim_lines = [\\n\", \"        shim_lines_part1, shim_lines_part2, shim_lines_part3, shim_lines_part4,\\n\", \"        \"    \\\"    if a in ('-n','--name','--model') and i+1<len(argv):\\\"\",\\n\", \"        \"    \\\"        m = re.match(r'(\\\\d+)x', argv[i+1])\\\"\",\\n\", \"        \"    \\\"        if m:\\\"\",\\n\", \"        \"    \\\"            try: return int(m.group(1))\\\\n            except: pass\\\"\",\\n\", \"        \"    \\\"    for i,a in enumerate(argv):\\\"\",\\n\", \"        \"    \\\"        if a in ('-s','--scale') and i+1<len(argv):\\\"\",\\n\", \"        \"    \\\"            try: return int(argv[i+1])\\\\n            except: pass\\\"\",\\n\", \"        \"    \\\"    return 4\\\"\",\\n\", \"        \\\"if __name__ == '__main__':\\\"\",\\n\", \"        \\\"    argv = sys.argv[1:]\\\"\",\\n\", \"        \\\"    netscale = _infer_netscale(argv)\\\"\",\\n\", \"        \\\"    script_path = os.path.join(os.getcwd(), 'inference_realesrgan.py')\\\"\",\\n\", \"        \\\"    try:\\\"\",\\n\", \"        \\\"        with open(script_path, 'r', encoding='utf-8') as f:\\\"\",\\n\", \"        \\\"            code = f.read()\\\"\",\\n\", \"        \\\"    except Exception:\\\"\",\\n\", \"        \\\"        sys.argv = [script_path] + argv\\\"\",\\n\", \"        \\\"        runpy.run_path('inference_realesrgan.py', run_name='__main__')\\\"\",\\n\", \"        \\\"    else:\\\"\",\\n\", \"        \\\"        _globals = {'__name__':'__main__', '__file__':script_path, 'netscale':netscale, 'model':None, 'outscale':netscale, 'scale':netscale}\\\"\",\\n\", \"        \\\"        _globals['sys'] = sys\\\"\",\\n\", \"        \\\"        sys.argv = [script_path] + argv\\\"\",\\n\", \"        \\\"        exec(compile(code, script_path, 'exec'), _globals)\\\"\",\\n\", \"    ]\\n\", \"    try:\\n\", \"        with open(shim_path, 'w', encoding='utf-8') as sf:\\n\", \"            sf.write('\\n'.join(shim_lines))\\n\", \"        print('Wrote shim to', shim_path)\\n\", \"        wrote = os.path.exists(shim_path)\\n\", \"    except Exception as e:\\n\", \"        print('Failed to write shim:', e)\\n\", \"else:\\n\", \"    print('Shim exists or repo missing; shim_path exists=', os.path.exists(shim_path))\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 7a — Construct fallback pycmd components (safe_argv & args_literal)\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"safe_argv = ['-n','4x-UltraSharp','-i', FRAMES_DIR, '-o', FRAMES_DIR + '_upscaled', '--fp32', '--outscale', '4']\\n\", \"args_literal = '[' + ','.join(repr(a) for a in safe_argv) + ']'\\n\", \"print('safe_argv ->', safe_argv)\\n\", \"print('args_literal preview ->', args_literal[:120])\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 7b — Build run_cmd (shim vs fallback) — inspect but don't run\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"run_cmd = None\\n\", \"if os.path.exists(REPO_DIR):\\n\", \"    shim_path = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\\n\", \"    if os.path.exists(shim_path):\\n\", \"        run_cmd = [sys.executable, shim_path, '-n','4x-UltraSharp','-i',FRAMES_DIR,'-o',FRAMES_DIR + '_upscaled','--fp32','--outscale','4']\\n\", \"    else:\\n\", \"        pycmd = (\\n\", \"            \\\"import runpy,sys,os,re; argv=\\\" + args_literal + \"; sys.argv=[os.path.join(os.getcwd(),'inference_realesrgan.py')]+argv; \"\\n\", \"            \\\"def _infer(argv):\\\\n    import re\\\\n    for i,a in enumerate(argv):\\\\n        if a in ('-n','--name','--model') and i+1<len(argv):\\\\n            m=re.match(r'(\\\\\\\\d+)x',argv[i+1]);\\\\n            if m: return int(m.group(1))\\\\n    for i,a in enumerate(argv):\\\\n        if a in ('-s','--scale') and i+1<len(argv):\\\\n            try: return int(argv[i+1])\\\\n            except: pass\\\\n    return 4\\\\n\"\\n\", \"            \\\"netscale=_infer(argv)\\\\nrunpy.run_path('inference_realesrgan.py', run_name='__main__')\\\"\\n\", \"        )\\n\", \"        run_cmd = [sys.executable, '-c', pycmd]\\n\", \"print('Prepared run_cmd:')\\n\", \"print(run_cmd)\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 8 — Execute run_cmd (inference) — run only after inspection\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"if run_cmd is None:\\n\", \"    print('run_cmd undefined — build it first')\\n\", \"else:\\n\", \"    print('Running:', run_cmd)\\n\", \"    try:\\n\", \"        res = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600)\\n\", \"    except Exception as e:\\n\", \"        print('Failed to run subprocess:', e)\\n\", \"    else:\\n\", \"        with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\\n\", \"            lf.write('=== STDOUT ===\\n')\\n\", \"            lf.write(res.stdout or '')\\n\", \"            lf.write('\\n=== STDERR ===\\n')\\n\", \"            lf.write(res.stderr or '')\\n\", \"        print('Return code =', getattr(res,'returncode',None))\\n\", \"        if res.returncode == 0:\\n\", \"            print('Inference OK — see', INFERENCE_LOG)\\n\", \"        else:\\n\", \"            print('Inference failed — see', INFERENCE_LOG)\\n\", \"            globals()['last_inference_stderr'] = res.stderr\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 9a — Prepare tv_init string (stub) — small atomized cells\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"tv_init = '''# Minimal stub torchvision package for Real-ESRGAN/basicsr compatibility\\nfrom . import utils\\nfrom . import transforms\\n__all__ = ['utils','transforms']\\n'''\\n\", \"print('tv_init length', len(tv_init))\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"utils_code = '''# Minimal stub for torchvision.utils.make_grid\\ntry:\\n    from torchvision.utils import make_grid as _make_grid\\n    def make_grid(tensor, nrow=8, padding=2, normalize=False):\\n        return _make_grid(tensor, nrow=nrow, padding=padding, normalize=normalize)\\nexcept Exception:\\n    import numpy as _np\\n    from PIL import Image as _Image\\n    import torch as _torch\\n    def make_grid(tensor, nrow=8, padding=2, normalize=False):\\n        if isinstance(tensor, (list, tuple)):\\n            tensor = _torch.stack(tensor, dim=0)\\n        if not isinstance(tensor, _torch.Tensor):\\n            raise TypeError('Fallback make_grid expects a torch.Tensor or list of tensors')\\n        t = tensor.detach().cpu()\\n        if t.dim() == 3:\\n            t = t.unsqueeze(0)\\n        B,C,H,W = t.shape\\n        if normalize:\\n            t = (t - t.min()) / (t.max() - t.min() + 1e-8)\\n        else:\\n            if t.max() > 50:\\n                t = t / 255.0\\n        def to_uint8(x):\\n            arr = (x.numpy().transpose(1,2,0) * 255.0).clip(0,255).astype(_np.uint8)\\n            if arr.shape[2] == 1:\\n                arr = _np.repeat(arr, 3, axis=2)\\n            return _Image.fromarray(arr)\\n        imgs = [to_uint8(t[i]) for i in range(B)]\\n        rows = (B + nrow - 1) // nrow\\n        grid_h = rows * H + padding * (rows - 1)\\n        grid_w = nrow * W + padding * (nrow - 1)\\n        grid = _Image.new('RGB', (grid_w, grid_h), (0,0,0))\\n        for idx, img in enumerate(imgs):\\n            r = idx // nrow\\n            c = idx % nrow\\n            grid.paste(img, (c * (W + padding), r * (H + padding)))\\n        arr = _np.array(grid).transpose(2,0,1).astype(_np.float32) / 255.0\\n        return _torch.from_numpy(arr)\\n'''\\n\", \"print('utils_code length', len(utils_code))\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"tr_init = '''# transforms package stub\\nfrom . import functional_tensor\\n__all__ = ['functional_tensor']\\n'''\\n\", \"print('tr_init length', len(tr_init))\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"func_code = '''# Auto-generated stub: try to import the real functional_tensor, otherwise delegate to torchvision.transforms.functional\\ntry:\\n    from torchvision.transforms.functional_tensor import *  # type: ignore\\nexcept Exception:\\n    try:\\n        from torchvision.transforms import functional as _f\\n    except Exception:\\n        def rgb_to_grayscale(x):\\n            raise ImportError('rgb_to_grayscale not available in this environment')\\n        def convert_image_dtype(x, dtype):\\n            raise ImportError('convert_image_dtype not available in this environment')\\n    else:\\n        rgb_to_grayscale = getattr(_f, 'rgb_to_grayscale', None)\\n        convert_image_dtype = getattr(_f, 'convert_image_dtype', None)\\n    __all__ = [n for n in ('rgb_to_grayscale','convert_image_dtype') if globals().get(n) is not None]\\n'''\\n\", \"print('func_code length', len(func_code))\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 9b — Write stub files to disk\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"try:\\n\", \"    stub_root = os.path.join(WORKSPACE, 'torchvision_stub')\\n\", \"    torchvision_pkg = os.path.join(stub_root, 'torchvision')\\n\", \"    transforms_pkg = os.path.join(torchvision_pkg, 'transforms')\\n\", \"    shutil.rmtree(stub_root, ignore_errors=True)\\n\", \"    os.makedirs(transforms_pkg, exist_ok=True)\\n\", \"    with open(os.path.join(torchvision_pkg, '__init__.py'), 'w', encoding='utf-8') as f_init:\\n\", \"        f_init.write(tv_init)\\n\", \"    with open(os.path.join(torchvision_pkg, 'utils.py'), 'w', encoding='utf-8') as f_utils:\\n\", \"        f_utils.write(utils_code)\\n\", \"    with open(os.path.join(transforms_pkg, '__init__.py'), 'w', encoding='utf-8') as f_tr:\\n\", \"        f_tr.write(tr_init)\\n\", \"    with open(os.path.join(transforms_pkg, 'functional_tensor.py'), 'w', encoding='utf-8') as f_ft:\\n\", \"        f_ft.write(func_code)\\n\", \"    print('Stub files written to', stub_root)\\n\", \"except Exception as e:\\n\", \"    print('Failed to write stub files:', e)\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 10 — Add stub_root to PYTHONPATH and run run_cmd with stub env\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"env = os.environ.copy()\\n\", \"prev_pp = env.get('PYTHONPATH','')\\n\", \"env['PYTHONPATH'] = stub_root + (os.pathsep + prev_pp if prev_pp else '')\\n\", \"print('PYTHONPATH adjusted for subprocess')\\n\", \"if run_cmd is None:\\n\", \"    print('run_cmd undefined; build run_cmd before retry')\\n\", \"else:\\n\", \"    print('Running with stub PYTHONPATH...')\\n\", \"    res_stub = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600, env=env)\\n\", \"    print('Stub returncode =', getattr(res_stub,'returncode',None))\\n\", \"    try:\\n\", \"        with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\\n\", \"            lf.write('\\n=== STUB SUBPROCESS STDOUT ===\\n')\\n\", \"            lf.write(res_stub.stdout or '')\\n\", \"            lf.write('\\n=== STUB SUBPROCESS STDERR ===\\n')\\n\", \"            lf.write(res_stub.stderr or '')\\n\", \"    except Exception as e:\\n\", \"        print('Could not append to INFERENCE_LOG:', e)\\n\"]},\n",
    "  {\"cell_type\": \"markdown\", \"metadata\": {}, \"source\": [\"## 11 — Show logs (quick) and list directories\"]},\n",
    "  {\"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [\"print('=== INFERENCE_LOG tail ===')\\n\", \"print(tail(INFERENCE_LOG, 400))\\n\", \"print('\\n=== INSTALL_LOG tail ===')\\n\", \"print(tail(INSTALL_LOG, 200))\\n\", \"print('\\n=== weights dir listing ===')\\n\", \"wdir = os.path.join(REPO_DIR, 'weights') if 'REPO_DIR' in globals() else os.path.join(WORKSPACE, 'Real-ESRGAN', 'weights')\\n\", \"try:\\n\", \"    print(os.listdir(wdir))\\n\", \"except Exception as e:\\n\", \"    print('Could not list weights dir:', e)\\n\", \"print('\\n=== upscaled frames dir ===')\\n\", \"try:\\n\", \"    print(os.listdir(FRAMES_DIR + '_upscaled'))\\n\", \"except Exception as e:\\n\", \"    print('Could not list upscaled dir:', e)\\n\"]}\n",
    " ]\n",
    "}\n",
    "\n"
   ],
   "id": "f01d92473229c375"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}