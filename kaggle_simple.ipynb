{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title üé¨ –ì–û–î–ñ–û 30 –°–ï–ö ‚Äî –ü–†–û–°–¢–ê–Ø –í–ï–†–°–ò–Ø –ë–ï–ó COMFYUI\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "# ============================================\n",
    "# üìù –ù–ê–°–¢–†–û–ô–ö–ò - –ú–ï–ù–Ø–ô –¢–û–õ–¨–ö–û –≠–¢–û!\n",
    "# ============================================\n",
    "PROMPT = \"cinematic portrait of gojo satoru, white spiky hair, black blindfold, confident expression, anime style, highly detailed, 8k, professional lighting\"\n",
    "NEGATIVE_PROMPT = \"blurry, deformed, low quality, watermark, text, bad anatomy, multiple heads, duplicate\"\n",
    "\n",
    "# –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã\n",
    "USE_ANIMATEDIFF = True  # True = –Ω–∞—Å—Ç–æ—è—â–∞—è –∞–Ω–∏–º–∞—Ü–∏—è, False = —Å—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã + RIFE\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "WIDTH = 512\n",
    "HEIGHT = 768\n",
    "NUM_FRAMES = 16 if USE_ANIMATEDIFF else 8  # AnimateDiff: 16-24, –æ–±—ã—á–Ω—ã–π: 8-12\n",
    "STEPS = 25 if USE_ANIMATEDIFF else 20  # –î–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ steps\n",
    "CFG_SCALE = 7.5 if USE_ANIMATEDIFF else 7\n",
    "FPS = 8  # FPS –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ\n",
    "\n",
    "# –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è RIFE (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "USE_RIFE = True  # –ü—Ä–∏–º–µ–Ω–∏—Ç—å RIFE –¥–ª—è –µ—â—ë –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω–æ–π –∞–Ω–∏–º–∞—Ü–∏–∏\n",
    "RIFE_EXP = 4 if USE_ANIMATEDIFF else 5  # AnimateDiff: 4 (16‚Üí256), –æ–±—ã—á–Ω—ã–π: 5 (8‚Üí256)\n",
    "# ============================================\n",
    "\n",
    "# === –ü–ê–ü–ö–ò ===\n",
    "WORKSPACE = \"/kaggle/working\"\n",
    "FRAMES_DIR = f\"{WORKSPACE}/frames\"\n",
    "DATASET_DIR = \"/kaggle/input/comfyui-models-gojo\"\n",
    "\n",
    "os.makedirs(FRAMES_DIR, exist_ok=True)\n",
    "\n",
    "# === –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô (–û–î–ò–ù –†–ê–ó) ===\n",
    "print(\"üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...\")\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ —Å—Ä–∞–∑—É, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä–æ–±–ª–µ–º —Å –∏–º–ø–æ—Ä—Ç–æ–º\n",
    "import sys\n",
    "import importlib.util\n",
    "\n",
    "def check_package(package_name):\n",
    "    \"\"\"–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–∞–∫–µ—Ç–∞ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞\"\"\"\n",
    "    return importlib.util.find_spec(package_name) is not None\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤\n",
    "packages_to_install = []\n",
    "\n",
    "if not check_package(\"diffusers\"):\n",
    "    packages_to_install.append(\"diffusers[torch]\")\n",
    "    packages_to_install.append(\"transformers\")\n",
    "    packages_to_install.append(\"accelerate\")\n",
    "else:\n",
    "    print(\"‚úì diffusers —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "\n",
    "if not check_package(\"cv2\"):\n",
    "    packages_to_install.append(\"opencv-python\")\n",
    "else:\n",
    "    print(\"‚úì opencv-python —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "\n",
    "if USE_ANIMATEDIFF and not check_package(\"imageio\"):\n",
    "    packages_to_install.append(\"imageio\")\n",
    "    packages_to_install.append(\"imageio-ffmpeg\")\n",
    "elif USE_ANIMATEDIFF:\n",
    "    print(\"‚úì imageio —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –ø–∞–∫–µ—Ç—ã –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π\n",
    "if packages_to_install:\n",
    "    print(f\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞: {', '.join(packages_to_install)}...\")\n",
    "    !pip install -q {' '.join(packages_to_install)}\n",
    "    print(\"‚úì –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
    "\n",
    "print(\"‚úì –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≥–æ—Ç–æ–≤—ã!\\n\")\n",
    "\n",
    "# === –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–î–†–û–í / –ê–ù–ò–ú–ê–¶–ò–ò ===\n",
    "print(f\"üé® {'–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∏–º–∞—Ü–∏–∏' if USE_ANIMATEDIFF else '–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–∞–¥—Ä–æ–≤'} ({NUM_FRAMES} –∫–∞–¥—Ä–æ–≤)...\")\n",
    "print(f\"   –ü—Ä–æ–º–ø—Ç: {PROMPT[:80]}...\")\n",
    "print(f\"   –†–∞–∑–º–µ—Ä: {WIDTH}x{HEIGHT}, Steps: {STEPS}, CFG: {CFG_SCALE}\\n\")\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å ~30 —Å–µ–∫ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ)\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∫–∞ PyTorch –∏ PIL...\")\n",
    "import torch\n",
    "from PIL import Image\n",
    "print(\"‚úì –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n",
    "\n",
    "if USE_ANIMATEDIFF:\n",
    "    # === –†–ï–ñ–ò–ú ANIMATEDIFF - –ù–ê–°–¢–û–Ø–©–ê–Ø –ê–ù–ò–ú–ê–¶–ò–Ø ===\n",
    "    from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
    "    from diffusers.utils import export_to_video\n",
    "\n",
    "    print(\"–ó–∞–≥—Ä—É–∑–∫–∞ AnimateDiff pipeline...\")\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º motion adapter\n",
    "    adapter = MotionAdapter.from_pretrained(\n",
    "        \"guoyww/animatediff-motion-adapter-v1-5-2\",\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "\n",
    "    # AnimateDiff —Ä–∞–±–æ—Ç–∞–µ—Ç —Å SD 1.5\n",
    "    pipe = AnimateDiffPipeline.from_pretrained(\n",
    "        \"runwayml/stable-diffusion-v1-5\",\n",
    "        motion_adapter=adapter,\n",
    "        torch_dtype=torch.float16\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "    pipe.enable_vae_slicing()\n",
    "    pipe.enable_model_cpu_offload()\n",
    "\n",
    "    print(\"‚úì AnimateDiff –≥–æ—Ç–æ–≤!\\n\")\n",
    "    print(\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∏–º–∞—Ü–∏–∏ (—ç—Ç–æ –∑–∞–π–º–µ—Ç ~3-7 –º–∏–Ω—É—Ç)...\")\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–∏–º–∞—Ü–∏—é\n",
    "    output = pipe(\n",
    "        prompt=PROMPT,\n",
    "        negative_prompt=NEGATIVE_PROMPT,\n",
    "        num_frames=NUM_FRAMES,\n",
    "        width=WIDTH,\n",
    "        height=HEIGHT,\n",
    "        num_inference_steps=STEPS,\n",
    "        guidance_scale=CFG_SCALE,\n",
    "        generator=torch.Generator(\"cuda\").manual_seed(42)\n",
    "    )\n",
    "\n",
    "    frames = output.frames[0]\n",
    "    total_gen_time = time.time() - start_time\n",
    "\n",
    "    print(f\"‚úÖ –ê–Ω–∏–º–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞ –∑–∞ {total_gen_time:.1f}s!\\n\")\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä—ã\n",
    "    for i, frame in enumerate(frames):\n",
    "        frame.save(f\"{FRAMES_DIR}/{i}.png\")\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤–æ–µ –≤–∏–¥–µ–æ\n",
    "    base_video = f\"{WORKSPACE}/ANIMATED_BASE.mp4\"\n",
    "    export_to_video(frames, base_video, fps=FPS)\n",
    "    print(f\"‚úì –ë–∞–∑–æ–≤–æ–µ –≤–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ ({len(frames)} –∫–∞–¥—Ä–æ–≤, {FPS} fps)\")\n",
    "\n",
    "    del pipe, adapter\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "else:\n",
    "    # === –†–ï–ñ–ò–ú –°–¢–ê–¢–ò–ß–ù–´–• –ö–ê–î–†–û–í ===\n",
    "    from diffusers import StableDiffusionXLPipeline\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–ª–∏ HuggingFace\n",
    "    model_path = f\"{DATASET_DIR}/sd_xl_base_1.0.safetensors\"\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º HuggingFace...\")\n",
    "        model_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "    print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SDXL...\")\n",
    "    pipe = StableDiffusionXLPipeline.from_single_file(\n",
    "        model_path,\n",
    "        torch_dtype=torch.float16,\n",
    "        use_safetensors=True\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    pipe.enable_attention_slicing()\n",
    "    pipe.enable_vae_slicing()\n",
    "\n",
    "    print(\"‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!\\n\")\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–¥—Ä—ã\n",
    "    start_time = time.time()\n",
    "    for i in range(NUM_FRAMES):\n",
    "        print(f\"–ö–∞–¥—Ä {i+1}/{NUM_FRAMES}...\", end=\" \")\n",
    "\n",
    "        generator = torch.Generator(device=\"cuda\").manual_seed(42 + i)\n",
    "\n",
    "        image = pipe(\n",
    "            prompt=PROMPT,\n",
    "            negative_prompt=NEGATIVE_PROMPT,\n",
    "            width=WIDTH,\n",
    "            height=HEIGHT,\n",
    "            num_inference_steps=STEPS,\n",
    "            guidance_scale=CFG_SCALE,\n",
    "            generator=generator\n",
    "        ).images[0]\n",
    "\n",
    "        image.save(f\"{FRAMES_DIR}/{i}.png\")\n",
    "        print(f\"‚úì ({time.time() - start_time:.1f}s)\")\n",
    "\n",
    "    total_gen_time = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ {NUM_FRAMES} –∫–∞–¥—Ä–æ–≤ –∑–∞ {total_gen_time:.1f}s!\\n\")\n",
    "\n",
    "    del pipe\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# === UPSCALE –° REAL-ESRGAN (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) ===\n",
    "print(\"\\nüìà –ê–ø—Å–∫–µ–π–ª –∫–∞–¥—Ä–æ–≤ —Å Real-ESRGAN...\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ upscale –º–æ–¥–µ–ª—å\n",
    "upscale_model = f\"{DATASET_DIR}/4x-UltraSharp.pth\"\n",
    "\n",
    "if os.path.exists(upscale_model):\n",
    "    # –ö–ª–æ–Ω–∏—Ä—É–µ–º Real-ESRGAN –µ—Å–ª–∏ –µ—â–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n",
    "    if not os.path.exists(f\"{WORKSPACE}/Real-ESRGAN\"):\n",
    "        !git clone https://github.com/xinntao/Real-ESRGAN {WORKSPACE}/Real-ESRGAN\n",
    "        %cd {WORKSPACE}/Real-ESRGAN\n",
    "        !pip install -q basicsr facexlib gfpgan\n",
    "        !pip install -q realesrgan\n",
    "\n",
    "    %cd {WORKSPACE}/Real-ESRGAN\n",
    "\n",
    "    # –ö–æ–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
    "    !mkdir -p weights\n",
    "    !cp {upscale_model} weights/\n",
    "\n",
    "    # –ê–ø—Å–∫–µ–π–ª –∫–∞–∂–¥–æ–≥–æ –∫–∞–¥—Ä–∞\n",
    "    print(\"–ó–∞–ø—É—Å–∫ –∞–ø—Å–∫–µ–π–ª–∞...\")\n",
    "    !python inference_realesrgan.py \\\n",
    "        -n 4x-UltraSharp \\\n",
    "        -i {FRAMES_DIR} \\\n",
    "        -o {FRAMES_DIR}_upscaled \\\n",
    "        --fp32\n",
    "\n",
    "    # –ó–∞–º–µ–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∫–∞–¥—Ä—ã –∞–ø—Å–∫–µ–π–ª–µ–Ω–Ω—ã–º–∏\n",
    "    !rm -rf {FRAMES_DIR}\n",
    "    !mv {FRAMES_DIR}_upscaled {FRAMES_DIR}\n",
    "\n",
    "    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ (Real-ESRGAN –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å)\n",
    "    import glob\n",
    "    upscaled_files = sorted(glob.glob(f\"{FRAMES_DIR}/*_out.png\"))\n",
    "    for i, filepath in enumerate(upscaled_files):\n",
    "        os.rename(filepath, f\"{FRAMES_DIR}/{i}.png\")\n",
    "\n",
    "    print(\"‚úì –ê–ø—Å–∫–µ–π–ª –∑–∞–≤–µ—Ä—à–µ–Ω!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Upscale –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–ø—Å–∫–µ–π–ª\")\n",
    "\n",
    "# === RIFE –ò–ù–¢–ï–†–ü–û–õ–Ø–¶–ò–Ø ===\n",
    "if USE_RIFE:\n",
    "    print(f\"\\nüéûÔ∏è –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è {NUM_FRAMES} ‚Üí {NUM_FRAMES * (2**RIFE_EXP)} –∫–∞–¥—Ä–æ–≤ —Å RIFE...\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è RIFE –æ—Ç–∫–ª—é—á–µ–Ω, —Å–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ –∏–∑ {NUM_FRAMES} –∫–∞–¥—Ä–æ–≤...\")\n",
    "    !ffmpeg -framerate {FPS} -i {FRAMES_DIR}/%d.png \\\n",
    "        -c:v libx264 -pix_fmt yuv420p -preset fast \\\n",
    "        {WORKSPACE}/GOJO_OUTPUT.mp4 -y -loglevel error\n",
    "\n",
    "    final_video = f\"{WORKSPACE}/GOJO_OUTPUT.mp4\"\n",
    "    if os.path.exists(final_video):\n",
    "        file_size = os.path.getsize(final_video) / 1024 / 1024\n",
    "        print(f\"‚úÖ –ì–û–¢–û–í–û! ({file_size:.1f} MB)\")\n",
    "        display(FileLink(final_video))\n",
    "\n",
    "if USE_RIFE:\n",
    "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Practical-RIFE\n",
    "    !rm -rf {WORKSPACE}/RIFE\n",
    "    !git clone https://github.com/hzwer/Practical-RIFE {WORKSPACE}/RIFE\n",
    "    %cd {WORKSPACE}/RIFE\n",
    "\n",
    "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ RIFE\n",
    "    !pip install -q scikit-video\n",
    "\n",
    "    # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å RIFE v4.26\n",
    "    print(\"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ RIFE v4.26...\")\n",
    "    !pip install -q gdown\n",
    "    !mkdir -p train_log\n",
    "    !gdown 1gViYvvQrtETBgU1w8axZSsr7YUuw31uy -O train_log.zip\n",
    "\n",
    "    model_downloaded = False\n",
    "\n",
    "    if os.path.exists(\"train_log.zip\") and os.path.getsize(\"train_log.zip\") > 1000000:\n",
    "        !unzip -q train_log.zip\n",
    "\n",
    "        # –ò—â–µ–º –º–æ–¥–µ–ª—å\n",
    "        if os.path.exists(\"train_log/flownet.pkl\"):\n",
    "            model_downloaded = True\n",
    "            print(\"‚úì –ú–æ–¥–µ–ª—å RIFE –≥–æ—Ç–æ–≤–∞!\")\n",
    "        else:\n",
    "            # –ò—â–µ–º –≤ –¥—Ä—É–≥–∏—Ö –º–µ—Å—Ç–∞—Ö\n",
    "            result = !find . -name \"flownet.pkl\" | head -1\n",
    "            if result:\n",
    "                !cp {result[0]} train_log/flownet.pkl\n",
    "                model_downloaded = True\n",
    "                print(\"‚úì –ú–æ–¥–µ–ª—å RIFE –≥–æ—Ç–æ–≤–∞!\")\n",
    "\n",
    "    if not model_downloaded:\n",
    "        print(\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å RIFE\")\n",
    "        print(\"–°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ –≤–∏–¥–µ–æ –∏–∑ –∫–∞–¥—Ä–æ–≤...\")\n",
    "        !ffmpeg -framerate {FPS} -i {FRAMES_DIR}/%d.png \\\n",
    "            -c:v libx264 -pix_fmt yuv420p -preset fast \\\n",
    "            {WORKSPACE}/GOJO_OUTPUT.mp4 -y -loglevel error\n",
    "\n",
    "        final_video = f\"{WORKSPACE}/GOJO_OUTPUT.mp4\"\n",
    "        if os.path.exists(final_video):\n",
    "            file_size = os.path.getsize(final_video) / 1024 / 1024\n",
    "            print(f\"‚úÖ –ì–û–¢–û–í–û! ({file_size:.1f} MB)\")\n",
    "            display(FileLink(final_video))\n",
    "    else:\n",
    "        # –ó–∞–ø—É—Å–∫–∞–µ–º RIFE –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é\n",
    "        print(f\"–ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ (exp={RIFE_EXP})...\")\n",
    "\n",
    "        !python inference_video.py \\\n",
    "            --img {FRAMES_DIR} \\\n",
    "            --exp {RIFE_EXP} \\\n",
    "            --output {WORKSPACE}/GOJO_OUTPUT.mp4 \\\n",
    "            --UHD\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "        final_video = f\"{WORKSPACE}/GOJO_OUTPUT.mp4\"\n",
    "        if os.path.exists(final_video):\n",
    "            file_size = os.path.getsize(final_video) / 1024 / 1024\n",
    "            fps = NUM_FRAMES * (2**RIFE_EXP) / 30  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –¥–ª–∏–Ω–∞ –≤–∏–¥–µ–æ\n",
    "            print(f\"\\nüéâ –ì–û–¢–û–í–û! –í–∏–¥–µ–æ {NUM_FRAMES * (2**RIFE_EXP)} –∫–∞–¥—Ä–æ–≤ ({file_size:.1f} MB)\")\n",
    "            display(FileLink(final_video))\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è RIFE –Ω–µ —Å–æ–∑–¥–∞–ª –≤–∏–¥–µ–æ, —Å–æ–∑–¥–∞–µ–º fallback...\")\n",
    "            !ffmpeg -framerate {FPS} -i {FRAMES_DIR}/%d.png \\\n",
    "                -c:v libx264 -pix_fmt yuv420p -preset fast \\\n",
    "                {WORKSPACE}/GOJO_OUTPUT.mp4 -y -loglevel error\n",
    "\n",
    "            if os.path.exists(final_video):\n",
    "                file_size = os.path.getsize(final_video) / 1024 / 1024\n",
    "                print(f\"‚úÖ –ì–û–¢–û–í–û! ({file_size:.1f} MB)\")\n",
    "                display(FileLink(final_video))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã –ò–¢–û–ì–ò:\")\n",
    "print(f\"   –†–µ–∂–∏–º: {'AnimateDiff (–∞–Ω–∏–º–∞—Ü–∏—è)' if USE_ANIMATEDIFF else '–°—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã'}\")\n",
    "print(f\"   –ü—Ä–æ–º–ø—Ç: {PROMPT[:50]}...\")\n",
    "print(f\"   –†–∞–∑–º–µ—Ä: {WIDTH}x{HEIGHT}\")\n",
    "print(f\"   –ö–∞–¥—Ä–æ–≤: {NUM_FRAMES}\" + (f\" ‚Üí {NUM_FRAMES * (2**RIFE_EXP)}\" if USE_RIFE else \"\"))\n",
    "print(f\"   –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {total_gen_time:.1f}s\")\n",
    "if USE_ANIMATEDIFF:\n",
    "    print(\"\\nüí° –°–æ–≤–µ—Ç—ã –¥–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏:\")\n",
    "    print(\"   ‚Ä¢ –î–æ–±–∞–≤—å—Ç–µ –≤ –ø—Ä–æ–º–ø—Ç: 'turning head', 'blinking', 'hair flowing'\")\n",
    "    print(\"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: 'smooth motion', 'cinematic camera movement'\")\n",
    "    print(\"   ‚Ä¢ –í negative: 'static, frozen, choppy animation'\")\n",
    "print(\"=\"*60)\n"
   ],
   "id": "a1fbd2b0995e791b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}