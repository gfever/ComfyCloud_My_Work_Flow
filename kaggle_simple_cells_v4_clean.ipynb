{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé¨ –ì–û–î–ñ–û 30 –°–ï–ö ‚Äî –ü–†–û–°–¢–ê–Ø –í–ï–†–°–ò–Ø –ë–ï–ó COMFYUI\n",
    "\n",
    "**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç notebook:**\n",
    "- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–Ω–∏–º–∞—Ü–∏—é —Å AnimateDiff –∏–ª–∏ —Å—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã\n",
    "- –ü—Ä–∏–º–µ–Ω—è–µ—Ç upscale —á–µ—Ä–µ–∑ Real-ESRGAN (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "- –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ—Ç –∫–∞–¥—Ä—ã —á–µ—Ä–µ–∑ RIFE –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏\n",
    "- –°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ\n",
    "\n",
    "**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:**\n",
    "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –º–æ–¥–µ–ª—è–º–∏ –≤ Kaggle\n",
    "2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —è—á–µ–π–∫–µ –Ω–∏–∂–µ\n",
    "3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ —è—á–µ–π–∫–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É (Run All)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === –†–ê–ù–ù–Ø–Ø –ù–ê–°–¢–†–û–ô–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø / –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê ===\n",
    "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–∞–∂–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –î–û –ª—é–±—ã—Ö heavy-–∏–º–ø–æ—Ä—Ç–æ–≤,\n",
    "# —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–π –æ –¥—É–±–ª–∏—Ä—É—é—â–µ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ CUDA-–ø–ª–∞–≥–∏–Ω–æ–≤ (cuFFT/cuDNN/cuBLAS) –æ—Ç XLA/JAX/TensorFlow.\n",
    "import os\n",
    "import importlib\n",
    "_changed_env = False\n",
    "\n",
    "def _set_env_if_needed(k, v):\n",
    "    global _changed_env\n",
    "    if os.environ.get(k) != v:\n",
    "        os.environ[k] = v\n",
    "        _changed_env = True\n",
    "\n",
    "# –ü–æ–¥–∞–≤–ª—è–µ–º TensorFlow info/warnings, –æ—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥–∞–ª–æ–∫–∞—Ü–∏—é XLA –∫–ª–∏–µ–Ω—Ç–∞\n",
    "_set_env_if_needed('TF_CPP_MIN_LOG_LEVEL', '3')\n",
    "_set_env_if_needed('XLA_PYTHON_CLIENT_PREALLOCATE', 'false')\n",
    "_set_env_if_needed('XLA_PYTHON_CLIENT_MEM_FRACTION', '0.0')\n",
    "# –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º JAX –Ω–∞ CPU, –µ—Å–ª–∏ –æ–Ω —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî —á—Ç–æ–±—ã –æ–Ω –Ω–µ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª GPU-–ø–ª–∞–≥–∏–Ω—ã\n",
    "_set_env_if_needed('JAX_PLATFORM_NAME', 'cpu')\n",
    "_set_env_if_needed('JAX_PLATFORMS', 'cpu')\n",
    "\n",
    "# –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –º—è–≥–∫–æ –ø–æ–¥–∞–≤–∏—Ç—å absl-–ª–æ–≥–∏ (–µ—Å–ª–∏ absl –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç)\n",
    "try:\n",
    "    import absl.logging\n",
    "    absl.logging._warn_preinit_stderr = False\n",
    "    absl.logging.set_verbosity(absl.logging.WARNING)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞: –µ—Å—Ç—å –ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤—ã–∑–≤–∞—Ç—å XLA/JAX/TensorFlow –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "_found = {}\n",
    "for mod in ('jax', 'jaxlib', 'tensorflow', 'torch_xla'):\n",
    "    _found[mod] = importlib.util.find_spec(mod) is not None\n",
    "\n",
    "print('ENV diagnostic:')\n",
    "print('  TF_CPP_MIN_LOG_LEVEL=', os.environ.get('TF_CPP_MIN_LOG_LEVEL'))\n",
    "print('  XLA_PYTHON_CLIENT_PREALLOCATE=', os.environ.get('XLA_PYTHON_CLIENT_PREALLOCATE'))\n",
    "print('  XLA_PYTHON_CLIENT_MEM_FRACTION=', os.environ.get('XLA_PYTHON_CLIENT_MEM_FRACTION'))\n",
    "print('  JAX_PLATFORM_NAME=', os.environ.get('JAX_PLATFORM_NAME'))\n",
    "print('  JAX_PLATFORMS=', os.environ.get('JAX_PLATFORMS'))\n",
    "print('Detected potentially conflicting packages:')\n",
    "for k, v in _found.items():\n",
    "    print(f'  {k}:', 'present' if v else 'not found')\n",
    "\n",
    "if _changed_env:\n",
    "    print('\\n‚ö†Ô∏è –í–∞–∂–Ω–æ: –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω—ã ‚Äî –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ kernel (Restart Kernel) –ø–µ—Ä–µ–¥ –¥–∞–ª—å–Ω–µ–π—à–∏–º –∏–º–ø–æ—Ä—Ç–æ–º heavy-–±–∏–±–ª–∏–æ—Ç–µ–∫, —á—Ç–æ–±—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤—Å—Ç—É–ø–∏–ª–∏ –≤ —Å–∏–ª—É –∏ —Å–æ–æ–±—â–µ–Ω–∏—è XLA/TensorFlow –Ω–µ –ø–æ—è–≤–ª—è–ª–∏—Å—å.')\n",
    "else:\n",
    "    print('\\n‚ÑπÔ∏è –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === KAGGLE SETUP & CHECKS ===\n",
    "# –≠—Ç–∞ —è—á–µ–π–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –±–∞–∑–æ–≤—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ Kaggle –∏ –¥–∞—ë—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏.\n",
    "import os\n",
    "import sys\n",
    "import textwrap\n",
    "\n",
    "# –ó–∞—â–∏—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º print_separator –µ—Å–ª–∏ —è—á–µ–π–∫–∞ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ\n",
    "if 'print_separator' not in globals():\n",
    "    def print_separator(nl_before=True):\n",
    "        SEP = '=' * 60\n",
    "        if nl_before:\n",
    "            print('\\n' + SEP)\n",
    "        else:\n",
    "            print(SEP + '\\n')\n",
    "\n",
    "is_kaggle = any(p.startswith('/kaggle') for p in (os.getcwd(),)) or os.environ.get('KAGGLE_KERNEL_RUN_TYPE') is not None\n",
    "print_separator()\n",
    "print('üß≠ KAGGLE CHECK')\n",
    "print_separator(nl_before=False)\n",
    "print('Running in Kaggle environment:', is_kaggle)\n",
    "\n",
    "# GPU check (non-blocking): try to detect torch without blocking the notebook\n",
    "import importlib.util\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "try:\n",
    "    if importlib.util.find_spec('torch') is None:\n",
    "        print('Torch not installed ‚Äî GPU check skipped (will be checked again in import cell).')\n",
    "    else:\n",
    "        print('Torch package detected ‚Äî running lightweight subprocess check (timeout 12s) to avoid hanging import...')\n",
    "        try:\n",
    "            cmd = [sys.executable, '-c', 'import torch, json; print(json.dumps({\"cuda\": torch.cuda.is_available(), \"device_count\": torch.cuda.device_count(), \"device_name\": (torch.cuda.get_device_name(0).strip() if torch.cuda.is_available() else \"no gpu\")}))']\n",
    "            # timeout can be adjusted via env var KAGGLE_TORCH_CHECK_TIMEOUT (seconds)\n",
    "            _timeout = int(os.environ.get('KAGGLE_TORCH_CHECK_TIMEOUT', '12'))\n",
    "            print(f'(torch subprocess timeout set to {_timeout}s)')\n",
    "            res = subprocess.run(cmd, capture_output=True, text=True, timeout=_timeout)\n",
    "            if res.returncode == 0 and res.stdout:\n",
    "                try:\n",
    "                    info = json.loads(res.stdout.strip())\n",
    "                    cuda_avail = info.get('cuda', False)\n",
    "                    device_name = info.get('device_name', 'no gpu')\n",
    "                    print(f'GPU available: {cuda_avail} ‚Äî {device_name}')\n",
    "                except Exception:\n",
    "                    print('‚úì torch detected but could not parse subprocess output:', res.stdout.strip())\n",
    "            else:\n",
    "                print('‚ö†Ô∏è torch subprocess failed or produced no output. stderr:', res.stderr.strip())\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print('‚ö†Ô∏è Torch import timed out (subprocess). Skipping GPU check to avoid hanging the notebook.')\n",
    "except Exception as _e:\n",
    "    print('Torch check skipped (error):', _e)\n",
    "\n",
    "# Check for Hugging Face token in environment or common Kaggle input path\n",
    "hf_token = os.environ.get('HUGGINGFACE_HUB_TOKEN') or os.environ.get('HF_TOKEN')\n",
    "# First try the canonical path /kaggle/input/hf-token/token.txt\n",
    "hf_token_file = '/kaggle/input/hf-token/token.txt'\n",
    "found_token_path = None\n",
    "if not hf_token and os.path.exists(hf_token_file):\n",
    "    try:\n",
    "        with open(hf_token_file, 'r', encoding='utf-8') as f:\n",
    "            hf_token = f.read().strip()\n",
    "            os.environ['HUGGINGFACE_HUB_TOKEN'] = hf_token\n",
    "            found_token_path = hf_token_file\n",
    "            print(f'‚úì Hugging Face token found in {hf_token_file} and set to HUGGINGFACE_HUB_TOKEN')\n",
    "    except Exception as e:\n",
    "        print('‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å token file:', e)\n",
    "\n",
    "# If still not found, search all /kaggle/input/** for token*.txt (flexible)\n",
    "if not hf_token:\n",
    "    try:\n",
    "        import glob\n",
    "        candidates = glob.glob('/kaggle/input/**/token*.txt', recursive=True)\n",
    "        if candidates:\n",
    "            # pick the first reasonable candidate\n",
    "            for c in candidates:\n",
    "                try:\n",
    "                    with open(c, 'r', encoding='utf-8') as f:\n",
    "                        t = f.read().strip()\n",
    "                    if t:\n",
    "                        hf_token = t\n",
    "                        os.environ['HUGGINGFACE_HUB_TOKEN'] = hf_token\n",
    "                        found_token_path = c\n",
    "                        print(f'‚úì Hugging Face token found in {c} and set to HUGGINGFACE_HUB_TOKEN')\n",
    "                        break\n",
    "                except Exception:\n",
    "                    continue\n",
    "    except Exception as _e:\n",
    "        print('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ token files:', _e)\n",
    "\n",
    "if hf_token:\n",
    "    print('‚úì Hugging Face token available via environment.')\n",
    "    if found_token_path:\n",
    "        print('  (token loaded from:', found_token_path + ')')\n",
    "else:\n",
    "    print('\\n‚ö†Ô∏è Hugging Face token not found.')\n",
    "    print(textwrap.dedent('''\n",
    "    –ß—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª–∏ —Å Hugging Face –≤ Kaggle, –¥–æ–±–∞–≤—å—Ç–µ –≤–∞—à —Ç–æ–∫–µ–Ω —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
    "\n",
    "    1) –í –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ Kaggle: Add Data -> —Å–æ–∑–¥–∞–π—Ç–µ dataset —Å —Ñ–∞–π–ª–æ–º token.txt (—Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞—à —Ç–æ–∫–µ–Ω) –∏ –ø–æ–¥–∫–ª—é—á–∏—Ç–µ –µ–≥–æ –∫ –Ω–æ—É—Ç–±—É–∫—É –∫–∞–∫ /kaggle/input/hf-token\n",
    "    2) –õ–∏–±–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è –ø—Ä—è–º–æ –≤ –Ω–æ—É—Ç–±—É–∫–µ (–≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–µ):\n",
    "\n",
    "       import os\n",
    "       os.environ['HUGGINGFACE_HUB_TOKEN'] = '–í–ê–®_–¢–û–ö–ï–ù'\n",
    "\n",
    "    –ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ç–æ–∫–µ–Ω–∞ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ kernel.\n",
    "    '''))\n",
    "\n",
    "# ipywidgets hint\n",
    "try:\n",
    "    import ipywidgets  # type: ignore\n",
    "    print('‚úì ipywidgets –¥–æ—Å—Ç—É–ø–µ–Ω')\n",
    "except Exception:\n",
    "    print('\\n‚ö†Ô∏è ipywidgets –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî GUI –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å.')\n",
    "    print('  –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ ipywidgets –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–µ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ kernel:')\n",
    "    print('\\n```bash\\n!pip install ipywidgets -q\\n```\\n')\n",
    "\n",
    "# Quick safe defaults suggestion for Kaggle (optional)\n",
    "if is_kaggle:\n",
    "    print('\\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤ Kaggle:')\n",
    "    print('  - –í–∫–ª—é—á–∏—Ç–µ GPU –≤ Settings -> Accelerator -> GPU')\n",
    "    print('  - –î–ª—è —Ç–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–µ–±–æ–ª—å—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: WIDTH=256, HEIGHT=256, NUM_FRAMES=4, STEPS=15')\n",
    "    print('  - –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ –ø–∞–º—è—Ç—å, —É–º–µ–Ω—å—à–∏—Ç–µ WIDTH/NUM_FRAMES –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ model_cpu_offload() (pipeline —É–∂–µ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è —Å —ç—Ç–∏–º —Ñ–ª–∞–≥–æ–º)')\n",
    "\n",
    "print_separator()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === SMOKE TEST (–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è prompts.json –∏ Hugging Face token) ===\n",
    "import glob, os, json\n",
    "print_separator()\n",
    "print('üîé SMOKE TEST ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ prompts.json –∏ Hugging Face token')\n",
    "print_separator(nl_before=False)\n",
    "\n",
    "# –ü–æ–∫–∞–∂–µ–º –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–µ input'—ã\n",
    "inputs = glob.glob('/kaggle/input/*') if os.path.exists('/kaggle/input') else []\n",
    "print('Connected input datasets:', inputs)\n",
    "\n",
    "# –ò—â–µ–º prompts.json\n",
    "prompts_candidates = glob.glob('/kaggle/input/**/prompts.json', recursive=True) if os.path.exists('/kaggle/input') else []\n",
    "if not prompts_candidates and os.path.exists('/kaggle/working/prompts.json'):\n",
    "    prompts_candidates = ['/kaggle/working/prompts.json']\n",
    "\n",
    "if prompts_candidates:\n",
    "    p = prompts_candidates[0]\n",
    "    print('‚úì prompts.json found at:', p)\n",
    "    try:\n",
    "        with open(p, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print('  keys:', list(data.keys()))\n",
    "        # preview safe snippets\n",
    "        base = (data.get('BASE_PROMPT') or '')[:200]\n",
    "        motion = (data.get('MOTION_PROMPT') or '')[:120]\n",
    "        print('  BASE_PROMPT preview:', base)\n",
    "        print('  MOTION_PROMPT preview:', motion)\n",
    "    except Exception as e:\n",
    "        print('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ prompts.json:', e)\n",
    "else:\n",
    "    print('‚ö†Ô∏è prompts.json not found in /kaggle/input or /kaggle/working. Attach dataset or upload file.')\n",
    "    print(\"  Tips: Add Data -> attach 'noxfvr/comfy-gojo-dataset' or upload prompts.json to working dir.\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º Hugging Face token (–±–µ–∑ –≤—ã–≤–æ–¥–∞ –ø–æ–ª–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è)\n",
    "token = os.environ.get('HUGGINGFACE_HUB_TOKEN') or os.environ.get('HF_TOKEN')\n",
    "if token:\n",
    "    print('\\n‚úì HUGGINGFACE_HUB_TOKEN found in environment (masked):')\n",
    "    try:\n",
    "        print('  length:', len(token), 'prefix:', token[:6] + '...')\n",
    "    except Exception:\n",
    "        print('  (cannot preview token)')\n",
    "    # –ü—ã—Ç–∞–µ–º—Å—è –≤–∞–ª–∏–¥–∞—Ü–∏—é, –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω huggingface_hub\n",
    "    try:\n",
    "        from huggingface_hub import HfApi\n",
    "        api = HfApi()\n",
    "        info = api.whoami(token=token)\n",
    "        user = info.get('name') or info.get('user') or info\n",
    "        print('  HF token appears valid; user:', user)\n",
    "    except Exception as e:\n",
    "        print('  Could not validate token with huggingface_hub (not installed or error):', e)\n",
    "        print(\"  To validate: run '!pip install -q huggingface_hub' and re-run this cell\")\n",
    "else:\n",
    "    print('\\n‚ö†Ô∏è HUGGINGFACE_HUB_TOKEN not found in environment.')\n",
    "    print('  If you have hf-token dataset attached, ensure it contains token.txt and restart the kernel.')\n",
    "\n",
    "print_separator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# üìù –ù–ê–°–¢–†–û–ô–ö–ò - –ú–ï–ù–Ø–ô –¢–û–õ–¨–ö–û –≠–¢–û!\n",
    "# ============================================\n",
    "# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ø—Ä–æ–º–ø—Ç–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–µ—Å—Ç–∞—Ö)\n",
    "DEFAULT_BASE_PROMPT = \"cinematic portrait of gojo satoru, white spiky hair, black blindfold, confident expression, anime style, highly detailed, 8k, professional lighting\"\n",
    "DEFAULT_NEGATIVE_PROMPT = \"blurry, deformed, low quality, watermark, text, bad anatomy, multiple heads, duplicate\"\n",
    "\n",
    "PROMPT = DEFAULT_BASE_PROMPT\n",
    "NEGATIVE_PROMPT = DEFAULT_NEGATIVE_PROMPT\n",
    "\n",
    "# –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã\n",
    "USE_ANIMATEDIFF = True  # True = –Ω–∞—Å—Ç–æ—è—â–∞—è –∞–Ω–∏–º–∞—Ü–∏—è, False = —Å—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã + RIFE\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
    "WIDTH = 512\n",
    "HEIGHT = 768\n",
    "NUM_FRAMES = 16 if USE_ANIMATEDIFF else 8  # AnimateDiff: 16-24, –æ–±—ã—á–Ω—ã–π: 8-12\n",
    "STEPS = 25 if USE_ANIMATEDIFF else 20  # –î–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ steps\n",
    "CFG_SCALE = 7.5 if USE_ANIMATEDIFF else 7\n",
    "FPS = 8  # FPS –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ\n",
    "\n",
    "# –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è RIFE (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
    "USE_RIFE = True  # –ü—Ä–∏–º–µ–Ω–∏—Ç—å RIFE –¥–ª—è –µ—â—ë –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω–æ–π –∞–Ω–∏–º–∞—Ü–∏–∏\n",
    "RIFE_EXP = 4 if USE_ANIMATEDIFF else 5  # AnimateDiff: 4 (16‚Üí256), –æ–±—ã—á–Ω—ã–π: 5 (8‚Üí256)\n",
    "# –ò–º—è —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –∞–ø—Å–∫–µ–π–ª–∞ (Real-ESRGAN)\n",
    "UPSCALE_MODEL_NAME = '4x-UltraSharp.pth'\n",
    "# ============================================\n",
    "\n",
    "# === PROMPTS ‚Äî –í–ê–®–ò PROMPT'–´ –î–õ–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø –ò –ê–ù–ò–ú–ê–¶–ò–ò (–ø–µ—Ä–µ–º–µ—â–µ–Ω–∞) ===\n",
    "# –≠—Ç–∞ —è—á–µ–π–∫–∞ —Ç–µ–ø–µ—Ä—å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ø—Ä—è–º–æ –ø–æ—Å–ª–µ –±–ª–æ–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–∫. –†–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –∑–¥–µ—Å—å BASE/MOTION/EXTRA/NEGATIVE\n",
    "import os\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤\n",
    "PROMPTS_FILE = os.path.join(os.getcwd(), 'prompts.json')\n",
    "\n",
    "# –ù–∞–±–æ—Ä –ø—Ä–µ—Å–µ—Ç–æ–≤: –∏–º—è -> (base, motion, extra, negative)\n",
    "PRESETS = {\n",
    "    'default': (\n",
    "        DEFAULT_BASE_PROMPT,\n",
    "        \"turning head, hair flowing, smooth motion\",\n",
    "        \"dramatic rim lighting, soft bloom, depth of field\",\n",
    "        DEFAULT_NEGATIVE_PROMPT\n",
    "    ),\n",
    "    'slow pan': (\n",
    "        \"cinematic portrait, highly detailed, 8k, beautiful face\",\n",
    "        \"slow camera pan left, subtle head turn\",\n",
    "        \"soft warm lighting, cinematic\",\n",
    "        \"blurry, low quality, watermark, text\"\n",
    "    ),\n",
    "    'head turn': (\n",
    "        \"close-up portrait, detailed, professional lighting\",\n",
    "        \"turning head to left then right, hair movement\",\n",
    "        \"rim light, subtle bloom\",\n",
    "        \"multiple heads, deformed, watermark\"\n",
    "    ),\n",
    "    'blinking': (\n",
    "        \"portrait, soft lighting, anime style\",\n",
    "        \"subtle blink, small head tilt\",\n",
    "        \"soft bokeh, cinematic lighting\",\n",
    "        \"blurry, artifact, watermark\"\n",
    "    )\n",
    "}\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ—Å–µ—Ç (–µ—Å–ª–∏ PROMPT —É–∂–µ –∑–∞–¥–∞–Ω, –ø—ã—Ç–∞–µ–º—Å—è —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å)\n",
    "def load_preset(name):\n",
    "    if name in PRESETS:\n",
    "        base, motion, extra, negative = PRESETS[name]\n",
    "        return {'BASE_PROMPT': base, 'MOTION_PROMPT': motion, 'EXTRA_PROMPT': extra, 'NEGATIVE_PROMPT': negative}\n",
    "    return None\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ prompts.json\n",
    "def save_prompts_file(data, path=PROMPTS_FILE):\n",
    "    try:\n",
    "        import json\n",
    "        with open(path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"‚úì Prompts saved to {path}\")\n",
    "    except Exception as e:\n",
    "        print('‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å prompts.json:', e)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ prompts.json\n",
    "def load_prompts_file(path=PROMPTS_FILE):\n",
    "    try:\n",
    "        import json\n",
    "        if os.path.exists(path):\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "    except Exception as e:\n",
    "        print('‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å prompts.json:', e)\n",
    "    return None\n",
    "\n",
    "# –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–∏—Ç—å ipywidgets; –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî –≤—ã–≤–æ–¥–∏–º fallback –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏\n",
    "def create_prompts_gui():\n",
    "    try:\n",
    "        import ipywidgets as widgets\n",
    "    except Exception:\n",
    "        print('‚ö†Ô∏è ipywidgets –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî GUI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install ipywidgets')\n",
    "        # Fallback: –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞—ë–º PROMP–¢ –∏–∑ —Ç–µ–∫—É—â –∫–æ–Ω—Å—Ç–∞–Ω—Ç\n",
    "        parts = [p for p in (globals().get('PROMPT', ''), '') if p]\n",
    "        globals()['PROMPT'] = globals().get('PROMPT', '')\n",
    "        globals()['NEGATIVE_PROMPT'] = globals().get('NEGATIVE_PROMPT', '')\n",
    "        print('\\nPROMPT (fallback):', globals()['PROMPT'])\n",
    "        return\n",
    "\n",
    "    # –í–∏–¥–∂–µ—Ç—ã\n",
    "    preset_dropdown = widgets.Dropdown(options=list(PRESETS.keys()), value='default', description='Preset:')\n",
    "    base_ta = widgets.Textarea(value=PRESETS['default'][0], description='Base:', layout=widgets.Layout(width='100%', height='80px'))\n",
    "    motion_ta = widgets.Textarea(value=PRESETS['default'][1], description='Motion:', layout=widgets.Layout(width='100%', height='60px'))\n",
    "    extra_ta = widgets.Textarea(value=PRESETS['default'][2], description='Extra:', layout=widgets.Layout(width='100%', height='60px'))\n",
    "    negative_ta = widgets.Textarea(value=PRESETS['default'][3], description='Negative:', layout=widgets.Layout(width='100%', height='60px'))\n",
    "\n",
    "    save_btn = widgets.Button(description='Save to prompts.json', button_style='success')\n",
    "    load_btn = widgets.Button(description='Load from prompts.json')\n",
    "    update_btn = widgets.Button(description='Update PROMPT', button_style='primary')\n",
    "    out = widgets.Output()\n",
    "\n",
    "    # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏\n",
    "    def on_preset_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            vals = load_preset(change['new'])\n",
    "            if vals:\n",
    "                base_ta.value = vals['BASE_PROMPT']\n",
    "                motion_ta.value = vals['MOTION_PROMPT']\n",
    "                extra_ta.value = vals['EXTRA_PROMPT']\n",
    "                negative_ta.value = vals['NEGATIVE_PROMPT']\n",
    "\n",
    "    def on_save_clicked(b):\n",
    "        data = {\n",
    "            'BASE_PROMPT': base_ta.value,\n",
    "            'MOTION_PROMPT': motion_ta.value,\n",
    "            'EXTRA_PROMPT': extra_ta.value,\n",
    "            'NEGATIVE_PROMPT': negative_ta.value\n",
    "        }\n",
    "        save_prompts_file(data)\n",
    "\n",
    "    def on_load_clicked(b):\n",
    "        data = load_prompts_file()\n",
    "        if data:\n",
    "            base_ta.value = data.get('BASE_PROMPT', base_ta.value)\n",
    "            motion_ta.value = data.get('MOTION_PROMPT', motion_ta.value)\n",
    "            extra_ta.value = data.get('EXTRA_PROMPT', extra_ta.value)\n",
    "            negative_ta.value = data.get('NEGATIVE_PROMPT', negative_ta.value)\n",
    "            with out:\n",
    "                clear_output()\n",
    "                print('‚úì Prompts loaded into GUI (not yet applied)')\n",
    "        else:\n",
    "            with out:\n",
    "                clear_output()\n",
    "                print('‚ö†Ô∏è prompts.json –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω')\n",
    "\n",
    "    def on_update_clicked(b):\n",
    "        # –°–æ–±–∏—Ä–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π PROMPT\n",
    "        parts = [p.strip() for p in (base_ta.value, motion_ta.value, extra_ta.value) if p and p.strip()]\n",
    "        final = ', '.join(parts)\n",
    "        globals()['PROMPT'] = final\n",
    "        globals()['NEGATIVE_PROMPT'] = negative_ta.value\n",
    "        with out:\n",
    "            clear_output()\n",
    "            print('‚úì PROMPT –æ–±–Ω–æ–≤–ª—ë–Ω')\n",
    "            print('\\nPROMPT:')\n",
    "            print(final)\n",
    "            print('\\nNEGATIVE_PROMPT:')\n",
    "            print(negative_ta.value)\n",
    "\n",
    "    preset_dropdown.observe(on_preset_change)\n",
    "    save_btn.on_click(on_save_clicked)\n",
    "    load_btn.on_click(on_load_clicked)\n",
    "    update_btn.on_click(on_update_clicked)\n",
    "\n",
    "    # Layout\n",
    "    controls = widgets.VBox([\n",
    "        preset_dropdown,\n",
    "        base_ta,\n",
    "        motion_ta,\n",
    "        extra_ta,\n",
    "        negative_ta,\n",
    "        widgets.HBox([update_btn, save_btn, load_btn]),\n",
    "        out\n",
    "    ])\n",
    "\n",
    "    display(controls)\n",
    "    # –ü–æ–ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å prompts.json –≤ GUI –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "    data = load_prompts_file()\n",
    "    if data:\n",
    "        base_ta.value = data.get('BASE_PROMPT', base_ta.value)\n",
    "        motion_ta.value = data.get('MOTION_PROMPT', motion_ta.value)\n",
    "        extra_ta.value = data.get('EXTRA_PROMPT', extra_ta.value)\n",
    "        negative_ta.value = data.get('NEGATIVE_PROMPT', negative_ta.value)\n",
    "        with out:\n",
    "            print('‚úì prompts.json –∑–∞–≥—Ä—É–∂–µ–Ω –≤ GUI')\n",
    "\n",
    "# –í—ã–∑—ã–≤–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ GUI\n",
    "create_prompts_gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ===\n",
    "import os\n",
    "import time\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "WORKSPACE = \"/kaggle/working\"\n",
    "FRAMES_DIR = f\"{WORKSPACE}/frames\"\n",
    "DATASET_DIR = \"/kaggle/input/comfyui-models-gojo\"\n",
    "\n",
    "os.makedirs(FRAMES_DIR, exist_ok=True)\n",
    "print(\"‚úì –ü–∞–ø–∫–∏ —Å–æ–∑–¥–∞–Ω—ã\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô ===\n",
    "print(\"üîß –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...\\n\")\n",
    "\n",
    "import sys\n",
    "import importlib.util\n",
    "\n",
    "def check_package(package_name):\n",
    "    \"\"\"–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–∞–∫–µ—Ç–∞ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞\"\"\"\n",
    "    return importlib.util.find_spec(package_name) is not None\n",
    "\n",
    "# –°–ø–∏—Å–æ–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤\n",
    "packages_to_install = []\n",
    "\n",
    "if not check_package(\"diffusers\"):\n",
    "    packages_to_install.append(\"diffusers[torch]\")\n",
    "    packages_to_install.append(\"transformers\")\n",
    "    packages_to_install.append(\"accelerate\")\n",
    "else:\n",
    "    print(\"‚úì diffusers —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "\n",
    "if not check_package(\"cv2\"):\n",
    "    packages_to_install.append(\"opencv-python\")\n",
    "else:\n",
    "    print(\"‚úì opencv-python —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "\n",
    "if USE_ANIMATEDIFF and not check_package(\"imageio\"):\n",
    "    packages_to_install.append(\"imageio\")\n",
    "    packages_to_install.append(\"imageio-ffmpeg\")\n",
    "elif USE_ANIMATEDIFF:\n",
    "    print(\"‚úì imageio —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º ipywidgets –¥–ª—è GUI, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç\n",
    "if not check_package(\"ipywidgets\"):\n",
    "    packages_to_install.append(\"ipywidgets\")\n",
    "else:\n",
    "    print(\"‚úì ipywidgets —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –ø–∞–∫–µ—Ç—ã –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π (—á–µ—Ä–µ–∑ subprocess –¥–ª—è –ø–µ—Ä–µ–Ω–æ—Å–∏–º–æ—Å—Ç–∏)\n",
    "if packages_to_install:\n",
    "    print(f\"\\n–£—Å—Ç–∞–Ω–æ–≤–∫–∞: {', '.join(packages_to_install)}...\")\n",
    "    import subprocess\n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º Python interpreter –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤ —Ç–µ–∫—É—â–µ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + packages_to_install)\n",
    "    print(\"‚úì –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
    "    # –ü—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —É—Å—Ç–∞–Ω–æ–≤–∫–µ ipywidgets –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ kernel –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–±–æ—Ç—ã GUI\n",
    "    if 'ipywidgets' in packages_to_install:\n",
    "        print('\\n‚ö†Ô∏è ipywidgets —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ‚Äî –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ kernel (Restart Kernel) –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ Kaggle, —á—Ç–æ–±—ã GUI –∑–∞—Ä–∞–±–æ—Ç–∞–ª –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.')\n",
    "\n",
    "print(\"\\n‚úì –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≥–æ—Ç–æ–≤—ã!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== –ü–û–î–ê–í–õ–ï–ù–ò–ï –®–£–ú–ê –û–¢ XLA / TensorFlow / absl ===\n",
    "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –î–û –∏–º–ø–æ—Ä—Ç–æ–≤, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä—É—é—â–µ–π —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ CUDA-–ø–ª–∞–≥–∏–Ω–æ–≤\n",
    "import os\n",
    "# –°–∫—Ä—ã—Ç—å INFO/WARNING TensorFlow-–ª–æ–≥–∏ (–µ—Å–ª–∏ TF –ø–æ–¥–≥—Ä—É–∂–∞–µ—Ç—Å—è –∫–æ—Å–≤–µ–Ω–Ω–æ)\n",
    "os.environ.setdefault('TF_CPP_MIN_LOG_LEVEL', '3')\n",
    "# –û—Ç–∫–ª—é—á–∏—Ç—å –ø—Ä–µ–¥–∞–ª–æ–∫–∞—Ü–∏—é –ø–∞–º—è—Ç–∏ —É XLA –∫–ª–∏–µ–Ω—Ç–∞ (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω jax/xla)\n",
    "os.environ.setdefault('XLA_PYTHON_CLIENT_PREALLOCATE', 'false')\n",
    "os.environ.setdefault('XLA_PYTHON_CLIENT_MEM_FRACTION', '0.0')\n",
    "\n",
    "# –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∞–≤–∏—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è absl —É–∂–µ –Ω–∞ —ç—Ç–∞–ø–µ –∏–º–ø–æ—Ä—Ç–∞ (–±–µ–∑ –ø–∞–¥–µ–Ω–∏–π, –µ—Å–ª–∏ absl –Ω–µ—Ç)\n",
    "try:\n",
    "    import absl.logging\n",
    "    # –ù–µ –ø–∏—Å–∞—Ç—å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ stderr\n",
    "    absl.logging._warn_preinit_stderr = False\n",
    "    absl.logging.set_verbosity(absl.logging.WARNING)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# === –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö ===\n",
    "# –ó–∞—â–∏—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ —Ñ—É–Ω–∫—Ü–∏—è print_separator –Ω–µ –±—ã–ª–∞ —Ä–∞–Ω–µ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ (—è—á–µ–π–∫–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª–∞—Å—å),\n",
    "# –æ–ø—Ä–µ–¥–µ–ª–∏–º –ø—Ä–æ—Å—Ç—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é –≤–µ—Ä—Å–∏—é, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å NameError –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –æ—Ç–¥–µ–ª—å–Ω–æ–π —è—á–µ–π–∫–∏.\n",
    "if \"print_separator\" not in globals():\n",
    "    def print_separator(nl_before=True):\n",
    "        SEP = '=' * 60\n",
    "        if nl_before:\n",
    "            print('\\n' + SEP)\n",
    "        else:\n",
    "            print(SEP + '\\n')\n",
    "\n",
    "print_separator()\n",
    "print(\"üé® –ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å ~30 —Å–µ–∫)...\\n\")\n",
    "\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "print(\"‚úì PyTorch –∏ PIL –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n",
    "print(f\"‚úì CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === –ó–ê–ì–†–£–ó–ö–ê ANIMATEDIFF PIPELINE (–æ—Ç–¥–µ–ª—å–Ω–∞—è —è—á–µ–π–∫–∞) ===\n",
    "# –ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –ø–µ—Ä–µ–¥ —è—á–µ–π–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –º–æ–¥–µ–ª—å –∏ —Å—ç–∫–æ–Ω–æ–º–∏—Ç—å –≤—Ä–µ–º—è –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.\n",
    "if 'USE_ANIMATEDIFF' in globals() and USE_ANIMATEDIFF:\n",
    "    if 'pipe' in globals() and 'adapter' in globals():\n",
    "        print('‚úì AnimateDiff pipeline —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω (pipe, adapter –≤ globals).')\n",
    "    else:\n",
    "        print('–ó–∞–≥—Ä—É–∑–∫–∞ AnimateDiff pipeline...')\n",
    "        try:\n",
    "            from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
    "            from diffusers.utils import export_to_video\n",
    "            import torch\n",
    "\n",
    "            adapter = MotionAdapter.from_pretrained(\n",
    "                \"guoyww/animatediff-motion-adapter-v1-5-2\",\n",
    "                torch_dtype=torch.float16\n",
    "            )\n",
    "\n",
    "            # AnimateDiff —Ä–∞–±–æ—Ç–∞–µ—Ç —Å SD 1.5\n",
    "            pipe = AnimateDiffPipeline.from_pretrained(\n",
    "                \"runwayml/stable-diffusion-v1-5\",\n",
    "                motion_adapter=adapter,\n",
    "                torch_dtype=torch.float16\n",
    "            ).to(\"cuda\")\n",
    "\n",
    "            pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "            pipe.enable_vae_slicing()\n",
    "            pipe.enable_model_cpu_offload()\n",
    "\n",
    "            print('‚úì AnimateDiff –≥–æ—Ç–æ–≤! (adapter & pipe –∑–∞–≥—Ä—É–∂–µ–Ω—ã)')\n",
    "        except Exception as _e:\n",
    "            print('‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å AnimateDiff pipeline:', _e)\n",
    "            print('  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∫—É diffusers, –¥–æ—Å—Ç—É–ø –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∏ –Ω–∞–ª–∏—á–∏–µ CUDA/GPU.')"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–î–†–û–í / –ê–ù–ò–ú–ê–¶–ò–ò ===\n",
    "# –ó–∞—â–∏—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–ø–æ–ª–Ω–∏–ª —Ç–æ–ª—å–∫–æ —ç—Ç—É —è—á–µ–π–∫—É, —Ç–æ —É—Å—Ç–∞–Ω–æ–≤–∏–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é\n",
    "import os\n",
    "import time\n",
    "_defaults = {\n",
    "    'PROMPT': \"cinematic portrait of gojo satoru, white spiky hair, black blindfold, confident expression, anime style, highly detailed, 8k, professional lighting\",\n",
    "    'NEGATIVE_PROMPT': \"blurry, deformed, low quality, watermark, text, bad anatomy, multiple heads, duplicate\",\n",
    "    'USE_ANIMATEDIFF': True,\n",
    "    'USE_RIFE': True,\n",
    "    'WIDTH': 512,\n",
    "    'HEIGHT': 768,\n",
    "    'NUM_FRAMES': 16,\n",
    "    'STEPS': 25,\n",
    "    'CFG_SCALE': 7.5,\n",
    "    'FPS': 8,\n",
    "    'RIFE_EXP': 4,\n",
    "    'WORKSPACE': os.getcwd()\n",
    "}\n",
    "for _k, _v in _defaults.items():\n",
    "    if _k not in globals():\n",
    "        globals()[_k] = _v\n",
    "        print(f\"‚ö†Ô∏è –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è {_k} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {_v}\")\n",
    "\n",
    "# –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫–∞–¥—Ä–æ–≤ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç\n",
    "if 'FRAMES_DIR' not in globals():\n",
    "    FRAMES_DIR = f\"{WORKSPACE}/frames\"\n",
    "os.makedirs(FRAMES_DIR, exist_ok=True)\n",
    "\n",
    "print_separator()\n",
    "print(f\"üé® {'–ì–ï–ù–ï–†–ê–¶–ò–Ø –ê–ù–ò–ú–ê–¶–ò–ò' if USE_ANIMATEDIFF else '–ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–î–†–û–í'}\")\n",
    "print_separator(nl_before=False)\n",
    "print(f\"–ü—Ä–æ–º–ø—Ç: {PROMPT[:80]}...\")\n",
    "print(f\"–†–∞–∑–º–µ—Ä: {WIDTH}x{HEIGHT}, Steps: {STEPS}, CFG: {CFG_SCALE}\")\n",
    "print(f\"–ö–∞–¥—Ä–æ–≤: {NUM_FRAMES}\\n\")\n",
    "\n",
    "if USE_ANIMATEDIFF:\n",
    "    # === –†–ï–ñ–ò–ú ANIMATEDIFF - –ù–ê–°–¢–û–Ø–©–ê–Ø –ê–ù–ò–ú–ê–¶–ò–Ø ===\n",
    "    # –¢–µ–ø–µ—Ä—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π `pipe` (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å). –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –ø–æ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–ø—É—Å—Ç–∏—Ç—å —è—á–µ–π–∫—É –∑–∞–≥—Ä—É–∑–∫–∏.\n",
    "    if 'pipe' not in globals():\n",
    "        print(\"‚ö†Ô∏è AnimateDiff pipeline –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ—Ç–¥–µ–ª—å–Ω—É—é —è—á–µ–π–∫—É '–ó–ê–ì–†–£–ó–ö–ê AN–ò–ú–ê–¶–ò–ò PIPELINE' –ø–µ—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É, —á—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å –µ–≥–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.\")\n",
    "        # –ü–æ–ø—Ä–æ–±—É–µ–º –≤—Å—ë –∂–µ –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å inline (fallback):\n",
    "        try:\n",
    "            from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
    "            from diffusers.utils import export_to_video\n",
    "            import torch\n",
    "\n",
    "            print('–ó–∞–≥—Ä—É–∑–∫–∞ AnimateDiff pipeline (fallback inline)...')\n",
    "            adapter = MotionAdapter.from_pretrained(\n",
    "                \"guoyww/animatediff-motion-adapter-v1-5-2\",\n",
    "                torch_dtype=torch.float16\n",
    "            )\n",
    "            pipe = AnimateDiffPipeline.from_pretrained(\n",
    "                \"runwayml/stable-diffusion-v1-5\",\n",
    "                motion_adapter=adapter,\n",
    "                torch_dtype=torch.float16\n",
    "            ).to(\"cuda\")\n",
    "            pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "            pipe.enable_vae_slicing()\n",
    "            pipe.enable_model_cpu_offload()\n",
    "\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥—Ä—É–∑–∏—Ç—å AnimateDiff pipeline –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: ' + str(e))\n",
    "\n",
    "    print('–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∏–º–∞—Ü–∏–∏ (—ç—Ç–æ –∑–∞–π–º–µ—Ç ~3-7 –º–∏–Ω—É—Ç)...')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–∏–º–∞—Ü–∏—é\n",
    "    output = pipe(\n",
    "        prompt=PROMPT,\n",
    "        negative_prompt=NEGATIVE_PROMPT,\n",
    "        num_frames=NUM_FRAMES,\n",
    "        width=WIDTH,\n",
    "        height=HEIGHT,\n",
    "        num_inference_steps=STEPS,\n",
    "        guidance_scale=CFG_SCALE,\n",
    "        generator=torch.Generator(\"cuda\").manual_seed(42)\n",
    "    )\n",
    "\n",
    "    frames = output.frames[0]\n",
    "    total_gen_time = time.time() - start_time\n",
    "\n",
    "    print(f\"\\n‚úÖ –ê–Ω–∏–º–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞ –∑–∞ {total_gen_time:.1f}s!\\n\")\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä—ã\n",
    "    for i, frame in enumerate(frames):\n",
    "        frame.save(f\"{FRAMES_DIR}/{i}.png\")\n",
    "\n",
    "    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤–æ–µ –≤–∏–¥–µ–æ\n",
    "    base_video = f\"{WORKSPACE}/ANIMATED_BASE.mp4\"\n",
    "    export_to_video(frames, base_video, fps=FPS)\n",
    "    print(f\"‚úì –ë–∞–∑–æ–≤–æ–µ –≤–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ ({len(frames)} –∫–∞–¥—Ä–æ–≤, {FPS} fps)\")\n",
    "\n",
    "    del pipe, adapter\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "else:\n",
    "    # === –†–ï–ñ–ò–ú –°–¢–ê–¢–ò–ß–ù–´–• –ö–ê–î–†–û–í ===\n",
    "    from diffusers import StableDiffusionXLPipeline\n",
    "\n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–ª–∏ HuggingFace\n",
    "    model_path = f\"{DATASET_DIR}/sd_xl_base_1.0.safetensors\"\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        print(\"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º HuggingFace...\")\n",
    "        model_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "    print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SDXL...\")\n",
    "    pipe = StableDiffusionXLPipeline.from_single_file(\n",
    "        model_path,\n",
    "        torch_dtype=torch.float16,\n",
    "        use_safetensors=True\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    pipe.enable_attention_slicing()\n",
    "    pipe.enable_vae_slicing()\n",
    "\n",
    "    print(\"‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!\\n\")\n",
    "\n",
    "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–¥—Ä—ã\n",
    "    start_time = time.time()\n",
    "    for i in range(NUM_FRAMES):\n",
    "        print(f\"–ö–∞–¥—Ä {i+1}/{NUM_FRAMES}...\", end=\" \")\n",
    "\n",
    "        generator = torch.Generator(device=\"cuda\").manual_seed(42 + i)\n",
    "\n",
    "        image = pipe(\n",
    "            prompt=PROMPT,\n",
    "            negative_prompt=NEGATIVE_PROMPT,\n",
    "            width=WIDTH,\n",
    "            height=HEIGHT,\n",
    "            num_inference_steps=STEPS,\n",
    "            guidance_scale=CFG_SCALE,\n",
    "            generator=generator\n",
    "        ).images[0]\n",
    "\n",
    "        image.save(f\"{FRAMES_DIR}/{i}.png\")\n",
    "        print(f\"‚úì ({time.time() - start_time:.1f}s)\")\n",
    "\n",
    "    total_gen_time = time.time() - start_time\n",
    "    print(f\"\\n‚úÖ {NUM_FRAMES} –∫–∞–¥—Ä–æ–≤ –∑–∞ {total_gen_time:.1f}s!\\n\")\n",
    "\n",
    "    del pipe\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"‚úì –ö–∞–¥—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {FRAMES_DIR}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === UPSCALE –° REAL-ESRGAN (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) ===\n",
    "print_separator()\n",
    "print(\"üìà –ê–ü–°–ö–ï–ô–õ –ö–ê–î–†–û–í –° REAL-ESRGAN\")\n",
    "print_separator(nl_before=False)\n",
    "\n",
    "# === CELL 1: minimal guards (idempotent when run separately) ===\n",
    "import os, sys, shutil, subprocess\n",
    "if 'WORKSPACE' not in globals():\n",
    "    WORKSPACE = os.getcwd()\n",
    "    print(f\"‚ö†Ô∏è WORKSPACE not set ‚Äî using {WORKSPACE}\")\n",
    "if 'FRAMES_DIR' not in globals():\n",
    "    FRAMES_DIR = f\"{WORKSPACE}/frames\"\n",
    "    print(f\"‚ö†Ô∏è FRAMES_DIR not set ‚Äî using {FRAMES_DIR}\")\n",
    "if 'DATASET_DIR' not in globals():\n",
    "    DATASET_DIR = f\"{WORKSPACE}/dataset\"\n",
    "    print(f\"‚ö†Ô∏è DATASET_DIR not set ‚Äî using {DATASET_DIR}\")\n",
    "\n",
    "os.makedirs(FRAMES_DIR, exist_ok=True)\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "\n",
    "UPSCALE_MODEL_NAME = globals().get('UPSCALE_MODEL_NAME', '4x-UltraSharp.pth')\n",
    "upscale_model = f\"{DATASET_DIR}/{UPSCALE_MODEL_NAME}\"\n",
    "print('upscale_model =', upscale_model)\n",
    "\n",
    "# === CELL 2: repo check & optional clone ===\n",
    "REPO_DIR = os.path.join(WORKSPACE, 'Real-ESRGAN')\n",
    "print('REPO_DIR =', REPO_DIR)\n",
    "if os.path.exists(upscale_model):\n",
    "    print('Upscale model found at', upscale_model)\n",
    "    if not os.path.exists(REPO_DIR):\n",
    "        print('Cloning Real-ESRGAN into', REPO_DIR)\n",
    "        try:\n",
    "            subprocess.check_call(['git', 'clone', 'https://github.com/xinntao/Real-ESRGAN', REPO_DIR])\n",
    "            print('Clone OK')\n",
    "        except Exception as e:\n",
    "            print('‚ö†Ô∏è Clone failed:', e)\n",
    "else:\n",
    "    print('Upscale model not present ‚Äî to run upscale place model at', upscale_model)\n",
    "\n",
    "# === CELL 3: chdir to repo and prepare logs/install_cmd ===\n",
    "if os.path.exists(REPO_DIR):\n",
    "    os.chdir(REPO_DIR)\n",
    "    print('CWD ->', os.getcwd())\n",
    "else:\n",
    "    print('Repo not present; skipping chdir')\n",
    "\n",
    "LOG_DIR = os.path.join(WORKSPACE, 'logs')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "INSTALL_LOG = os.path.join(LOG_DIR, 'real_esrgan_install.log')\n",
    "INFERENCE_LOG = os.path.join(LOG_DIR, 'real_esrgan_inference.log')\n",
    "install_cmd = [sys.executable, '-m', 'pip', 'install', '--upgrade', 'torchvision', '-f', 'https://download.pytorch.org/whl/torch_stable.html']\n",
    "print('INFERENCE_LOG =', INFERENCE_LOG)\n",
    "\n",
    "# === CELL 4a: build src_candidates list ===\n",
    "src_candidates = []\n",
    "if 'upscale_model' in globals() and upscale_model:\n",
    "    src_candidates.append(upscale_model)\n",
    "src_candidates.append(os.path.join(DATASET_DIR, UPSCALE_MODEL_NAME))\n",
    "src_candidates.append(os.path.join(WORKSPACE, 'dataset', UPSCALE_MODEL_NAME))\n",
    "src_candidates.append(os.path.join(WORKSPACE, 'models', UPSCALE_MODEL_NAME))\n",
    "print('src_candidates:')\n",
    "for p in src_candidates:\n",
    "    print(' -', p)\n",
    "\n",
    "# === CELL 4b: copy first existing candidate into weights/ ===\n",
    "if os.path.exists(REPO_DIR) and src_candidates:\n",
    "    try:\n",
    "        weights_dir = os.path.join(os.getcwd(), 'weights')\n",
    "        os.makedirs(weights_dir, exist_ok=True)\n",
    "        copied = False\n",
    "        for src in src_candidates:\n",
    "            try:\n",
    "                if src and os.path.exists(src):\n",
    "                    shutil.copy(src, weights_dir)\n",
    "                    print('Copied', src, '->', weights_dir)\n",
    "                    copied = True\n",
    "                    break\n",
    "            except Exception as _e:\n",
    "                print('Warning copying', src, ':', _e)\n",
    "        if not copied:\n",
    "            print('No candidate found to copy into weights')\n",
    "    except Exception as e:\n",
    "        print('‚ö†Ô∏è Error preparing weights:', e)\n",
    "else:\n",
    "    print('Skipping weights copy (repo or candidates missing)')\n",
    "\n",
    "# === CELL 5a: candidate_shims list ===\n",
    "candidate_shims = [\n",
    "    os.path.join(WORKSPACE, 'tmp_inference_shim.py'),\n",
    "    os.path.join(os.getcwd(), 'tmp_inference_shim.py'),\n",
    "    os.path.join('/kaggle/working', 'tmp_inference_shim.py'),\n",
    "    os.path.join('/apps/ComfyCloud_My_Work_Flow', 'tmp_inference_shim.py'),\n",
    "]\n",
    "print('candidate_shims:')\n",
    "for c in candidate_shims:\n",
    "    print(' -', c)\n",
    "\n",
    "# === CELL 5b: try copy prepared shim ===\n",
    "shim_path = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\n",
    "wrote = False\n",
    "for c in candidate_shims:\n",
    "    try:\n",
    "        if c and os.path.exists(c):\n",
    "            shutil.copy(c, shim_path)\n",
    "            wrote = os.path.exists(shim_path)\n",
    "            print('Copied shim from', c)\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print('Failed to copy shim from', c, ':', e)\n",
    "print('shim_path exists:', os.path.exists(shim_path))\n",
    "\n",
    "# === CELL 6a: build shim content (parts) ===\n",
    "shim_lines_part1 = 'import sys, os, runpy, types, re'\n",
    "shim_lines_part2 = '# Minimal compatibility shim: define netscale/model/outscale and exec the original script'\n",
    "shim_lines_part3 = 'def _infer_netscale(argv):'\n",
    "shim_lines_part4 = '    for i,a in enumerate(argv):'\n",
    "print('shim parts defined')\n",
    "\n",
    "# === CELL 6b: compose shim_lines and write shim file (if needed) ===\n",
    "if (not os.path.exists(shim_path)) and os.path.exists(REPO_DIR):\n",
    "    shim_lines = [\n",
    "        shim_lines_part1,\n",
    "        shim_lines_part2,\n",
    "        shim_lines_part3,\n",
    "        shim_lines_part4,\n",
    "        \"    if a in ('-n','--name','--model') and i+1<len(argv):\",\n",
    "        \"        m = re.match(r'(\\\\d+)x', argv[i+1])\",\n",
    "        \"        if m:\",\n",
    "        \"            try: return int(m.group(1))\\\\n            except: pass\",\n",
    "        \"    for i,a in enumerate(argv):\",\n",
    "        \"        if a in ('-s','--scale') and i+1<len(argv):\",\n",
    "        \"            try: return int(argv[i+1])\\\\n            except: pass\",\n",
    "        \"    return 4\",\n",
    "        \"if __name__ == '__main__':\",\n",
    "        \"    argv = sys.argv[1:]\",\n",
    "        \"    netscale = _infer_netscale(argv)\",\n",
    "        \"    script_path = os.path.join(os.getcwd(), 'inference_realesrgan.py')\",\n",
    "        \"    try:\",\n",
    "        \"        with open(script_path, 'r', encoding='utf-8') as f:\",\n",
    "        \"            code = f.read()\",\n",
    "        \"    except Exception:\",\n",
    "        \"        sys.argv = [script_path] + argv\",\n",
    "        \"        runpy.run_path('inference_realesrgan.py', run_name='__main__')\",\n",
    "        \"    else:\",\n",
    "        \"        _globals = {'__name__':'__main__', '__file__':script_path, 'netscale':netscale, 'model':None, 'outscale':netscale, 'scale':netscale}\",\n",
    "        \"        _globals['sys'] = sys\",\n",
    "        \"        sys.argv = [script_path] + argv\",\n",
    "        \"        exec(compile(code, script_path, 'exec'), _globals)\",\n",
    "    ]\n",
    "    try:\n",
    "        with open(shim_path, 'w', encoding='utf-8') as sf:\n",
    "            sf.write('\\n'.join(shim_lines))\n",
    "        wrote = os.path.exists(shim_path)\n",
    "        if wrote:\n",
    "            print('Wrote shim to', shim_path)\n",
    "    except Exception as e:\n",
    "        print('Warning: failed to write shim:', e)\n",
    "else:\n",
    "    print('Shim exists or repo missing; shim_path exists =', os.path.exists(shim_path))\n",
    "\n",
    "# === CELL 7a: construct fallback safe_argv & args_literal ===\n",
    "safe_argv = ['-n','4x-UltraSharp','-i', FRAMES_DIR, '-o', FRAMES_DIR + '_upscaled', '--fp32', '--outscale', '4']\n",
    "args_literal = '[' + ','.join(repr(a) for a in safe_argv) + ']'\n",
    "print('safe_argv ->', safe_argv)\n",
    "\n",
    "# === CELL 7b: build run_cmd (shim vs fallback) ‚Äî inspect but don't run ===\n",
    "run_cmd = None\n",
    "if os.path.exists(REPO_DIR):\n",
    "    shim_path = os.path.join(os.getcwd(), 'inference_with_shim_full.py')\n",
    "    if os.path.exists(shim_path):\n",
    "        run_cmd = [sys.executable, shim_path, '-n','4x-UltraSharp','-i',FRAMES_DIR,'-o',FRAMES_DIR + '_upscaled','--fp32','--outscale','4']\n",
    "    else:\n",
    "        pycmd = (\n",
    "            \"import runpy,sys,os,re; argv=\" + args_literal + \"; sys.argv=[os.path.join(os.getcwd(),'inference_realesrgan.py')]+argv; \"\n",
    "            \"def _infer(argv):\\n    import re\\n    for i,a in enumerate(argv):\\n        if a in ('-n','--name','--model') and i+1<len(argv):\\n            m=re.match(r'(\\\\d+)x',argv[i+1]);\\n            if m: return int(m.group(1))\\n    for i,a in enumerate(argv):\\n        if a in ('-s','--scale') and i+1<len(argv):\\n            try: return int(argv[i+1])\\n            except: pass\\n    return 4\\n\"\n",
    "            \"netscale=_infer(argv)\\nrunpy.run_path('inference_realesrgan.py', run_name='__main__')\"\n",
    "        )\n",
    "        run_cmd = [sys.executable, '-c', pycmd]\n",
    "print('Prepared run_cmd:')\n",
    "print(run_cmd)\n",
    "print('\\nWhen ready ‚Äî run the next cell to execute inference.')\n",
    "\n",
    "# === CELL 8: execute run_cmd (inference) ‚Äî run only after inspection ===\n",
    "if run_cmd is None:\n",
    "    print('run_cmd undefined ‚Äî build it first (previous cell)')\n",
    "else:\n",
    "    print('Running:', run_cmd)\n",
    "    try:\n",
    "        res = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600)\n",
    "    except Exception as e:\n",
    "        print('Failed to run subprocess:', e)\n",
    "        res = None\n",
    "    if res is not None:\n",
    "        try:\n",
    "            with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n",
    "                lf.write('=== STDOUT ===\\n')\n",
    "                lf.write(res.stdout or '')\n",
    "                lf.write('\\n=== STDERR ===\\n')\n",
    "                lf.write(res.stderr or '')\n",
    "        except Exception:\n",
    "            pass\n",
    "        print('Return code =', getattr(res,'returncode',None))\n",
    "        if res.returncode == 0:\n",
    "            print('‚úì Inference completed ‚Äî see', INFERENCE_LOG)\n",
    "        else:\n",
    "            print('‚úó Inference failed ‚Äî see', INFERENCE_LOG)\n",
    "            globals()['last_inference_stderr'] = res.stderr\n",
    "\n",
    "# === CELL 9a: If stderr mentions functional_tensor ‚Äî prepare minimal stub strings ===\n",
    "# (define strings separately so user can inspect before writing)\n",
    "if 'last_inference_stderr' in globals():\n",
    "    _stderr_preview = (globals().get('last_inference_stderr') or '').lower()\n",
    "else:\n",
    "    _stderr_preview = ''\n",
    "print('stderr preview contains functional_tensor:', 'functional_tensor' in _stderr_preview)\n",
    "\n",
    "# Prepare stub strings (do not write yet)\n",
    "tv_init = \"\"\"# Minimal stub torchvision package for Real-ESRGAN/basicsr compatibility\n",
    "from . import utils\n",
    "from . import transforms\n",
    "__all__ = ['utils','transforms']\n",
    "\"\"\"\n",
    "\n",
    "utils_code = \"\"\"# Minimal stub for torchvision.utils.make_grid\n",
    "try:\n",
    "    from torchvision.utils import make_grid as _make_grid\n",
    "    def make_grid(tensor, nrow=8, padding=2, normalize=False):\n",
    "        return _make_grid(tensor, nrow=nrow, padding=padding, normalize=normalize)\n",
    "except Exception:\n",
    "    import numpy as _np\n",
    "    from PIL import Image as _Image\n",
    "    import torch as _torch\n",
    "    def make_grid(tensor, nrow=8, padding=2, normalize=False):\n",
    "        if isinstance(tensor, (list, tuple)):\n",
    "            tensor = _torch.stack(tensor, dim=0)\n",
    "        if not isinstance(tensor, _torch.Tensor):\n",
    "            raise TypeError('Fallback make_grid expects a torch.Tensor or list of tensors')\n",
    "        t = tensor.detach().cpu()\n",
    "        if t.dim() == 3:\n",
    "            t = t.unsqueeze(0)\n",
    "        B,C,H,W = t.shape\n",
    "        if normalize:\n",
    "            t = (t - t.min()) / (t.max() - t.min() + 1e-8)\n",
    "        else:\n",
    "            if t.max() > 50:\n",
    "                t = t / 255.0\n",
    "        def to_uint8(x):\n",
    "            arr = (x.numpy().transpose(1,2,0) * 255.0).clip(0,255).astype(_np.uint8)\n",
    "            if arr.shape[2] == 1:\n",
    "                arr = _np.repeat(arr, 3, axis=2)\n",
    "            return _Image.fromarray(arr)\n",
    "        imgs = [to_uint8(t[i]) for i in range(B)]\n",
    "        rows = (B + nrow - 1) // nrow\n",
    "        grid_h = rows * H + padding * (rows - 1)\n",
    "        grid_w = nrow * W + padding * (nrow - 1)\n",
    "        grid = _Image.new('RGB', (grid_w, grid_h), (0,0,0))\n",
    "        for idx, img in enumerate(imgs):\n",
    "            r = idx // nrow\n",
    "            c = idx % nrow\n",
    "            grid.paste(img, (c * (W + padding), r * (H + padding)))\n",
    "        arr = _np.array(grid).transpose(2,0,1).astype(_np.float32) / 255.0\n",
    "        return _torch.from_numpy(arr)\n",
    "\"\"\"\n",
    "\n",
    "tr_init = \"\"\"# transforms package stub\n",
    "from . import functional_tensor\n",
    "__all__ = ['functional_tensor']\n",
    "\"\"\"\n",
    "\n",
    "func_code = \"\"\"# Auto-generated stub: try to import the real functional_tensor, otherwise delegate to torchvision.transforms.functional\n",
    "try:\n",
    "    from torchvision.transforms.functional_tensor import *  # type: ignore\n",
    "except Exception:\n",
    "    try:\n",
    "        from torchvision.transforms import functional as _f\n",
    "    except Exception:\n",
    "        def rgb_to_grayscale(x):\n",
    "            raise ImportError('rgb_to_grayscale not available in this environment')\n",
    "        def convert_image_dtype(x, dtype):\n",
    "            raise ImportError('convert_image_dtype not available in this environment')\n",
    "    else:\n",
    "        rgb_to_grayscale = getattr(_f, 'rgb_to_grayscale', None)\n",
    "        convert_image_dtype = getattr(_f, 'convert_image_dtype', None)\n",
    "    __all__ = [n for n in ('rgb_to_grayscale','convert_image_dtype') if globals().get(n) is not None]\n",
    "\"\"\"\n",
    "\n",
    "print('Prepared stub strings (not written yet)')\n",
    "\n",
    "# === CELL 9b: write stub files and retry run_cmd with PYTHONPATH adjusted ===\n",
    "if 'functional_tensor' in _stderr_preview or 'functional_tensor' in (tail(INFERENCE_LOG, 50) or '').lower():\n",
    "    try:\n",
    "        stub_root = os.path.join(WORKSPACE, 'torchvision_stub')\n",
    "        torchvision_pkg = os.path.join(stub_root, 'torchvision')\n",
    "        transforms_pkg = os.path.join(torchvision_pkg, 'transforms')\n",
    "        shutil.rmtree(stub_root, ignore_errors=True)\n",
    "        os.makedirs(transforms_pkg, exist_ok=True)\n",
    "\n",
    "        with open(os.path.join(torchvision_pkg, '__init__.py'), 'w', encoding='utf-8') as f_init:\n",
    "            f_init.write(tv_init)\n",
    "        with open(os.path.join(torchvision_pkg, 'utils.py'), 'w', encoding='utf-8') as f_utils:\n",
    "            f_utils.write(utils_code)\n",
    "        with open(os.path.join(transforms_pkg, '__init__.py'), 'w', encoding='utf-8') as f_tr:\n",
    "            f_tr.write(tr_init)\n",
    "        with open(os.path.join(transforms_pkg, 'functional_tensor.py'), 'w', encoding='utf-8') as f_ft:\n",
    "            f_ft.write(func_code)\n",
    "\n",
    "        env = os.environ.copy()\n",
    "        prev_pp = env.get('PYTHONPATH', '')\n",
    "        env['PYTHONPATH'] = stub_root + (os.pathsep + prev_pp if prev_pp else '')\n",
    "\n",
    "        print('Running run_cmd with stub PYTHONPATH...')\n",
    "        if run_cmd is None:\n",
    "            print('run_cmd undefined ‚Äî cannot retry')\n",
    "        else:\n",
    "            res_stub = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600, env=env)\n",
    "            print('Stub attempt returncode:', getattr(res_stub,'returncode',None))\n",
    "            try:\n",
    "                with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n",
    "                    lf.write('\\n=== STUB SUBPROCESS STDOUT ===\\n')\n",
    "                    lf.write(res_stub.stdout or '')\n",
    "                    lf.write('\\n=== STUB SUBPROCESS STDERR ===\\n')\n",
    "                    lf.write(res_stub.stderr or '')\n",
    "            except Exception:\n",
    "                pass\n",
    "            if res_stub.returncode == 0:\n",
    "                print('‚úì Inference completed using local stub; see', INFERENCE_LOG)\n",
    "            else:\n",
    "                print('Stub attempt failed with code', res_stub.returncode)\n",
    "                print('Attempting editable install of Real-ESRGAN package then torchvision install and retry...')\n",
    "                try:\n",
    "                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n",
    "                        lf.write('\\n=== Ensuring Real-ESRGAN package is installed (editable) ===\\n')\n",
    "                except Exception:\n",
    "                    pass\n",
    "                try:\n",
    "                    res_pkg = subprocess.run([sys.executable, '-m', 'pip', 'install', '-e', '.'], capture_output=True, text=True, timeout=900)\n",
    "                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n",
    "                        lf.write('\\n=== PKG INSTALL STDOUT ===\\n')\n",
    "                        lf.write(res_pkg.stdout or '')\n",
    "                        lf.write('\\n=== PKG INSTALL STDERR ===\\n')\n",
    "                        lf.write(res_pkg.stderr or '')\n",
    "                except Exception as _pkg_e:\n",
    "                    print('Editable install failed:', _pkg_e)\n",
    "\n",
    "                try:\n",
    "                    res_install = subprocess.run(install_cmd, capture_output=True, text=True, timeout=900)\n",
    "                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n",
    "                        lf.write('\\n=== TORCHVISION INSTALL STDOUT ===\\n')\n",
    "                        lf.write(res_install.stdout or '')\n",
    "                        lf.write('\\n=== TORCHVISION INSTALL STDERR ===\\n')\n",
    "                        lf.write(res_install.stderr or '')\n",
    "                except Exception as _ie:\n",
    "                    print('torchvision install failed:', _ie)\n",
    "                    res_install = None\n",
    "\n",
    "                if res_install and res_install.returncode == 0:\n",
    "                    print('torchvision installed; retrying inference (with stub PYTHONPATH)')\n",
    "                    res2 = subprocess.run(run_cmd, capture_output=True, text=True, timeout=3600, env=env)\n",
    "                    with open(INFERENCE_LOG, 'a', encoding='utf-8') as lf:\n",
    "                        lf.write('\\n=== RETRY STDOUT ===\\n')\n",
    "                        lf.write(res2.stdout or '')\n",
    "                        lf.write('\\n=== RETRY STDERR ===\\n')\n",
    "                        lf.write(res2.stderr or '')\n",
    "                    if res2.returncode == 0:\n",
    "                        print('‚úì Real-ESRGAN inference completed after installing torchvision; see', INFERENCE_LOG)\n",
    "                    else:\n",
    "                        print('Retry also failed ‚Äî see', INFERENCE_LOG)\n",
    "                else:\n",
    "                    print('Could not install torchvision ‚Äî see', INFERENCE_LOG)\n",
    "    except Exception as e:\n",
    "        print('Exception during stub/install/retry:', e)\n",
    "else:\n",
    "    print('No functional_tensor error detected in stderr tail ‚Äî skip stub flow')\n",
    "\n",
    "# === CELL 10: final move/rename upscaled frames into FRAMES_DIR (if present) ===\n",
    "try:\n",
    "    if os.path.exists(FRAMES_DIR + '_upscaled'):\n",
    "        print('Moving upscaled frames into', FRAMES_DIR)\n",
    "        shutil.rmtree(FRAMES_DIR, ignore_errors=True)\n",
    "        shutil.move(FRAMES_DIR + '_upscaled', FRAMES_DIR)\n",
    "        import glob\n",
    "        upscaled_files = sorted(glob.glob(f\"{FRAMES_DIR}/*_out.png\"))\n",
    "        for i, filepath in enumerate(upscaled_files):\n",
    "            try:\n",
    "                os.rename(filepath, f\"{FRAMES_DIR}/{i}.png\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        print('‚úì Upscaled frames moved/renamed')\n",
    "    else:\n",
    "        print('No upscaled frames dir found ‚Äî nothing to move')\n",
    "except Exception as e:\n",
    "    print('Error while moving/renaming upscaled frames:', e)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === –ò–¢–û–ì–ò ===\n",
    "# –ó–∞—â–∏—Ç–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è total_gen_time –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ (—è—á–µ–π–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ –∑–∞–ø—É—Å–∫–∞–ª–∞—Å—å),\n",
    "# —Å—Ç–∞–≤–∏–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 0.0\n",
    "if 'total_gen_time' not in globals():\n",
    "    total_gen_time = 0.0\n",
    "\n",
    "print_separator()\n",
    "print(\"üìã –ò–¢–û–ì–ò –ì–ï–ù–ï–†–ê–¶–ò–ò\")\n",
    "print_separator(nl_before=False)\n",
    "print(f\"–†–µ–∂–∏–º: {'AnimateDiff (–∞–Ω–∏–º–∞—Ü–∏—è)' if USE_ANIMATEDIFF else '–°—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã'}\")\n",
    "print(f\"–ü—Ä–æ–º–ø—Ç: {PROMPT[:50]}...\")\n",
    "print(f\"–†–∞–∑–º–µ—Ä: {WIDTH}x{HEIGHT}\")\n",
    "print(f\"–ö–∞–¥—Ä–æ–≤: {NUM_FRAMES}\" + (f\" ‚Üí {NUM_FRAMES * (2**RIFE_EXP)}\" if USE_RIFE else \"\"))\n",
    "print(f\"–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {total_gen_time:.1f}s\")\n",
    "\n",
    "if USE_ANIMATEDIFF:\n",
    "    print(f\"\\n{'=\"*60}\")\n",
    "    print(\"üí° –°–û–í–ï–¢–´ –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø –ê–ù–ò–ú–ê–¶–ò–ò\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(\"–î–æ–±–∞–≤—å—Ç–µ –≤ –ø—Ä–æ–º–ø—Ç:\")\n",
    "    print(\"  ‚Ä¢ 'turning head', 'blinking', 'hair flowing'\")\n",
    "    print(\"  ‚Ä¢ 'smooth motion', 'cinematic camera movement'\")\n",
    "    print(\"  ‚Ä¢ 'dynamic pose', 'wind blowing'\")\n",
    "    print(\"\\n–î–æ–±–∞–≤—å—Ç–µ –≤ negative:\")\n",
    "    print(\"  ‚Ä¢ 'static', 'frozen', 'choppy animation'\")\n",
    "    print(\"  ‚Ä¢ 'stiff', 'rigid', 'still image'\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚úÖ –í–°–Å –ì–û–¢–û–í–û!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === UNLOAD PIPE (–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ pipeline –∏ VRAM) ===\n",
    "# –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É, —á—Ç–æ–±—ã —É–¥–∞–ª–∏—Ç—å `pipe` –∏ `adapter` –∏–∑ globals –∏ –æ—á–∏—Å—Ç–∏—Ç—å VRAM.\n",
    "def unload_pipe():\n",
    "    \"\"\"–£–¥–∞–ª—è–µ—Ç pipe/adapter –∏–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –∏ –æ—á–∏—â–∞–µ—Ç VRAM (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω torch).\"\"\"\n",
    "    import gc\n",
    "    removed = []\n",
    "    try:\n",
    "        if 'pipe' in globals():\n",
    "            try:\n",
    "                del globals()['pipe']\n",
    "                removed.append('pipe')\n",
    "            except Exception:\n",
    "                pass\n",
    "        if 'adapter' in globals():\n",
    "            try:\n",
    "                del globals()['adapter']\n",
    "                removed.append('adapter')\n",
    "            except Exception:\n",
    "                pass\n",
    "        # –ü–æ–ø—Ä–æ–±—É–µ–º –æ—Å–≤–æ–±–æ–¥–∏—Ç—å GPU –ø–∞–º—è—Ç—å\n",
    "        try:\n",
    "            import torch\n",
    "            torch.cuda.empty_cache()\n",
    "            removed.append('cuda_cache_cleared')\n",
    "        except Exception:\n",
    "            pass\n",
    "        # –û–±—â–∞—è —É–±–æ—Ä–∫–∞ –ø–∞–º—è—Ç–∏\n",
    "        gc.collect()\n",
    "        print(f\"‚úì –£–¥–∞–ª–µ–Ω–æ: {', '.join(removed) if removed else '–Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\")\n",
    "    except Exception as e:\n",
    "        print('‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ pipe:', e)\n",
    "\n",
    "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É –µ—Å–ª–∏ ipywidgets –¥–æ—Å—Ç—É–ø–µ–Ω, –∏–Ω–∞—á–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    btn_unload = widgets.Button(description='Unload pipe (free VRAM)', button_style='warning')\n",
    "    def _on_unload_click(b):\n",
    "        unload_pipe()\n",
    "    btn_unload.on_click(_on_unload_click)\n",
    "    display(btn_unload)\n",
    "except Exception:\n",
    "    print('\\n‚ÑπÔ∏è –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –ø–∞–º—è—Ç–∏ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≤ —è—á–µ–π–∫–µ: unload_pipe()')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === QUICK SMOKE GENERATION ‚Äî –±—ã—Å—Ç—Ä—ã–π placeholder –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ workflow ===\n",
    "# –°–æ–∑–¥–∞—ë—Ç –ø—Ä–æ—Å—Ç—ã–µ –∫–∞–¥—Ä—ã —Å –¥–≤–∏–∂—É—â–∏–º—Å—è —Ç–µ–∫—Å—Ç–æ–º/—ç–ª–µ–º–µ–Ω—Ç–æ–º –∏ —Å–æ–±–∏—Ä–∞–µ—Ç MP4 —á–µ—Ä–µ–∑ ffmpeg.\n",
    "import os\n",
    "import subprocess\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "print_separator()\n",
    "print('‚ö° QUICK SMOKE GENERATION ‚Äî —Å–æ–∑–¥–∞—ë–º placeholder-–∫–∞–¥—Ä—ã')\n",
    "print_separator(nl_before=False)\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã (–±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –Ω–µ–±–æ–ª—å—à–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è)\n",
    "SMOKE_WIDTH = 256\n",
    "SMOKE_HEIGHT = 256\n",
    "SMOKE_FRAMES = 8\n",
    "SMOKE_FPS = 8\n",
    "\n",
    "# –ü—É—Ç—å –¥–ª—è –∫–∞–¥—Ä–æ–≤\n",
    "if 'WORKSPACE' not in globals():\n",
    "    WORKSPACE = os.getcwd()\n",
    "SMOKE_FRAMES_DIR = f\"{WORKSPACE}/smoke_frames\"\n",
    "os.makedirs(SMOKE_FRAMES_DIR, exist_ok=True)\n",
    "\n",
    "# –ü—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "prompt_text = globals().get('PROMPT', 'Test generation ‚Äî change PROMPT cell')\n",
    "text_preview = (prompt_text or '')[:120]\n",
    "\n",
    "# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–¥—Ä—ã\n",
    "for i in range(SMOKE_FRAMES):\n",
    "    # —Ñ–æ–Ω –∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç\n",
    "    r = (30 + i * 20) % 256\n",
    "    g = (80 + i * 10) % 256\n",
    "    b = (160 + i * 5) % 256\n",
    "    img = Image.new('RGB', (SMOKE_WIDTH, SMOKE_HEIGHT), (r, g, b))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    try:\n",
    "        font = ImageFont.load_default()\n",
    "    except Exception:\n",
    "        font = None\n",
    "    # –¥–≤–∏–∂—É—â–∏–π—Å—è —Ç–µ–∫—Å—Ç\n",
    "    w, h = draw.textsize(text_preview, font=font)\n",
    "    x = int((SMOKE_WIDTH - w) * i / max(1, SMOKE_FRAMES - 1))\n",
    "    y = SMOKE_HEIGHT // 2 - h // 2\n",
    "    draw.text((x, y), text_preview, fill=(255, 255, 255), font=font)\n",
    "    # –¥–≤–∏–∂—É—â–∏–π—Å—è –∫—Ä—É–∂–æ–∫\n",
    "    cx = int(SMOKE_WIDTH * (0.2 + 0.6 * (i / max(1, SMOKE_FRAMES - 1))))\n",
    "    cy = int(SMOKE_HEIGHT * 0.25)\n",
    "    r0 = 12\n",
    "    draw.ellipse((cx - r0, cy - r0, cx + r0, cy + r0), fill=(255, 200, 0))\n",
    "    # –ø–æ–¥–ø–∏—Å—å –∫–∞–¥—Ä–∞\n",
    "    draw.text((6, SMOKE_HEIGHT - 14), f'frame {i+1}/{SMOKE_FRAMES}', fill=(230,230,230), font=font)\n",
    "    path = os.path.join(SMOKE_FRAMES_DIR, f\"{i}.png\")\n",
    "    img.save(path)\n",
    "    print(f'  saved {path}')\n",
    "\n",
    "# –°–æ–±–∏—Ä–∞–µ–º MP4 —á–µ—Ä–µ–∑ ffmpeg\n",
    "smoke_video = f\"{WORKSPACE}/SMOKE_OUTPUT.mp4\"\n",
    "ffmpeg_cmd = [\n",
    "    'ffmpeg', '-y', '-framerate', str(SMOKE_FPS), '-i', f\"{SMOKE_FRAMES_DIR}/%d.png\",\n",
    "    '-c:v', 'libx264', '-pix_fmt', 'yuv420p', '-preset', 'fast', smoke_video\n",
    "]\n",
    "print('\\n–ó–∞–ø—É—Å–∫ ffmpeg...')\n",
    "try:\n",
    "    subprocess.check_call(ffmpeg_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    print(f'‚úì Smoke video saved: {smoke_video}')\n",
    "    try:\n",
    "        from IPython.display import FileLink, display\n",
    "        display(FileLink(smoke_video))\n",
    "    except Exception:\n",
    "        pass\n",
    "except Exception as e:\n",
    "    print('‚ö†Ô∏è ffmpeg failed or not available:', e)\n",
    "    print('  You can manually assemble frames using:')\n",
    "    print(f\"  ffmpeg -framerate {SMOKE_FPS} -i {SMOKE_FRAMES_DIR}/%d.png -c:v libx264 -pix_fmt yuv420p -preset fast {smoke_video}\")\n",
    "\n",
    "print_separator()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === SHOW REAL-ESRGAN LOGS ===\n",
    "# –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—á–∞–ª–æ –ª–æ–≥–æ–≤ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∏ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ Real-ESRGAN, –µ—Å–ª–∏ –æ–Ω–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç\n",
    "import os\n",
    "LOG_DIR = os.path.join(os.getcwd(), 'logs')\n",
    "install_log = os.path.join(LOG_DIR, 'real_esrgan_install.log')\n",
    "inf_log = os.path.join(LOG_DIR, 'real_esrgan_inference.log')\n",
    "\n",
    "def show_log(path, max_chars=20000):\n",
    "    if os.path.exists(path):\n",
    "        print('\\n' + '='*40)\n",
    "        print('LOG:', path)\n",
    "        print('='*40)\n",
    "        try:\n",
    "            with open(path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                data = f.read()\n",
    "            print(data[:max_chars])\n",
    "            if len(data) > max_chars:\n",
    "                print('\\n... (truncated) ...')\n",
    "        except Exception as e:\n",
    "            print('Could not read log:', e)\n",
    "    else:\n",
    "        print(f'Log not found: {path}')\n",
    "\n",
    "print('Checking Real-ESRGAN logs in', LOG_DIR)\n",
    "show_log(install_log)\n",
    "show_log(inf_log)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
