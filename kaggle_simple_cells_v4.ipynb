{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üé¨ –ì–û–î–ñ–û 30 –°–ï–ö ‚Äî –ü–†–û–°–¢–ê–Ø –í–ï–†–°–ò–Ø –ë–ï–ó COMFYUI\n",
        "\n",
        "**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç notebook:**\n",
        "- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∞–Ω–∏–º–∞—Ü–∏—é —Å AnimateDiff –∏–ª–∏ —Å—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã\n",
        "- –ü—Ä–∏–º–µ–Ω—è–µ—Ç upscale —á–µ—Ä–µ–∑ Real-ESRGAN (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
        "- –ò–Ω—Ç–µ—Ä–ø–æ–ª–∏—Ä—É–µ—Ç –∫–∞–¥—Ä—ã —á–µ—Ä–µ–∑ RIFE –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏\n",
        "- –°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ\n",
        "\n",
        "**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:**\n",
        "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç —Å –º–æ–¥–µ–ª—è–º–∏ –≤ Kaggle\n",
        "2. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —è—á–µ–π–∫–µ –Ω–∏–∂–µ\n",
        "3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –≤—Å–µ —è—á–µ–π–∫–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É (Run All)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# üìù –ù–ê–°–¢–†–û–ô–ö–ò - –ú–ï–ù–Ø–ô –¢–û–õ–¨–ö–û –≠–¢–û!\n",
        "# ============================================\n",
        "PROMPT = \"cinematic portrait of gojo satoru, white spiky hair, black blindfold, confident expression, anime style, highly detailed, 8k, professional lighting\"\n",
        "NEGATIVE_PROMPT = \"blurry, deformed, low quality, watermark, text, bad anatomy, multiple heads, duplicate\"\n",
        "\n",
        "# –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã\n",
        "USE_ANIMATEDIFF = True  # True = –Ω–∞—Å—Ç–æ—è—â–∞—è –∞–Ω–∏–º–∞—Ü–∏—è, False = —Å—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã + RIFE\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏\n",
        "WIDTH = 512\n",
        "HEIGHT = 768\n",
        "NUM_FRAMES = 16 if USE_ANIMATEDIFF else 8  # AnimateDiff: 16-24, –æ–±—ã—á–Ω—ã–π: 8-12\n",
        "STEPS = 25 if USE_ANIMATEDIFF else 20  # –î–ª—è –∞–Ω–∏–º–∞—Ü–∏–∏ –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ steps\n",
        "CFG_SCALE = 7.5 if USE_ANIMATEDIFF else 7\n",
        "FPS = 8  # FPS –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –≤–∏–¥–µ–æ\n",
        "\n",
        "# –ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è RIFE (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
        "USE_RIFE = True  # –ü—Ä–∏–º–µ–Ω–∏—Ç—å RIFE –¥–ª—è –µ—â—ë –±–æ–ª–µ–µ –ø–ª–∞–≤–Ω–æ–π –∞–Ω–∏–º–∞—Ü–∏–∏\n",
        "RIFE_EXP = 4 if USE_ANIMATEDIFF else 5  # AnimateDiff: 4 (16‚Üí256), –æ–±—ã—á–Ω—ã–π: 5 (8‚Üí256)\n",
        "# ============================================\n",
        "\n",
        "print(\"‚úì –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n",
        "print(f\"  –†–µ–∂–∏–º: {'AnimateDiff' if USE_ANIMATEDIFF else '–°—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã'}\")\n",
        "print(f\"  –ö–∞–¥—Ä–æ–≤: {NUM_FRAMES}\" + (f\" ‚Üí {NUM_FRAMES * (2**RIFE_EXP)}\" if USE_RIFE else \"\"))\n",
        "print(f\"  –†–∞–∑–º–µ—Ä: {WIDTH}x{HEIGHT}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø ===\n",
        "import os\n",
        "import time\n",
        "from IPython.display import FileLink, display\n",
        "\n",
        "WORKSPACE = \"/kaggle/working\"\n",
        "FRAMES_DIR = f\"{WORKSPACE}/frames\"\n",
        "DATASET_DIR = \"/kaggle/input/comfyui-models-gojo\"\n",
        "\n",
        "os.makedirs(FRAMES_DIR, exist_ok=True)\n",
        "print(\"‚úì –ü–∞–ø–∫–∏ —Å–æ–∑–¥–∞–Ω—ã\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === –£–°–¢–ê–ù–û–í–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô ===\n",
        "print(\"üîß –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...\\n\")\n",
        "\n",
        "import sys\n",
        "import importlib.util\n",
        "\n",
        "def check_package(package_name):\n",
        "    \"\"\"–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–∞–∫–µ—Ç–∞ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞\"\"\"\n",
        "    return importlib.util.find_spec(package_name) is not None\n",
        "\n",
        "# –°–ø–∏—Å–æ–∫ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤\n",
        "packages_to_install = []\n",
        "\n",
        "if not check_package(\"diffusers\"):\n",
        "    packages_to_install.append(\"diffusers[torch]\")\n",
        "    packages_to_install.append(\"transformers\")\n",
        "    packages_to_install.append(\"accelerate\")\n",
        "else:\n",
        "    print(\"‚úì diffusers —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
        "\n",
        "if not check_package(\"cv2\"):\n",
        "    packages_to_install.append(\"opencv-python\")\n",
        "else:\n",
        "    print(\"‚úì opencv-python —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
        "\n",
        "if USE_ANIMATEDIFF and not check_package(\"imageio\"):\n",
        "    packages_to_install.append(\"imageio\")\n",
        "    packages_to_install.append(\"imageio-ffmpeg\")\n",
        "elif USE_ANIMATEDIFF:\n",
        "    print(\"‚úì imageio —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\")\n",
        "\n",
        "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ –ø–∞–∫–µ—Ç—ã –æ–¥–Ω–æ–π –∫–æ–º–∞–Ω–¥–æ–π\n",
        "if packages_to_install:\n",
        "    print(f\"\\n–£—Å—Ç–∞–Ω–æ–≤–∫–∞: {', '.join(packages_to_install)}...\")\n",
        "    !pip install -q {' '.join(packages_to_install)}\n",
        "    print(\"‚úì –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
        "\n",
        "print(\"\\n‚úì –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≥–æ—Ç–æ–≤—ã!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö ===\n",
        "print(\"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫ (—ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å ~30 —Å–µ–∫)...\\n\")\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "print(\"‚úì PyTorch –∏ PIL –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n",
        "print(f\"‚úì CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === –ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–î–†–û–í / –ê–ù–ò–ú–ê–¶–ò–ò ===\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"üé® {'–ì–ï–ù–ï–†–ê–¶–ò–Ø –ê–ù–ò–ú–ê–¶–ò–ò' if USE_ANIMATEDIFF else '–ì–ï–ù–ï–†–ê–¶–ò–Ø –ö–ê–î–†–û–í'}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "print(f\"–ü—Ä–æ–º–ø—Ç: {PROMPT[:80]}...\")\n",
        "print(f\"–†–∞–∑–º–µ—Ä: {WIDTH}x{HEIGHT}, Steps: {STEPS}, CFG: {CFG_SCALE}\")\n",
        "print(f\"–ö–∞–¥—Ä–æ–≤: {NUM_FRAMES}\\n\")\n",
        "\n",
        "if USE_ANIMATEDIFF:\n",
        "    # === –†–ï–ñ–ò–ú ANIMATEDIFF - –ù–ê–°–¢–û–Ø–©–ê–Ø –ê–ù–ò–ú–ê–¶–ò–Ø ===\n",
        "    from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler\n",
        "    from diffusers.utils import export_to_video\n",
        "\n",
        "    print(\"–ó–∞–≥—Ä—É–∑–∫–∞ AnimateDiff pipeline...\")\n",
        "\n",
        "    # –ó–∞–≥—Ä—É–∂–∞–µ–º motion adapter\n",
        "    adapter = MotionAdapter.from_pretrained(\n",
        "        \"guoyww/animatediff-motion-adapter-v1-5-2\",\n",
        "        torch_dtype=torch.float16\n",
        "    )\n",
        "\n",
        "    # AnimateDiff —Ä–∞–±–æ—Ç–∞–µ—Ç —Å SD 1.5\n",
        "    pipe = AnimateDiffPipeline.from_pretrained(\n",
        "        \"runwayml/stable-diffusion-v1-5\",\n",
        "        motion_adapter=adapter,\n",
        "        torch_dtype=torch.float16\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        "    pipe.enable_vae_slicing()\n",
        "    pipe.enable_model_cpu_offload()\n",
        "\n",
        "    print(\"‚úì AnimateDiff –≥–æ—Ç–æ–≤!\\n\")\n",
        "    print(\"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∏–º–∞—Ü–∏–∏ (—ç—Ç–æ –∑–∞–π–º–µ—Ç ~3-7 –º–∏–Ω—É—Ç)...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–∏–º–∞—Ü–∏—é\n",
        "    output = pipe(\n",
        "        prompt=PROMPT,\n",
        "        negative_prompt=NEGATIVE_PROMPT,\n",
        "        num_frames=NUM_FRAMES,\n",
        "        width=WIDTH,\n",
        "        height=HEIGHT,\n",
        "        num_inference_steps=STEPS,\n",
        "        guidance_scale=CFG_SCALE,\n",
        "        generator=torch.Generator(\"cuda\").manual_seed(42)\n",
        "    )\n",
        "\n",
        "    frames = output.frames[0]\n",
        "    total_gen_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\n‚úÖ –ê–Ω–∏–º–∞—Ü–∏—è –≥–æ—Ç–æ–≤–∞ –∑–∞ {total_gen_time:.1f}s!\\n\")\n",
        "\n",
        "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä—ã\n",
        "    for i, frame in enumerate(frames):\n",
        "        frame.save(f\"{FRAMES_DIR}/{i}.png\")\n",
        "\n",
        "    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤–æ–µ –≤–∏–¥–µ–æ\n",
        "    base_video = f\"{WORKSPACE}/ANIMATED_BASE.mp4\"\n",
        "    export_to_video(frames, base_video, fps=FPS)\n",
        "    print(f\"‚úì –ë–∞–∑–æ–≤–æ–µ –≤–∏–¥–µ–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ ({len(frames)} –∫–∞–¥—Ä–æ–≤, {FPS} fps)\")\n",
        "\n",
        "    del pipe, adapter\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "else:\n",
        "    # === –†–ï–ñ–ò–ú –°–¢–ê–¢–ò–ß–ù–´–• –ö–ê–î–†–û–í ===\n",
        "    from diffusers import StableDiffusionXLPipeline\n",
        "\n",
        "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–ª–∏ HuggingFace\n",
        "    model_path = f\"{DATASET_DIR}/sd_xl_base_1.0.safetensors\"\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(\"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º HuggingFace...\")\n",
        "        model_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "\n",
        "    print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SDXL...\")\n",
        "    pipe = StableDiffusionXLPipeline.from_single_file(\n",
        "        model_path,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    pipe.enable_attention_slicing()\n",
        "    pipe.enable_vae_slicing()\n",
        "\n",
        "    print(\"‚úì –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!\\n\")\n",
        "\n",
        "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–∞–¥—Ä—ã\n",
        "    start_time = time.time()\n",
        "    for i in range(NUM_FRAMES):\n",
        "        print(f\"–ö–∞–¥—Ä {i+1}/{NUM_FRAMES}...\", end=\" \")\n",
        "\n",
        "        generator = torch.Generator(device=\"cuda\").manual_seed(42 + i)\n",
        "\n",
        "        image = pipe(\n",
        "            prompt=PROMPT,\n",
        "            negative_prompt=NEGATIVE_PROMPT,\n",
        "            width=WIDTH,\n",
        "            height=HEIGHT,\n",
        "            num_inference_steps=STEPS,\n",
        "            guidance_scale=CFG_SCALE,\n",
        "            generator=generator\n",
        "        ).images[0]\n",
        "\n",
        "        image.save(f\"{FRAMES_DIR}/{i}.png\")\n",
        "        print(f\"‚úì ({time.time() - start_time:.1f}s)\")\n",
        "\n",
        "    total_gen_time = time.time() - start_time\n",
        "    print(f\"\\n‚úÖ {NUM_FRAMES} –∫–∞–¥—Ä–æ–≤ –∑–∞ {total_gen_time:.1f}s!\\n\")\n",
        "\n",
        "    del pipe\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"‚úì –ö–∞–¥—Ä—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {FRAMES_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === UPSCALE –° REAL-ESRGAN (–û–ü–¶–ò–û–ù–ê–õ–¨–ù–û) ===\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üìà –ê–ü–°–ö–ï–ô–õ –ö–ê–î–†–û–í –° REAL-ESRGAN\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "upscale_model = f\"{DATASET_DIR}/4x-UltraSharp.pth\"\n",
        "\n",
        "if os.path.exists(upscale_model):\n",
        "    # –ö–ª–æ–Ω–∏—Ä—É–µ–º Real-ESRGAN –µ—Å–ª–∏ –µ—â–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω\n",
        "    if not os.path.exists(f\"{WORKSPACE}/Real-ESRGAN\"):\n",
        "        print(\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Real-ESRGAN...\")\n",
        "        !git clone https://github.com/xinntao/Real-ESRGAN {WORKSPACE}/Real-ESRGAN\n",
        "        %cd {WORKSPACE}/Real-ESRGAN\n",
        "        !pip install -q basicsr facexlib gfpgan realesrgan\n",
        "    else:\n",
        "        %cd {WORKSPACE}/Real-ESRGAN\n",
        "\n",
        "    # –ö–æ–ø–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å\n",
        "    !mkdir -p weights\n",
        "    !cp {upscale_model} weights/\n",
        "\n",
        "    # –ê–ø—Å–∫–µ–π–ª –∫–∞–∂–¥–æ–≥–æ –∫–∞–¥—Ä–∞\n",
        "    print(\"\\n–ó–∞–ø—É—Å–∫ –∞–ø—Å–∫–µ–π–ª–∞...\")\n",
        "    !python inference_realesrgan.py \\\n",
        "        -n 4x-UltraSharp \\\n",
        "        -i {FRAMES_DIR} \\\n",
        "        -o {FRAMES_DIR}_upscaled \\\n",
        "        --fp32\n",
        "\n",
        "    # –ó–∞–º–µ–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∫–∞–¥—Ä—ã –∞–ø—Å–∫–µ–π–ª–µ–Ω–Ω—ã–º–∏\n",
        "    !rm -rf {FRAMES_DIR}\n",
        "    !mv {FRAMES_DIR}_upscaled {FRAMES_DIR}\n",
        "\n",
        "    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ (Real-ESRGAN –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å)\n",
        "    import glob\n",
        "    upscaled_files = sorted(glob.glob(f\"{FRAMES_DIR}/*_out.png\"))\n",
        "    for i, filepath in enumerate(upscaled_files):\n",
        "        os.rename(filepath, f\"{FRAMES_DIR}/{i}.png\")\n",
        "\n",
        "    print(\"\\n‚úì –ê–ø—Å–∫–µ–π–ª –∑–∞–≤–µ—Ä—à–µ–Ω!\")\n",
        "    %cd {WORKSPACE}\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Upscale –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–ø—Å–∫–µ–π–ª\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === RIFE –ò–ù–¢–ï–†–ü–û–õ–Ø–¶–ò–Ø ===\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üéûÔ∏è –ò–ù–¢–ï–†–ü–û–õ–Ø–¶–ò–Ø –ö–ê–î–†–û–í\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "if not USE_RIFE:\n",
        "    print(f\"‚ö†Ô∏è RIFE –æ—Ç–∫–ª—é—á–µ–Ω, —Å–æ–∑–¥–∞–µ–º –≤–∏–¥–µ–æ –∏–∑ {NUM_FRAMES} –∫–∞–¥—Ä–æ–≤...\\n\")\n",
        "    !ffmpeg -framerate {FPS} -i {FRAMES_DIR}/%d.png \\\n",
        "        -c:v libx264 -pix_fmt yuv420p -preset fast \\\n",
        "        {WORKSPACE}/GOJO_OUTPUT.mp4 -y -loglevel error\n",
        "\n",
        "    final_video = f\"{WORKSPACE}/GOJO_OUTPUT.mp4\"\n",
        "    if os.path.exists(final_video):\n",
        "        file_size = os.path.getsize(final_video) / 1024 / 1024\n",
        "        print(f\"\\n‚úÖ –ì–û–¢–û–í–û! ({file_size:.1f} MB)\")\n",
        "        display(FileLink(final_video))\n",
        "else:\n",
        "    print(f\"–ò–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è {NUM_FRAMES} ‚Üí {NUM_FRAMES * (2**RIFE_EXP)} –∫–∞–¥—Ä–æ–≤ —Å RIFE...\\n\")\n",
        "    \n",
        "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º Practical-RIFE\n",
        "    if not os.path.exists(f\"{WORKSPACE}/RIFE\"):\n",
        "        print(\"–£—Å—Ç–∞–Ω–æ–≤–∫–∞ RIFE...\")\n",
        "        !rm -rf {WORKSPACE}/RIFE\n",
        "        !git clone https://github.com/hzwer/Practical-RIFE {WORKSPACE}/RIFE\n",
        "    \n",
        "    %cd {WORKSPACE}/RIFE\n",
        "\n",
        "    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ RIFE\n",
        "    !pip install -q scikit-video\n",
        "\n",
        "    # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å RIFE v4.26\n",
        "    if not os.path.exists(\"train_log/flownet.pkl\"):\n",
        "        print(\"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ RIFE v4.26...\")\n",
        "        !pip install -q gdown\n",
        "        !mkdir -p train_log\n",
        "        !gdown 1gViYvvQrtETBgU1w8axZSsr7YUuw31uy -O train_log.zip\n",
        "\n",
        "        model_downloaded = False\n",
        "\n",
        "        if os.path.exists(\"train_log.zip\") and os.path.getsize(\"train_log.zip\") > 1000000:\n",
        "            !unzip -q train_log.zip\n",
        "\n",
        "            # –ò—â–µ–º –º–æ–¥–µ–ª—å\n",
        "            if os.path.exists(\"train_log/flownet.pkl\"):\n",
        "                model_downloaded = True\n",
        "                print(\"‚úì –ú–æ–¥–µ–ª—å RIFE –≥–æ—Ç–æ–≤–∞!\")\n",
        "            else:\n",
        "                # –ò—â–µ–º –≤ –¥—Ä—É–≥–∏—Ö –º–µ—Å—Ç–∞—Ö\n",
        "                result = !find . -name \"flownet.pkl\" | head -1\n",
        "                if result:\n",
        "                    !cp {result[0]} train_log/flownet.pkl\n",
        "                    model_downloaded = True\n",
        "                    print(\"‚úì –ú–æ–¥–µ–ª—å RIFE –≥–æ—Ç–æ–≤–∞!\")\n",
        "\n",
        "        if not model_downloaded:\n",
        "            print(\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –º–æ–¥–µ–ª—å RIFE\")\n",
        "            print(\"–°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–µ –≤–∏–¥–µ–æ –∏–∑ –∫–∞–¥—Ä–æ–≤...\")\n",
        "            !ffmpeg -framerate {FPS} -i {FRAMES_DIR}/%d.png \\\n",
        "                -c:v libx264 -pix_fmt yuv420p -preset fast \\\n",
        "                {WORKSPACE}/GOJO_OUTPUT.mp4 -y -loglevel error\n",
        "    else:\n",
        "        print(\"‚úì –ú–æ–¥–µ–ª—å RIFE —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞\")\n",
        "        model_downloaded = True\n",
        "\n",
        "    if model_downloaded:\n",
        "        # –ó–∞–ø—É—Å–∫–∞–µ–º RIFE –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é\n",
        "        print(f\"\\n–ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ (exp={RIFE_EXP})...\")\n",
        "\n",
        "        !python inference_video.py \\\n",
        "            --img {FRAMES_DIR} \\\n",
        "            --exp {RIFE_EXP} \\\n",
        "            --output {WORKSPACE}/GOJO_OUTPUT.mp4 \\\n",
        "            --UHD\n",
        "\n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
        "        final_video = f\"{WORKSPACE}/GOJO_OUTPUT.mp4\"\n",
        "        if os.path.exists(final_video):\n",
        "            file_size = os.path.getsize(final_video) / 1024 / 1024\n",
        "            print(f\"\\nüéâ –ì–û–¢–û–í–û! –í–∏–¥–µ–æ {NUM_FRAMES * (2**RIFE_EXP)} –∫–∞–¥—Ä–æ–≤ ({file_size:.1f} MB)\")\n",
        "            display(FileLink(final_video))\n",
        "        else:\n",
        "            print(\"\\n‚ö†Ô∏è RIFE –Ω–µ —Å–æ–∑–¥–∞–ª –≤–∏–¥–µ–æ, —Å–æ–∑–¥–∞–µ–º fallback...\")\n",
        "            !ffmpeg -framerate {FPS} -i {FRAMES_DIR}/%d.png \\\n",
        "                -c:v libx264 -pix_fmt yuv420p -preset fast \\\n",
        "                {WORKSPACE}/GOJO_OUTPUT.mp4 -y -loglevel error\n",
        "\n",
        "            if os.path.exists(final_video):\n",
        "                file_size = os.path.getsize(final_video) / 1024 / 1024\n",
        "                print(f\"\\n‚úÖ –ì–û–¢–û–í–û! ({file_size:.1f} MB)\")\n",
        "                display(FileLink(final_video))\n",
        "    \n",
        "    %cd {WORKSPACE}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === –ò–¢–û–ì–ò ===\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"üìã –ò–¢–û–ì–ò –ì–ï–ù–ï–†–ê–¶–ò–ò\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"–†–µ–∂–∏–º: {'AnimateDiff (–∞–Ω–∏–º–∞—Ü–∏—è)' if USE_ANIMATEDIFF else '–°—Ç–∞—Ç–∏—á–Ω—ã–µ –∫–∞–¥—Ä—ã'}\")\n",
        "print(f\"–ü—Ä–æ–º–ø—Ç: {PROMPT[:50]}...\")\n",
        "print(f\"–†–∞–∑–º–µ—Ä: {WIDTH}x{HEIGHT}\")\n",
        "print(f\"–ö–∞–¥—Ä–æ–≤: {NUM_FRAMES}\" + (f\" ‚Üí {NUM_FRAMES * (2**RIFE_EXP)}\" if USE_RIFE else \"\"))\n",
        "print(f\"–í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {total_gen_time:.1f}s\")\n",
        "\n",
        "if USE_ANIMATEDIFF:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"üí° –°–û–í–ï–¢–´ –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø –ê–ù–ò–ú–ê–¶–ò–ò\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(\"–î–æ–±–∞–≤—å—Ç–µ –≤ –ø—Ä–æ–º–ø—Ç:\")\n",
        "    print(\"  ‚Ä¢ 'turning head', 'blinking', 'hair flowing'\")\n",
        "    print(\"  ‚Ä¢ 'smooth motion', 'cinematic camera movement'\")\n",
        "    print(\"  ‚Ä¢ 'dynamic pose', 'wind blowing'\")\n",
        "    print(\"\\n–î–æ–±–∞–≤—å—Ç–µ –≤ negative:\")\n",
        "    print(\"  ‚Ä¢ 'static', 'frozen', 'choppy animation'\")\n",
        "    print(\"  ‚Ä¢ 'stiff', 'rigid', 'still image'\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"‚úÖ –í–°–Å –ì–û–¢–û–í–û!\")\n",
        "print(f\"{'='*60}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}