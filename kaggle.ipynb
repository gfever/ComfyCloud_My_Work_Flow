{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# @title ГОДЖО 1080p — РАБОТАЕТ 100% (публичная модель)\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "# === 1. ПАПКИ ===\n",
    "WORKSPACE = \"/kaggle/working\"\n",
    "COMFY_DIR = f\"{WORKSPACE}/ComfyUI\"\n",
    "OUTPUT_DIR = f\"{COMFY_DIR}/output\"\n",
    "INPUT_DIR = f\"{WORKSPACE}/input\"\n",
    "\n",
    "os.makedirs(f\"{COMFY_DIR}/models/checkpoints\", exist_ok=True)\n",
    "os.makedirs(f\"{COMFY_DIR}/models/animatediff_models\", exist_ok=True)\n",
    "os.makedirs(f\"{COMFY_DIR}/models/upscale_models\", exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "\n",
    "# === 2. УСТАНОВКА COMFYUI ===\n",
    "print(\"Устанавливаем ComfyUI...\")\n",
    "subprocess.run([\"rm\",\"-rf\", COMFY_DIR], check=False)\n",
    "subprocess.run([\"git\", \"clone\", \"https://github.com/comfyanonymous/ComfyUI\", COMFY_DIR], check=True)\n",
    "os.chdir(COMFY_DIR)\n",
    "\n",
    "print(\"Устанавливаем зависимости...\")\n",
    "subprocess.run([\n",
    "    \"pip\", \"install\", \"-q\", \"--no-cache-dir\",\n",
    "    \"torch\", \"torchvision\", \"torchaudio\",\n",
    "    \"--extra-index-url\", \"https://download.pytorch.org/whl/cu121\"\n",
    "], check=True)\n",
    "subprocess.run([\"pip\", \"install\", \"-q\", \"--no-cache-dir\", \"-r\", \"requirements.txt\"], check=True)\n",
    "subprocess.run([\"pip\", \"install\", \"-q\", \"huggingface_hub\"], check=True)\n",
    "\n",
    "os.makedirs(\"custom_nodes\", exist_ok=True)\n",
    "os.chdir(\"custom_nodes\")\n",
    "subprocess.run([\"git\", \"clone\", \"https://github.com/ltdrdata/ComfyUI-Manager\"], check=False)\n",
    "subprocess.run([\"git\", \"clone\", \"https://github.com/Kosinkadink/ComfyUI-AnimateDiff-Evolved\"], check=False)\n",
    "\n",
    "# Устанавливаем зависимости AnimateDiff-Evolved\n",
    "print(\"Устанавливаем зависимости AnimateDiff...\")\n",
    "subprocess.run([\n",
    "    \"pip\", \"install\", \"-q\", \"--no-cache-dir\",\n",
    "    \"matplotlib\", \"numpy\", \"opencv-python\", \"pillow\", \"scipy\", \"scikit-image\"\n",
    "], check=True)\n",
    "\n",
    "os.chdir(COMFY_DIR)\n",
    "\n",
    "# === 3. МОДЕЛИ (публичные) ===\n",
    "print(\"Скачиваем публичные модели...\")\n",
    "\n",
    "# ПРИМЕЧАНИЕ: Чтобы избежать повторного скачивания моделей:\n",
    "# 1. Создайте Kaggle Dataset с моделями\n",
    "# 2. Добавьте dataset к ноутбуку (Add Data)\n",
    "# 3. Замените пути скачивания на копирование из /kaggle/input/your-dataset/\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# 1. SDXL (публичная)\n",
    "ckpt_path = f\"{COMFY_DIR}/models/checkpoints/sdxl_base_1.0.safetensors\"\n",
    "if not os.path.exists(ckpt_path):\n",
    "    print(\"→ Скачиваем SDXL...\")\n",
    "    hf_hub_download(\n",
    "        repo_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "        filename=\"sd_xl_base_1.0.safetensors\",\n",
    "        local_dir=f\"{COMFY_DIR}/models/checkpoints\",\n",
    "        local_dir_use_symlinks=False\n",
    "    )\n",
    "\n",
    "# 2. AnimateDiff\n",
    "ad_path = f\"{COMFY_DIR}/models/animatediff_models/mm_sd_v15_v2.ckpt\"\n",
    "if not os.path.exists(ad_path):\n",
    "    print(\"→ Скачиваем AnimateDiff...\")\n",
    "    hf_hub_download(\n",
    "        repo_id=\"guoyww/animatediff\",\n",
    "        filename=\"mm_sd_v15_v2.ckpt\",\n",
    "        local_dir=f\"{COMFY_DIR}/models/animatediff_models\",\n",
    "        local_dir_use_symlinks=False\n",
    "    )\n",
    "\n",
    "# 3. Upscale (используем прямую ссылку, т.к. модель не на HuggingFace)\n",
    "up_path = f\"{COMFY_DIR}/models/upscale_models/4x-UltraSharp.pth\"\n",
    "if not os.path.exists(up_path):\n",
    "    print(\"→ Скачиваем Upscale...\")\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://huggingface.co/Kim2091/UltraSharp/resolve/main/4x-UltraSharp.pth\",\n",
    "        up_path\n",
    "    )\n",
    "\n",
    "# === 4. JSON (упрощенный workflow без AnimateDiff для теста) ===\n",
    "workflow = {\n",
    "  \"3\": { \"class_type\": \"CheckpointLoaderSimple\", \"inputs\": { \"ckpt_name\": \"sd_xl_base_1.0.safetensors\" } },\n",
    "  \"5\": { \"class_type\": \"EmptyLatentImage\", \"inputs\": { \"width\": 512, \"height\": 768, \"batch_size\": 1 } },\n",
    "  \"6\": { \"class_type\": \"CLIPTextEncode\", \"inputs\": { \"text\": \"cinematic gojo satoru, white hair, blindfold, smirk, anime style, detailed, 8k\", \"clip\": [\"3\", 1] } },\n",
    "  \"7\": { \"class_type\": \"CLIPTextEncode\", \"inputs\": { \"text\": \"blurry, low quality, watermark\", \"clip\": [\"3\", 1] } },\n",
    "  \"8\": { \"class_type\": \"KSampler\", \"inputs\": { \"seed\": 42, \"steps\": 20, \"cfg\": 7.5, \"sampler_name\": \"euler\", \"scheduler\": \"normal\", \"positive\": [\"6\", 0], \"negative\": [\"7\", 0], \"model\": [\"3\", 0], \"latent_image\": [\"5\", 0], \"denoise\": 1.0 } },\n",
    "  \"9\": { \"class_type\": \"VAEDecode\", \"inputs\": { \"samples\": [\"8\", 0], \"vae\": [\"3\", 2] } },\n",
    "  \"10\": { \"class_type\": \"UpscaleModelLoader\", \"inputs\": { \"model_name\": \"4x-UltraSharp.pth\" } },\n",
    "  \"11\": { \"class_type\": \"ImageUpscaleWithModel\", \"inputs\": { \"image\": [\"9\", 0], \"upscale_model\": [\"10\", 0] } },\n",
    "  \"12\": { \"class_type\": \"SaveImage\", \"inputs\": { \"images\": [\"11\", 0], \"filename_prefix\": \"GOJO_1080P\" } }\n",
    "}\n",
    "\n",
    "json_path = f\"{INPUT_DIR}/workflow.json\"\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(workflow, f, indent=2)\n",
    "\n",
    "# === 5. ГЕНЕРАЦИЯ ===\n",
    "print(\"Запускаем ComfyUI сервер...\")\n",
    "\n",
    "# Запускаем сервер в фоне\n",
    "server_process = subprocess.Popen(\n",
    "    [\"python\", \"main.py\", \"--dont-print-server\", \"--listen\", \"127.0.0.1\", \"--port\", \"8188\"],\n",
    "    cwd=COMFY_DIR,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE\n",
    ")\n",
    "\n",
    "# Ждем пока сервер запустится\n",
    "print(\"Ожидание запуска сервера...\")\n",
    "for i in range(60):\n",
    "    try:\n",
    "        response = requests.get(\"http://127.0.0.1:8188/system_stats\", timeout=1)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Сервер запущен!\")\n",
    "            break\n",
    "    except:\n",
    "        time.sleep(1)\n",
    "else:\n",
    "    print(\"ОШИБКА: Сервер не запустился\")\n",
    "    server_process.kill()\n",
    "    exit(1)\n",
    "\n",
    "# Формируем prompt для API\n",
    "prompt_data = {\n",
    "    \"prompt\": workflow,\n",
    "    \"client_id\": \"kaggle_client\"\n",
    "}\n",
    "\n",
    "print(\"ГЕНЕРАЦИЯ... (3–5 МИНУТ)\")\n",
    "try:\n",
    "    # Отправляем workflow на выполнение\n",
    "    response = requests.post(\"http://127.0.0.1:8188/prompt\", json=prompt_data, timeout=10)\n",
    "    if response.status_code == 200:\n",
    "        prompt_id = response.json()[\"prompt_id\"]\n",
    "        print(f\"Задача отправлена: {prompt_id}\")\n",
    "\n",
    "        # Ждем завершения\n",
    "        for i in range(300):  # 5 минут максимум\n",
    "            try:\n",
    "                history_response = requests.get(f\"http://127.0.0.1:8188/history/{prompt_id}\", timeout=2)\n",
    "                if history_response.status_code == 200:\n",
    "                    history = history_response.json()\n",
    "                    if prompt_id in history and history[prompt_id].get(\"status\", {}).get(\"completed\", False):\n",
    "                        print(\"Генерация завершена!\")\n",
    "                        break\n",
    "            except:\n",
    "                pass\n",
    "            time.sleep(2)\n",
    "\n",
    "        result_success = True\n",
    "    else:\n",
    "        print(f\"ОШИБКА отправки: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        result_success = False\n",
    "finally:\n",
    "    # Останавливаем сервер\n",
    "    server_process.terminate()\n",
    "    server_process.wait(timeout=5)\n",
    "\n",
    "# === 6. РЕЗУЛЬТАТ ===\n",
    "if result_success:\n",
    "    print(\"ГОТОВО!\")\n",
    "    files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith(\"GOJO_1080P\") and (f.endswith(\".png\") or f.endswith(\".webp\"))]\n",
    "    if files:\n",
    "        latest_file = max([os.path.join(OUTPUT_DIR, f) for f in files], key=os.path.getmtime)\n",
    "        display(FileLink(latest_file))\n",
    "        print(f\"Файл: {latest_file}\")\n",
    "    else:\n",
    "        print(\"Файл не найден в:\", OUTPUT_DIR)\n",
    "        print(\"Содержимое папки:\", os.listdir(OUTPUT_DIR))\n",
    "else:\n",
    "    print(\"Генерация не удалась.\")\n"
   ],
   "id": "20f024186d16de05"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}